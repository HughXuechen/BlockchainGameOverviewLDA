A Decentralized Review System for Data Marketplaces
A Decentralized Review System for Data
Marketplaces
Anusha Avyukt
Viterbi School of Engineering
University of Southern California
Los Angeles, USA
avyukt@usc.edu
Gowri Ramachandran
Viterbi School of Engineering
University of Southern California
Los Angeles, USA
gsramach@usc.edu
Bhaskar Krishnamachari
Viterbi School of Engineering
University of Southern California
Los Angeles, USA
bkrishna@usc.edu
Abstract—Data Marketplaces allow a wide range of public and
private data providers on the one hand, and data-consuming
applications on the other, to interact. They can be used to
exchange valuable data relevant to a community, such as data
relevant to traffic, road conditions, parking, air quality and other
urban internet of things (IoT) applications, in a scalable manner.
Traditionally, online marketplaces use ratings by buyers to help
potential consumers identify good quality products; however such
rating systems are often easy for sellers to game by paying for
flattering ratings and reviews. These problems are even more
challenging in data marketplaces due to the possibility of sellers
launching Sybil attacks (taking on multiple fake identities) to rate
their own products. We propose a novel decentralized crypto-
economic system to ensure the credibility of reviews. The key
idea of our proposed system, which can be implemented using
decentralized smart contracts, is to have sellers apply for their
products to be reviewed, followed by an allocation of products
to a select subset of reviewers with credibility. The reviewer
allocation process is randomized and double-blinded to minimize
the possibility of collusion with the seller. The reviewers are
incentivized through a mechanism that not only provides a
reward for reviewing products posted by sellers but also an
additional reward for reviewing test products posted by the
marketplace. We analyze the incentive mechanism through game
theoretical modeling and show conditions under which the Nash
equilibrium policy is for all reviewers to perform the work needed
for the review (without guessing at the answer). We also show
how the staking mechanism in conjunction with high quality
reviews incentivizes sellers to post higher-quality products. A
marketplace with higher-quality products, in turn, is likely to
have a stronger reputation and attract more customers, helping
the entire ecosystem.
I. INTRODUCTION
There has been a growing interest in developing IoT and
data-driven machine learning based applications for smart
cities for a number of applications ranging from parking to
traffic monitoring to air quality monitoring. Building each such
IoT data-driven application as a separate vertically integrated
silo is very challenging to scale. Therefore several groups
of researchers and practitioners have recently proposed the
development of online data marketplaces that decouple data
sources and data providers from data consuming application
developers. Examples of such recent data marketplaces and
data management platforms for smart cities include Ter-
bine [1], Snowflake [2], Cisco Kinetic, Fiware [3] and the
I3 data marketplace [4].
Ratings and reviews play a significant role in helping to
inform and guide buyers about the relevance and quality of
products on a marketplace platform. Maintaining the integrity
and reliability of ratings and reviews for online marketplace
has been a continuing challenge. Many of the concerns have
had to do with sellers manipulating platforms by injecting
fake ratings. Another unaddressed challenge for centralized
marketplaces is that buyers must implicitly trust the single
platform owner to not censor or manipulate reviews and ratings
in such a way as to maximize their own profits.
In this paper, we propose a novel decentralized rating and
review system for a high-quality, curated data marketplace.
Unlike a traditional marketplace where sellers can proceed to
post products directly and then an open-ended review process
is followed, the proposed system is aimed at a more curated
system, which requires sellers to first apply to have their
data products reviewed along with an application fee and a
staked security deposit. The product is then allocated for a
double-blind review process (to prevent collusion) to a subset
of qualified reviewers, who assess the quality of the product
and provide their ratings. Reviewer assessment mechanisms
are proposed and analyzed to ensure a good-quality review
process, with reviewers compensated using funds from the
application fees as well as any forfeited deposits. The posting
of the product on the marketplace will be conditioned on
sufficient positive reviews, and the seller may also lose their
deposit in case of sufficiently negative reviews, driving the
marketplace towards high-quality products. By running the
process transparently in a decentralized manner using smart
contracts on an immutable Blockchain, the system guards
against the possibility of manipulation by a single marketplace
administrator.
The following are the key contributions of this work:
• A novel incentive-based decentralized review system for
data marketplaces.
• Game theoretic modeling of the incentivized review pro-
cess, identifying conditions under which the combination
of rewards from reviewing legitimate products and test
products yields all reviewers behaving honestly as the
sole equilibrium.
20
21
 IE
EE
 In
te
rn
at
io
na
l C
on
fe
re
nc
e 
on
 B
lo
ck
ch
ai
n 
an
d 
C
ry
pt
oc
ur
re
nc
y 
(I
C
B
C
) |
 9
78
-1
-6
65
4-
35
78
-9
/2
0/
$3
1.
00
 ©
20
21
 IE
EE
 | 
D
O
I: 
10
.1
10
9/
IC
B
C
51
06
9.
20
21
.9
46
11
49
978-1-6654-3578-9/21/$31.00 ©2021 IEEE
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 08:14:32 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 1. Key Elements of a Decentralized Data Marketplace [5]
• Analysis of seller-incentives showing how the mechanism
would contribute to a marketplace with high quality
goods.
• Code and data from our results are made publicly avail-
able for use by other researchers at https://github.com/
ANRGUSC/DecentralizedReviewSystem.
The proposed approach carefully synthesizes and builds on
a number of complementary ideas from different domains
in a fundamentally new construction, including double-blind
allocation from the traditional academic peer-review process
as well as the use and analysis of incentives using game
theory. To our knowledge no prior works have proposed such
a comprehensive, incentive-based decentralized review system
for such data marketplaces.
The rest of the paper is structured as follows: Section II
introduces data marketplaces and discusses the related work.
The proposed mechanism for our decentralized review system
is presented in Section III. The game theory analysis of the
proposed review system is presented in Section IV. Section V
presents the simulation results of the proposed review system.
The sellers’ strategy is analyzed in Section VI. Section VII
discusses open challenges. Section VIII concludes the paper.
II. BACKGROUND AND RELATED WORK
A. Marketplaces
Online Marketplaces: Online e-commerce services have
been active for almost two decades now to help consumers
buy physical goods without visiting multiple shops. Amazon,
e-Bay, and Alibaba are examples of digital marketplaces,
attracting thousands of sellers and buyers. Empirical studies
on marketplaces discuss the importance of ratings and show
how it influences the consumers’ buying behavior [6], [7].
Hu et al. highlights that the buyers tend to focus not only on
the reviews but also on the credibility of the reviewers before
buying a product in online data marketplaces [7]. From the
seller’s point of view, it is important to receive high ratings
from the customers. Some firms even devise strategies to
manipulate ratings on online marketplaces [8]. Even online
ratings and recommendation platforms such as Yelp allow
malicious sellers to tamper with the ratings of products or
services [9].
Decentralized Marketplaces: The marketplaces such as
Amazon, eBay, and Alibaba follow a centralized architecture
with a single administrative domain. Centralized architectures
are susceptible to a single point of failure since the adminis-
trative organization can manipulate the marketplace operations
or incorporate malicious policies to increase profits while
deceiving the sellers and/or buyers. OpenBazaar [10] presents
a decentralized marketplace using the blockchain technology.
Following a decentralized, peer-to-peer architecture, Open-
Bazaar allows the seller to list products for free without
any platform fee. Besides, all the marketplace operations are
executed on top of a blockchain platform, providing high
transparency for the sellers and buyers.
Data marketplaces: Like marketplaces for physical goods
such as books and electronic items, the data marketplaces [4],
[1], [2], [11] are being created to help the IoT device owners
and data providers to sell their data with application devel-
opers. I3 [4] is an open-source IoT data marketplace [12]
for smart communities. A city-wide parking application is
currently being developed using the I3 data marketplace in
Los Angeles, USA [13]. Another active data marketplace is
Terbine [1], which sells traffic and environment related data
such as temperature, humidity, and air quality for multiple
countries. Data from various sources, including financial and
governmental organizations, are available on the Snowflake
data marketplace [2]. QueXopa [11] is an emerging data
marketplace in Latin America, providing data about the trans-
portation industry and environment for application developers.
These efforts show that the data marketplaces are starting to
gain traction, and many application developers are leveraging
such platforms to build data-driven applications.
Decentralized data marketplaces: The data marketplaces
such as I3, Terbine, and SnowFlake are centralized mar-
ketplaces administered by a single organization. Such an
operational model allows the administrator to control the op-
erations and policies with little to no transparency. DDM [5],
Ocean [14], and Streamr [15] are examples of decentralized
data marketplaces, which leverage blockchain technology and
smart contracts to involve multiple organizations in the admin-
istration process, enhancing trust and transparency. Figure 1
shows the elements of a decentralized data marketplace.
B. Ratings for Online Marketplaces
In its early days, Amazon hired review writers to create
product reviews for books to provide a signal for buyers [16].
In this case, reviewers may not offer honest and negative
thoughts since it may discourage buyers, impacting product
sales. Such practices are harder to identify when the market-
place is administrated by a single organization, which sets the
reviewing processes’ policies.
Malbon [17] also present examples of sellers and marketers,
leaving fake reviews in the online marketplace to increase
sales. The majority of the marketplaces suffer from Sybil
attacks, wherein a set of malicious individuals create multiple
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 08:14:32 UTC from IEEE Xplore.  Restrictions apply. 
fake identities on the digital platform to leave fake reviews.
In the literature, to mitigate such Sybil attacks, approaches
based on social networks [18], [19] have been presented.
Such techniques look at the social connections between iden-
tities to check for human-established trust in relationships.
Unfortunately, these approaches do not entirely reduce the
Sybil attacks, since some users may act honestly for sufficient
duration to gain credibility on the platform and then use it
to let malicious users enter the platform. These attackers are
referred to as “traitors” since they turn against the platform
after acting honestly for a sufficient period [20].
Some marketplaces provide more credibility to the ratings
provided by the product purchasers. For example, the Amazon
marketplace adds a label “verified purchaser” next to ratings
added by people who bought it. Lately, malicious sellers
have started creating accounts in the name of random people,
shipped products to their address, and then added fake reviews
on the marketplace [21]. This scam, a more sophisticated form
of Sybil attack, is known as “brushing”. Such incidents show
that malicious sellers are willing to try various approaches to
gain a reputation in the marketplace maliciously.
Rating the Raters: There is existing work on managing
trust and reputation to check fraudulent and discriminatory
ratings and inflated reviews in wiki-like collaborative in-
formation platforms, social networks, and centralized digital
marketplaces to draw upon [22], [23], [24]. Some notable
examples are game-theoretic analysis to find strategies in
reputation-based systems [22], algorithms to filter out unfair
ratings e.g., Bayesian methods [23] and simulations to find the
proportion of good raters required by the algorithm to reduce
the effects of inflated or malicious rating [24]. Such efforts
highlight the importance of assessing the credibility of the
raters.
C. Blockchain and Decentralized Systems
The blockchain technology introduced techniques to create
decentralized systems involving multiple organizations. A new
class of solutions [25], [26], [27], [28], [29], [30] involving
Blockchain and distributed ledger technology, smart contracts,
and incentive mechanisms are starting to address Sybil attacks
and other trust issues in marketplaces. Siddarth et al. [25] dis-
cuss the pros and cons of Sybil-resistant mechanisms based on
voting and consensus algorithms. Teutsch et al. [27] introduce
TrueBit, a scalability solution for blockchain involving public
nodes, where the execution of blockchain smart contracts are
off-loaded onto ”prover” nodes whose job is to execute the
computation and return the result. However, the prover may
cheat and produce incorrect computation results. To address
this, [27] presents a verification mechanism involving a set
of ”verifier” nodes, whose job is to verify the computation’s
correctness using the proofs submitted by the prover nodes.
There is a possibility that even the verifier may cheat by
not checking the correctness. TrueBit incentivizes the verifier
nodes by randomly injecting forced errors into the verification
process to overcome this problem. The nodes that successfully
verify and detect the forced error win a big reward (denoted
as “jackpot” in [27]). Through this innovative incentive
mechanism, TrueBit can ensure that the verifier nodes are
correctly doing their job. This example shows that incentive-
based schemes can enhance trust in online platforms.
The Token Curated Registry (TCR) is another crypto-
economic mechanism that we have analyzed in prior
work [30]. It allows the community members to curate lists
or registries. For an item to be placed on a list, the owner of
the item has to stake money prior to the curation process. The
community members, who are also token holders then assess
the item and accept or reject the item based on their collective
knowledge. This approach allows application developers to
create quality lists and the vetting process is carried out by
the community members. Kosmarski et al. [29] have applied
the idea of a token curated registry to academic review process,
wherein the papers are reviewed by a selected set of reviewers
from the review pool. Our proposed idea borrows concepts
from TCR and the academic review process. However, as
shown in prior work [30] TCR suffers from the problem of
equilibrium selection – reviewers can either all vote to accept
or reject good products – both are equilibria. We address this
problem in this paper by proposing and analyzing a mechanism
that guarantees a unique desirable equilibrium.
D. Shortcomings in the State of the Art Review Systems
A large body of literature addresses rating and reputation
schemes for marketplaces that sell physical goods. Unfor-
tunately, the rating and reputation schemes developed for
marketplaces such as Amazon and e-Bay do not directly
apply to data marketplaces since the items exchanged between
sellers and buyers are no longer physical goods but intangible
data. Moreover, the digital data quality is very subjective,
and it largely depends on how the buyer is using the data
to make business decisions in their use case. Existing data
marketplaces such as I3 do not currently offer robust rating
mechanisms to weed out malicious sellers and corrupt raters,
and many of them involve central marketplace operators who
can themselves censor or promote biased reviews.
Besides, the current rating and reputation systems allow
the sellers to list products in the marketplace without any
scrutiny. The products are rated mostly by the buyers after
the products are listed on the marketplace. Such an approach
may harm the marketplace’s reputation since many malicious
sellers may register bad quality products on the platform. The
buyers who find or purchase such low-quality products would
start to form negative opinions about the entire marketplace.
Therefore, it is essential to filter in good quality products
into the marketplace and increase the marketplace’s reputation
and utility. Considering this issue, we investigate a novel and
decentralized rating scheme that scrutinizes the products at
the time of registration and enables credible and trustworthy
reviews to incentivize and support the listing of high quality
products on the marketplace.
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 08:14:32 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 2. A High-Level Overview of the Proposed Approach.
III. PROPOSED MECHANISM
Consider a seller about to post a data product on the
marketplace. The platform has a pool of reviewers who are
registered in the system. There may be some á priori process of
selecting reviewers, e.g. screening by a committee appointed
by the governance body, which would improve the quality of
reviews, but this is not required.
Figure 2 shows our proposed mechanism, which proceeds
as follows:
• Seller must first apply for the product to be reviewed by
providing a fee F and a stake amount S.
• K reviewers are selected in a double-blind and random
manner (e.g. using a distributed random beacon).
• Reviewers are allocated a product to review with a given
deadline and must provide a numerical rating for the
product. For simplicity, we assume a binary (accept /
reject) decision.
• If the majority of reviewers agree to accept, the product
will be accepted; the fee will be retained but the stake
will be returned to seller; a reward R will be given to
reviewers who agreed to accept. The reviewers in the
minority will not get anything.
• If the majority of reviewers agree to reject, the product
will be rejected; the stake and fees will be retained. A
reward R will be given to reviewers who agreed to reject.
(The reward for each review is drawn from a pool that
increases over time due to the combination of fees and
stake collected from the applying sellers).
• To incentivize the reviewers to do a thorough review, oc-
casionally, randomly, test products (for which the correct
decision is known a priori) are injected to the system and
are allocated for review. Reviewers that vote correctly
with regards to the test product are given an incentive,
W .
We next analyze the proposed mechanism from two per-
spectives. In section IV and section V, we first consider the
decision made by reviewers – whether or not to perform
reviews or simply guess a decision. We analyze this using
game theory and identify conditions under which a desirable
unique equilibrium is obtained. We then, in section VI analyze
the decision made by sellers – whether or not to apply for
review of a product depending on whether it is of high or low
quality.
IV. GAME THEORETIC ANALYSIS OF REVIEWER
STRATEGY
A. Model Assumptions
We build a mathematical model to analyze whether re-
viewers will be honest in doing the work needed for the
review process or simply “guess” whether a product should be
accepted or not. For simplicity, we consider a simple binary
rating in this model - each reviewer either recommends the
product to be approved or recommends that it be rejected.
The model proceeds as follows. We assume that each reviewer
has probability pQ of being able to review a given product
correctly. A product under review is a test product (one for
which the correct outcome is known a priori) with probability
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 08:14:32 UTC from IEEE Xplore.  Restrictions apply. 
Guess Review
Guess [α =
(1−pT )R
2
+ pTW
2
, α] [α, β =
(1−pT )R
2
+ pT pQW +
pT (1−pQ)W
2
− pLC]
Review [β, α] [γ = (1− pT )(p2QR+ pQ(1− pQ)R+
(1−pQ)2R
2
) + pT pQW +
pT (1−pQ)W
2
− pLC, γ]
TABLE I
PAYOFF MATRIX FOR REVIEWER GAME
pT , and a regular product to be reviewed with probability
1 − pT . The reviewer is given a reward W if they review a
test product correctly, and a reward R if they review a regular
product correctly. If they guess, they expend no effort and thus
incur no cost for doing the review. Reviewers are “lazy” with
probability pL and lazy reviewers incur a cost C if they do
the review (or, to put it differently, in expectation, the cost of
doing a review for any reviewer is the product pLC).
TABLE II
NOTATION FOR PARAMETERS
For Reviewer’s Game (Section IV)
pT : Probability that a test product is given to review
W : Reward for reviewing the test product correctly
R : Reward for a matching (majority) decision
pL : Probability that reviewer is lazy
C : Cost of doing the review when lazy
pQ : Probability that quality of review is high
For Sellers Game (Section VI)
K : Number of reviewers
pQ : Probability that quality of review is high
PA,H : Probability of accepting a high quality product
PR,L : Probability of rejecting a low quality product
MH : Profit expected when a high quality product is posted on
the marketplace
ML : Profit expected when a low quality product is posted on
the marketplace
Fapply : Application fee for getting a product reviewed
Fstake : Staking fee risked by the Seller
Useller
apply,H : Seller’s utility for a high quality product
Useller
apply,L : Seller’s utility for a low quality product
B. Game Payoffs
Under the above model, we illustrate the payoffs for a
simple 2-reviewer system in table I. As can be seen, the terms
in the payoff matrix can be summarized by the expressions
denoted by variables α, β, and γ.
Desired Equilibrium: The necessary and sufficient condi-
tion under which (Review, Review) is the only Nash equilib-
rium is as follows:
β > α and γ > α (1)
This is because with β > α, a player would prefer reviewing
to guessing even if the other player is guessing; and with
γ > β as well as γ > α neither player would deviate from
reviewing if the other player is reviewing; equivalently if one
player is guessing while the other is reviewing, they would
prefer to switch to reviewing as well.
To gain some insight, we consider the case when both
reviewers are always capable of doing correct reviews, i.e.
pQ = 1. In this case β > α is equivalent to:
W >
2pLC
pT
(2)
And γ > β > α so long as:
R > 0 (3)
Thus, so long as both conditions (2) and (3) hold, the
Nash equilibrium strategy profile is for both players to do
the work of reviewing (without guessing). The outcome may
be somewhat surprising at first glance - it suggests that the
incentive for reviewing, R, is less important for ensuring
the honesty of reviewers than the introduction of tests (with
probability pT ) and a high reward for reviewing those tests
(W ) correctly. Further, the reward W has to be sufficiently
high compared to the effort incurred in reviewing i.e. pLC and
inversely proportional to frequency with which test reviews are
provided to the reviewers.
While we have presented the payoff matrix for just 2
players for ease of exposition, in fact, the above analysis
is quite general and applicable to any number of reviewers.
The sufficient conditions for ensuring honest reviews from all
reviewers is the equilibrium that for any individual reviewer,
they should get sufficient incentive from honestly reviewing
the test products. Though we do not provide the full proof
here due to space limitations, in fact, conditions (2) and (3)
are necessary and sufficient for any number of reviewers to
have a unique equilibrium as the outcome that they all behave
honestly.
Undesirable Equilibrium We can also analyze the condi-
tion under which the game is guaranteed to have the unique
undesirable equilibrium of both reviewers choosing to guess.
This undesired equilibrium is obtained when the following
inequalities hold:
α > β and α > γ (4)
Assuming pQ = 1, the condition in (4) is equivalent to the
following:
pTW
2
+
(1− pT )R
2
< pLC (5)
V. SIMULATION RESULTS
We present some numerical simulations to illustrate and
validate the analysis in the previous section. We generate
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 08:14:32 UTC from IEEE Xplore.  Restrictions apply. 
100,000 random 2-reviewer games, with the following param-
eters being varied uniformly at random in each instance as
described: C from 0 to 50, pL from 0 to 1, R = W varied
from 0 to 100, and the following parameters are fixed in most
of our experiments as follows: pQ = 1, pT = 0.5. These
values were chosen to illustrate the combinations when the
dominant unique Nash equilibrium strategy is to review. In
one of the results we present, we also vary pT from 0.1 to
0.4, showing that W needs to be chosen accordingly to ensure
that reviewing remains the dominant unique Nash equilibrium
strategy.
The software was written using the NashPy library in
Python. The code and data used for the simulation is avail-
able at the following link: https://github.com/ANRGUSC/
DecentralizedReviewSystem.
In Figure 3, we show the results from our experiments.
These results show the fraction of cases when there was
a single equilibrium with both players choosing to review,
the cases of when there was single equilibrium with both
players choosing to guess, and cases when there is no unique
equilibrium. Each plot shows how these three cases vary as the
corresponding parameters are varied. We can see in particular
that:
1) The number of cases where the only equilibrium is for
both players to review decreases with pL and C. This is
consistent with the fact that the condition (2) becomes
harder to satisfy as these quantities increase.
2) The number of cases where the equilibrium is for both
players to review increases with R and W . This is
consistent with the fact that the condition (2) becomes
easier to satisfy as these quantities increase.
The condition in (2) is also directly validated in Figure 4 (a)
and 4 (c). If pT = 0.5, the condition for the only equilibrium
to correspond to both players reviewing honestly reduces to
the following:
W > 4pLC (6)
And if pL · C = 10, then that condition reduces to
W >
20
pT
(7)
These are precisely the regions in which we observe the games
having the desired unique equilibrium of review in Figure 4
(a) and 4 (c).
If we let pT = 0.5 and set R = W , the condition in (5)
reduces to the following, which is exactly the region shown
in Figure 4 (b):
R =W < 2pLC (8)
VI. ANALYSIS OF SELLER STRATEGY AND MARKET
QUALITY
From the analysis in the previous section we have learned
that so long as there are sufficient incentives (in particular, so
long as the product of frequency of tests and the reward for
completing the test reviews correctly pTW is sufficiently high
compared to the expected effort involved in doing the work
of reviewing pLC), the reviewers will have an incentive to
always do a full review.
We assume that each reviewer that does a full review has
an independent probability pQ > 0.5 that their decision is
correct (i.e. that they vote to accept a high quality product or
to reject a low quality product with this probability pQ). For a
high-quality product (respectively, low-quality product), if the
threshold for acceptance (rejection) is that more than 50% of
K reviewers vote to accept (reject) it, then the probability
it will be accepted (rejected) is given by the expression
1 − FX(K/2), where X is a Binomial random variable with
parameters (K, pQ). Assume pQ >= 0.5. A bound on the
probability of accepting a high quality product PA,H can
be given using the Chernoff bound (even tighter bounds are
possible [31]):
PA,H > 1− (2pQ(1− pQ))K
=⇒ PA,H > 1−
(
1
2
)K
(9)
The same bound also holds for PR,L, the probability of
rejecting a low-quality product. We can see that the likelihood
of making correct accept decisions for high-quality products
and the probability of making correct reject decisions for
low-quality products both rapidly approach 1, exponentially
fast with the size of the review committee K. Specifically,
a committee of size K > log(ε)
log(0.5) will ensure that correct
decisions are made with probability at least 1− ε. Concretely,
this implies that just 4 reviewers could ensure more than 90%
correct decisions, and K = 7 reviewers could ensure more
than 99% correct decisions.
From a seller’s perspective, consider their utility with re-
spect to applying to post a high-quality or low-quality product.
Let MH be the units of profit a high quality product is expected
to make if posted on the marketplace, and let ML be the units
of profit a low quality product is expected to make if posted
on the marketplace. Let the application fee be Fapply and the
staking fee is Fstake. The seller’s utility in applying for review
for the two types of products will be as follows:
Usellerapply,H = PA,HMH − (1− PA,H)Fstake − Fapply(10)
Usellerapply,L = (1− PR,L)ML − PR,LFstake − Fapply (11)
The seller will apply for a product whenever its correspond-
ing utility is positive. It is clear from the above expressions
that the seller’s utility for applying for a high quality product
increases as PA,H increases and their utility for applying with
a low-quality product likewise decreases as PR,L increases.
Higher staking fees will particularly discourage posting low-
quality products, though higher application fees would gen-
erally discourage posting any product that will not have
significant expected profit.
VII. DISCUSSION
The model of seller decisions in the previous section,
in conjunction with our analysis of the reviewer decisions,
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 08:14:32 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 3. Distribution of Strategies for Different Values of pT (top-left), pL (top-center), C (top-right), W (bottom-left), and R (bottom-center), and pQ
(bottom-right).
(a) (b) (c)
Fig. 4. Comparison of the Relationship between the Effort (pL · c) and the Reward for Review of Test Products (W ) for Review Strategy in (a) and Guess
Strategy in (b) with pT fixed at 0.5. Variation between Probability of Test Product pT and W for Review Strategy in (c) when pT varies from 0.1 to 0.4
and pL · c = 10 is kept constant.
indicates that having carefully and sufficiently incentivized
reviews has a cascading effect on the quality and reputation of
the market. If sufficient numbers of reviewers are incentivized
to put in the effort, the resulting increase in correct decisions
causes sellers to self-select and be more likely to apply with
higher quality products. A marketplace with more high quality
products in turn will attract more customers resulting in a
thriving ecosystem. At the same time, one must bear in mind
that all of this is predicated on providing sufficient incentives,
which in turn requires higher application fees. Such a review
system will be best suited to high quality products with
sufficient profit margins for the sellers to be able to afford
the high application fees.
We note that our problem formulation is motivated by the
need to ensure honesty in reviews in a decentralized system
where the reviewers may not be personally known to or hired
by a centralized organization. The use of a blockchain-based
smart contract would provide an enforcement mechanism for
the the payoffs indicated in the game-matrix that is credible
because it is transparent and tamper-proof. The implemen-
tation of our system on a blockchain platform would also
facilitate making the payments in an automated fashion using
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 08:14:32 UTC from IEEE Xplore.  Restrictions apply. 
cryptocurrencies.
The following are some of the open questions that we
believe merit further research:
• Formation of Review Committee: How to identify
potential reviewers, especially when the platform is still
new?
• Selection of Reviewers: Our proposed scheme relies on
external reviewers for quality assessment. It is important
to select the right number of reviewers since a small
number of reviewers may reduce the safety of the mar-
ketplaces, while a large number of reviewers may lead to
high cost of incentives. What is the optimal number?
• Test generation: Our proposed mechanism relies on the
use of test reviews to incentive reviewers to do the work.
Generating test reviews in a decentralized manner is an
open problem.
• Review Frequency: When a product gets reviewed only
once at the initial registration time, there is a possibility
that the seller may provide quality data at the registration
phase just to convince the reviewers. To ensure consis-
tently high data quality, the review process has to be
carried out frequently. How regularly or frequently should
a streaming data product be reviewed?
• Preserving confidentiality: How to preserve confiden-
tiality of the seller and rater to ensure true double blind
review? Also, it is important that the reviewer not know
if the product being reviewed is a test product or not.
This will require keeping this information from being
transparently visible to all on-chain participants. What
cryptographic primitives would this need?
• Scalability challenges: When the marketplace becomes
large with high number of data products, there may not
be enough number of qualified reviewers to carry out
the review process; a problem also faced by academic
conferences that receive a large number of submissions.
What is relationship between the number of products,
number of reviewers, and the quality of the products?
How can the review process be scaled to keep up with
the growing marketplace?
• Counterfeiting: The problem of counterfeiting is more
problematic for data products compared to physical goods
because fake data is very low cost to generate. Will
the review and rating mechanism we are proposing help
combat the problem of dumping or flooding of the market
with fake data products?
• Penalty for Incorrect Reviews: In this work we have
focused on a reward-mechanism for correct reviews and
analyzed it as a single shot game. It would be of
interest to analyze repeated interactions involving the
same reviewers as a repeated game setting and consider
reputation mechanisms as well as penalties for incorrect
reviews.
• Malicious Users: The game theoretic modeling here
doesn’t explicitly model a user whose payoff is outside
the given values, such as a malicious reviewer who de-
rives value from purposely injecting bad/incorrect reviews
into the system. How can we protect the system from
malicious users/reviewers?
What is presented in this paper is a general framework and
theoretical analysis that is platform-agnostic. The model and
simulations therefore do not depend on particular blockchain
platform characteristics such as the underlying consensus
mechanism for the platform itself, other than that it be tamper
proof and support decentralized smart contracts. The imple-
mentation details and performance may differ from platform to
platform, and will need to take into account the security needs
of the system. For example, since the selection of test/real
reviews must be kept hidden from the reviewers, this part will
have to be implemented either off-chain or with some privacy
mechanism.
As part of further work, it will be of interest to implement
the system presented in this work as a smart contract and
evaluate it empirically with real users.
VIII. CONCLUSIONS
Data marketplaces are being deployed to connect the data
sellers with application developers. The success of such data
marketplaces depends on the reputation and quality of the data
products. We have presented a decentralized review system
based on blockchain technology and smart contracts to in-
crease sellers’ and buyers’ trust for such platforms. The game-
theoretic analysis and the simulation of the proposed review
mechanism show conditions under which a unique equilibrium
strategy in our game encourages the reviewers to do an honest
review to assess data product quality instead of guessing. We
have also shown that the quality of the marketplace would
increase when the reviewers are accurate and accept high-
quality products into the marketplace, which, in turn, would
encourage sellers to submit high-quality products. To the best
of our knowledge, no prior works have proposed and analyzed
a comprehensive incentive-based decentralized review system
for such data marketplaces.
ACKNOWLEDGMENT
This work was supported by the USC Viterbi Center for
Cyber-Physical Systems and the Internet of Things (CCI).
REFERENCES
[1] “Terbine.io,” https://terbine.com/, accessed: 2021-3-9.
[2] B. Dageville, T. Cruanes, M. Zukowski, V. Antonov, A. Avanes, J. Bock,
J. Claybaugh, D. Engovatov, M. Hentschel, J. Huang, A. W. Lee, A. Mo-
tivala, A. Q. Munir, S. Pelley, P. Povinec, G. Rahn, S. Triantafyllis, and
P. Unterbrunner, “The Snowflake elastic data warehouse,” in Proceedings
of the 2016 International Conference on Management of Data, ser.
SIGMOD ’16. New York, NY, USA: Association for Computing
Machinery, 2016, p. 215–226.
[3] T. Zahariadis, A. Papadakis, F. Alvarez, J. Gonzalez, F. Lopez, F. Facca,
and Y. Al-Hazmi, “FIWARE lab: Managing resources and services in
a cloud federation supporting future internet applications,” in 2014
IEEE/ACM 7th International Conference on Utility and Cloud Com-
puting. IEEE, 2014, pp. 792–799.
[4] B. Krishnamachari, J. Power, S. H. Kim, and C. Shahabi, “I3: An IoT
marketplace for smart communities,” in Proceedings of the 16th Annual
International Conference on Mobile Systems, Applications, and Services,
2018, pp. 498–499.
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 08:14:32 UTC from IEEE Xplore.  Restrictions apply. 
[5] G. S. Ramachandran, R. Radhakrishnan, and B. Krishnamachari, “To-
wards a decentralized data marketplace for smart cities,” in 2018 IEEE
International Smart Cities Conference (ISC2). IEEE, 2018, pp. 1–8.
[6] F. Zhu and X. M. Zhang, “Impact of online consumer reviews on sales:
The moderating role of product and consumer characteristics,” Journal
of Marketing, vol. 74, no. 2, pp. 133–148, 2010.
[7] N. Hu, L. Liu, and J. J. Zhang, “Do online reviews affect product sales?
the role of reviewer characteristics and temporal effects,” Inf. Technol.
and Management, vol. 9, no. 3, p. 201–214, Sep. 2008.
[8] C. Dellarocas, “Strategic manipulation of internet opinion forums:
Implications for consumers and firms,” Management science, vol. 52,
no. 10, pp. 1577–1593, 2006.
[9] M. Luca and G. Zervas, “Fake it till you make it: Reputation, competi-
tion, and Yelp review fraud,” Management Science, vol. 62, no. 12, pp.
3412–3427, 2016.
[10] J. E. Arps and N. Christin, “Open market or ghost town? the curious case
of OpenBazaar,” in International Conference on Financial Cryptography
and Data Security. Springer, 2020, pp. 561–577.
[11] “QueXopa®,” https://quexopa.io/alternative-data/, accessed: 2021-3-9.
[12] X. Zhao, K. K. Sajan, G. S. Ramachandran, and B. Krishnamachari,
“Demo abstract: The intelligent IoT integrator data marketplace-version
1,” in 2020 IEEE/ACM Fifth International Conference on Internet-of-
Things Design and Implementation (IoTDI). IEEE, 2020, pp. 270–271.
[13] G. S. Ramachandran, J. Stout, J. J. Edson, and B. Krishnamachari,
“ParkingJSON: An open standard format for parking data in smart
cities,” Open Journal of Internet Of Things (OJIOT), vol. 6, no. 1, pp.
105–118, 2020.
[14] O. Protocol, “Ocean protocol: A decentralized substrate for AI data &
services-technical whitepaper,” Tech. Rep., 2018. International Journal
of Aerospace Engineering Hindawi, Tech. Rep., 2018.
[15] “Streamr,” https://streamr.network/, accessed: 2021-3-9.
[16] “How aunt ammy gets her free lunch: A study of the top-thousand cus-
tomer reviewers at Amazon.com,” http://www.freelunch.me/filecabinet,
accessed: 2021-3-12.
[17] J. Malbon, “Taking fake online consumer reviews seriously,” Journal of
Consumer Policy, vol. 36, no. 2, pp. 139–157, 2013.
[18] H. Yu, M. Kaminsky, P. B. Gibbons, and A. Flaxman, “SybilGuard:
Defending against sybil attacks via social networks,” in Proceedings
of the 2006 Conference on Applications, Technologies, Architectures,
and Protocols for Computer Communications, ser. SIGCOMM ’06.
New York, NY, USA: Association for Computing Machinery, 2006, p.
267–278.
[19] A. Molavi Kakhki, C. Kliman-Silver, and A. Mislove, “Iolaus: Securing
online content rating systems,” in Proceedings of the 22nd International
Conference on World Wide Web, ser. WWW ’13. New York, NY, USA:
Association for Computing Machinery, 2013, p. 919–930.
[20] S. Marti and H. Garcia-Molina, “Taxonomy of trust: Categorizing P2P
reputation systems,” Computer Networks, vol. 50, no. 4, pp. 472 – 484,
2006, management in Peer-to-Peer Systems.
[21] C. Jin, L. Yang, and K. Hosanagar, “To brush or not to brush: Product
rankings, customer search and fake orders,” Customer Search and Fake
Orders (September 30, 2019) .NET Institute Working Paper, no. 19-02,
2019.
[22] J. Mathis, J. McAndrews, and J.-C. Rochet, “Rating the raters: Are
reputation concerns powerful enough to discipline rating agencies?”
Journal of Monetary Economics, vol. 56, no. 5, pp. 657–674, Jul. 2009.
[23] A. Whitby, A. Jøsang, and J. Indulska, “Filtering out unfair ratings in
Bayesian reputation systems,” in Proceedings of the 7th International
Workshop on Trust in Agent Societies, vol. 6, 2004, pp. 106–117.
[24] A. V. Pantola, S. Pancho-Festin, and F. Salvador, “Rating the raters:
A reputation system for wiki-like domains,” in Proceedings of the
3rd International Conference on Security of Information and Networks.
New York, NY, USA: Association for Computing Machinery, 2010, p.
71–80.
[25] D. Siddarth, S. Ivliev, S. Siri, and P. Berman, “Who watches the
watchmen? a review of subjective approaches for sybil-resistance in
proof of personhood protocols,” arXiv:2008.05300, 2020.
[26] J. Peterson and J. Krug, “Augur: a decentralized, open-source platform
for prediction markets,” arXiv:1501.01042, 2015.
[27] J. Teutsch and C. Reitwießner, “A scalable verification solution for
blockchains,” arXiv:1908.04756, 2019.
[28] A. Asgaonkar and B. Krishnamachari, “Solving the buyer and seller’s
dilemma: A dual-deposit escrow smart contract for provably cheat-proof
delivery and payment for a digital good without a trusted mediator,” in
2019 IEEE International Conference on Blockchain and Cryptocurrency
(ICBC). IEEE, 2019, pp. 262–267.
[29] A. Kosmarski and N. Gordiychuk, “Token-curated registry in a schol-
arly journal: Can blockchain support journal communities?” Learned
Publishing, 2020.
[30] A. Asgaonkar and B. Krishnamachari, “Token curated registries-a game
theoretic approach,” arXiv:1809.01756, 2018.
[31] M. Telgarsky, “Central binomial tail bounds,” arXiv:0911.2077, 2009.
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 08:14:32 UTC from IEEE Xplore.  Restrictions apply. 
		2022-08-24T19:29:52-0400
	Preflight Ticket Signature