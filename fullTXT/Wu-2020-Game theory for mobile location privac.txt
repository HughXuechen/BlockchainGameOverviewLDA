Game Theory for Mobile Location Privacy
Game Theory for Mobile Location Privacy
Xiaotong Wuâˆ—
School of Computer Science and
Technology, Nanjing Normal
University
Nanjing, Jiangsu, China
wuxiaotong@njnu.edu.cn
Genlin Ji
School of Computer Science and
Technology, Nanjing Normal
University
Nanjing, Jiangsu, China
glji@njnu.edu.cn
Wanchun Dou
the State Key Lab for Novel Software
Technology, Nanjing University
Nanjing, Jiangsu, China
douwc@nju.edu.cn
Shui Yu
School of Computer Science,
University of Technology Sydney
Australia
Shui.Yu@uts.edu.au
Lianyong Qi
School of Information, Science and
Engineering, Qufu Normal University
Qufu, Shangdong, China
lianyongqi@gmail.com
ABSTRACT
With the rapid growth of mobile network and infrastructures,
location-related services accross multiple domains have received a
great deal of attention. However, privacy is always an important
problem that has a great influence on services. In order to research
the attack and defence of privacy, we present the existing game-
theoretic literatures for their interactions about mobile location
privacy problems. We first demonstrate the necessity of game the-
ory applied to location privacy. Then, we divide the literatures into
four types according to different game players. Next, we describe
the detailed content and analyse the equilibrium of privacy games.
In addition, we also provide the works based on mechanism design
to motive the defenders to increase the defence in various contexts.
Finally, we also discuss the possible trends and challenges of the
future research. Our survey provides a systematic and comprehen-
sive understanding about location privacy preservation problems
in mobile network.
CCS CONCEPTS
â€¢ Security and privacyâ†’ Privacy protections; Social aspects
of security and privacy; Economics of security and privacy;
â€¢ Networks â†’ Mobile networks;
KEYWORDS
game theory; privacy protection; differential privacy; Nash Equilib-
rium
âˆ—Corresponding Author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
BSCI â€™20, October 6, 2020, Taipei, Taiwan
Â© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-7610-5/20/10. . . $15.00
https://doi.org/10.1145/3384943.3409427
ACM Reference Format:
Xiaotong Wu, Genlin Ji, Wanchun Dou, Shui Yu, and Lianyong Qi. 2020.
Game Theory for Mobile Location Privacy. In Proceedings of the 2nd ACM In-
ternational Symposium on Blockchain and Secure Critical Infrastructure (BSCI
â€™20), October 6, 2020, Taipei, Taiwan. ACM, New York, NY, USA, 11 pages.
https://doi.org/10.1145/3384943.3409427
1 INTRODUCTION
With the rapid development of mobile communication networks
and infrastructures, there are a large number of services and appli-
cations in various mobile devices that are widely applied to daily
life of hundreds of thousands of people. Every day, a tremendous
amount of raw data of mobile users are generated, such as location,
transportations, health and so on. In particular, personal location is
the most common and most frequently used information for nav-
igation, shopping or outside catering. Although mobile users get
benefits from various convenient services, it is possible to leak lo-
cation information due to attacks from untrusted service providers
or adversaries. In fact, privacy has been one of the hottest topics in
various fields, including social network, blockchain, data mining
[2, 31, 40]. For some users, the leakage of private and sensitive
location may cause the loss of money or reputation. Therefore, it is
necessary to utilize private mechanisms to protect privacy against
attacks [30, 41].
In recent years, there have been a large number of works to
implement location privacy protection. In brief, before location in-
formation is sent to untrusted service providers or shared by trusted
data collectors, it needs to be sanitized by various privacy preser-
vation mechanisms. The common privacy metrics are ğ‘˜-anonymity
[36], â„“-diversity [25], ğ‘¡-closeness [22] and differential privacy (DP)
[11] and so on. However, the use of mechanisms satisfying these
privacy metrics always causes a certain amount of loss from aspect
of energy of mobile devices or a decline in service quality. For ex-
ample, when some user generates multiple dummy trajectories by
smart phone to hide his/her true trajectory, it is inevitable of service
delay and power consumption. When a trusted service provider
publishes data or offers query service, he/she must perturb data,
which causes the decrement of accuracy and utility. Thus, both indi-
viduals and service providers need to consider the balance between
data utility and privacy.
BSCI Session 3  BSCI '20, October 6, 2020, Taipei, Taiwan
106
https://doi.org/10.1145/3384943.3409427
https://doi.org/10.1145/3384943.3409427
http://crossmark.crossref.org/dialog/?doi=10.1145%2F3384943.3409427&domain=pdf&date_stamp=2020-10-06
Because of the flow of data, there are multiple different inter-
actions among three key roles, including data owners (i.e., mobile
users), data collectors (i.e., service providers or non-profit orga-
nizations) and adversaries. For each role, he/she has respective
considerations listed as follows:
â€¢ Selection of Privacy Mechanisms (SPM). For data users
and trusted collectors, they first need to choose a proper
privacy mechanism. However, different mechanisms have
different performances in terms of time and space complex-
ity and privacy effect. More importantly, privacy effect is
influenced by many known and unknown factors, such as
the strength of attack.
â€¢ Selection of Privacy Parameters (SPP).After selection of
a protection mechanism, data users and trusted collectors
also need to set up privacy parameter. It directly decides
utility loss (i.e., privacy cost) and the degree of privacy. This
is also correlated to attacks of adversaries.
â€¢ Selection of Strength of Attack (SSA). For adversaries
and untrusted collectors, their auxiliary information and
attack methods decide the upper of the strength of attack.
Each attackmay need a certain amount of cost1. The strength
of attack directly influences privacy risks of data owners and
trusted collectors.
It is challenging to analyse these types of selection of different
roles. In order to solve the challenge, there have been a large number
of literatures to model the interactions of different participants in
location privacy protection based on various mathematical theories.
Game theory [28, 32] is a rich set of mathematical tools to analyse
multi-play strategic decisionmaking. It is very suited to research the
behaviours of different participants. In addition, mechanism design
[27] is also a good theory for researchers to design proper incentive
mechanisms to motive data owners and trusted collectors to protect
location privacy. In fact, privacy decisions based on game-theoretic
methods help to improve efficiency of protection and reduce the
cost of privacy.
Unfortunately, there are few literatures to provide a systematic
and comprehensive overview of the existing efforts for location
privacy preservation. To the best of our knowledge, in the previous
game-based surveys [4, 7, 26, 29], the main focus is on the taxonomy
and survey of network security and privacy. Therefore, this paper
attempts to survey the related work about game-based attack and
defence for location privacy. In detail, we first demonstrate the
necessity of privacy game. Then, we classify game models in terms
of players and information. Next, we survey the existing works
about privacy game. At last, we present the future work.
The remaining of the paper is organized as follows. Section 2
proves the necessity of location privacy game between different
participants. Section 3 introduces the preliminaries of mobile pri-
vacy games including players and classifications. Section 4 presents
attack and defence in mobile network. Section 5 surveys privacy
game. Section 6 proposes the future work for privacy game. Section
7 concludes the work of the paper.
1In some special cases, in order to maximize the ability of atacks, some literatures
assume that the cost is zero.
2 THE NECESSITY OF PRIVACY GAME
Faced with risks of privacy leakage, a data owner needs to consider
not only which private technique to select, but also how to inter-
act with other key participants. At first, there are two important
findings listed as follows:
â€¢ No perfect privacy protection. The existing privacy pro-
tection techniques are usually divided into two classes, i.e.,
data clustering and theoretical framework [44]. The first one
has ğ‘˜-anonymity, â„“-diversity and ğ‘¡-closeness, while the sec-
ond one consists of differential privacy and membership
privacy. Unfortunately, both of two classes donâ€™t offer per-
fect private preservation [20].
â€¢ No free lunch in data privacy. Kifer et al. [20] has demon-
strated that it is inevitable to need a certain amount of cost
with privacy guarantee. The cost may be the loss of data
utility or the decline of service quality. In general, the higher
the degree of privacy preservation, the higher the cost.
The findings imply that each participant thinks about personal
interest and multiple different factors from his/her own perspective.
That is,
â€¢ For data owners, they need to balance the relationship among
data utility, privacy degree and cost, which are correlative
to privacy techniques and parameters.
â€¢ If data collectors are trusted, they has to guarantee data
security against attack from adversaries and also consider
data utility. On the other hand, faced with untrusted data
collectors, data owners protect their privacy in the local
setting.
â€¢ For adversaries, their objective may get sensitive information
of data owners or minimize utility of data.
Therefore, there exist various interactions between different par-
ticipants, including data owners, data collectors and adversaries.
Finally, it is inevitable that the interactions evolve into multiple
complicated games. In fact, there are a large number of researchers
to analyse these games between different participants.
3 PRELIMINARIES OF LOCATION PRIVACY
GAMES
In general, a data owner has multi-dimensional data. These dimen-
sions can be divided into three types. That is, identified attributes
distinguish the identity of a data owner. Sensitive dimensions are
private for data owners while the remaining ones are non-sensitive.
Here, we take trajectory information as an example. Assume that
the information consists of five attributes, i.e., name, sex, age, lo-
cation and time. Name is identified and location is sensitive. The
others are non-sensitive. When data owners offer or publish their
data, identified dimensions must be removed. However, it is far
from enough to prevent privacy leakage. Therefore, it needs vari-
ous preservation techniques to guarantee privacy.
3.1 Privacy Metrics
There are a lot of privacy metrics that have been proposed. As
illustrated in Section 2, the metrics can be divided into two types,
i.e., data clustering and theoretical framework. The former consists
BSCI Session 3  BSCI '20, October 6, 2020, Taipei, Taiwan
107
Figure 1: Game players for privacy attack and defence.
of anonymity, while the latter includes differential privacy and its
refinements. Here, we briefly introduce the main metrics.
3.1.1 Data Clustering. Techniques of data clustering are opera-
tional and practical. It consists of ğ‘˜-anonymity, â„“-diversity and
ğ‘¡-closeness and so on. Here, we take ğ‘˜-anonymity as an example.
The definition of ğ‘˜-anonymity is presented as follows.
Definition 3.1 (ğ‘˜-anonymity [36]). A mechanismM satisfies ğ‘˜-
anonymity if and only if after anonymization of dataset, each record
has at least ğ‘˜ âˆ’ 1 same records.
However, techniques of data clustering donâ€™t prevent privacy
leakage from attack of adversaries. Whatâ€™s more, they donâ€™t offer
the mathematical proof for privacy preservation.
3.1.2 Differential Privacy. Compared to data clustering, differential
privacy [9, 10] is a strong privacymetric, which is used in the central
setting.
Definition 3.2 (Differential Privacy [11]). A randomized mecha-
nism M satisfies ğœ–-differential privacy if and only if for any two
different datasetsğ·1 andğ·2 with only one different record, it needs
to satisfy for any output ğ‘‚ âˆˆ ğ‘…ğ‘ğ‘›ğ‘”ğ‘’ (M)
Pr[M(ğ·1) âˆˆ ğ‘‚] â‰¤ ğ‘’ğœ– Pr[M(ğ·2) âˆˆ ğ‘‚] (1)
in which ğœ– is privacy parameter.
3.1.3 Local Differential Privacy. Local differential privacy (LDP) is
an extended version of differential privacy, which is widely applied
in the local setting. It requires that each owner should perturb
his/her data before sending to the data collector. This ensures that
the data collector cannot distinguish the real data from the data
owner. The definition is presented as follows.
Definition 3.3 (Local Differential Privacy [8]). A randomizedmech-
anism M satisfies ğœ–-local differential privacy if and only if for any
two different value ğ‘‘ğ‘– and ğ‘‘ ğ‘— , it needs to satisfy for any output
ğ‘‚ âˆˆ ğ‘…ğ‘ğ‘›ğ‘”ğ‘’ (M)
Pr[M(ğ‘‘ğ‘– ) âˆˆ O] â‰¤ ğ‘’ğœ– Pr[M(ğ‘‘ ğ‘— ) âˆˆ O] (2)
in which ğœ– is privacy parameter.
3.2 Players
There are three main participants in attack and defence of location
privacy, including adversaries, data owners and data collectors. The
data owners are mobile users while the data collectors may be
service providers or non-profit organizations. Table 1 shows the key
roles and their relationship. The concrete description is presented
as follows:
â€¢ Data Owner. Each data owner has personal information
about health, trajectory and so on. However, leakage of pri-
vate information may bring a large amount of loss of reputa-
tion or money.
â€¢ Data Collector. In mobile network, service providers collect
and analyse data from hundreds of thousands of users (i.e.,
data owners). Meanwhile, they may be trusted or untrusted.
â€¢ Adversary. Adversaries always attempt to get sensitive in-
formation of data owners by illegal measures. The adver-
saries may be untrusted data collectors or hackers.
3.3 Classification of Privacy Games
According to different players, privacy games can be divided into
the following classes shown in Fig. 1:
â€¢ Game among data owners (OOG). In many scenes, each
data owner considers privacy protection and its cost. Mean-
while, the degree of privacy is influenced by not only himself
but also his neighbours. The correlation is changed to games
among data owners.
â€¢ Game between data owners and collector (OCG). There
are two basic interactions between data owners and collec-
tors. The first one is that data collectors receive data from
data owners and offer high-quality services. The second one
is that data owners sell their data and get monetary profit
from collectors. The interaction is to motive data owners to
report true location or preserve their privacy.
â€¢ Game between data owners and adversaries (OAG). Pri-
vacy of data owners is usually threatened by adversaries. It
is a competition of defence and attack between data own-
ers and adversaries. Unfortunately, untrusted data collectors
may be adversaries.
â€¢ Game Between data collectors and adversaries (CAG).
For a trusted data collector, he/she needs to protect data own-
ersâ€™ location information against attacks from adversaries.
For adversaries, their objective is to get private information
or minimize the utility of data.
There are multiple different game models used in the existing
works. Here, we introduce the classifications of non-cooperative
games shown in Fig. 2 and mechanism design.
â€¢ Non-CooperativeGames. In the games, each player makes
decision based on his/her own self-interest and doesnâ€™t co-
operate with others. In general, it can be divided to two
classes, i.e., games with incomplete (IG) and complete (CG)
information. The division is according to whether or not the
player knows othersâ€™ payoff function. CG has three cases, in-
cluding 2-player (2CG), ğ‘›-player (nCG) and zero-sum (ZCG)
games. IG has six types, including 2-player (2IG), ğ‘›-player
(nIG), one-shot (OIG), dynamic (DIG), zero-sum (ZIG) and
BSCI Session 3  BSCI '20, October 6, 2020, Taipei, Taiwan
108
Figure 2: Classifications of game models.
Stackelberg (SIG) games. In particular, one player (i.e., the
leader) first chooses the strategy and then all other players
(i.e., the follows) execute their strategies in SIG.
â€¢ Mechanism Design. Mechanism design (MD) is a set of
special game models to design a distributed protocol to im-
plement a particular objective for selfish participants. It al-
ways maximizes the overall payoff and motives agents to
report their true willingness.
4 ATTACK AND DEFENCE IN MOBILE
NETWORK
In the section, we introduce the basic threat models and privacy
preservation techniques.
4.1 Threat Model
In order to ensure the minimum guarantee of privacy, the data
owner generally removes his/her true identifier (e.g., name or ID)
and replaces it with any pseudonym, before the location is sent to
a data collector. Despite this, it also faces a certain amount of risks
of privacy leakage due to various attacks.
4.1.1 Location Identification. There is an adversary A with objec-
tive to identify location of data owners. By various legal or illegal
measures (e.g., eavesdropping or tracking), he/she has side informa-
tion that is true location of data owners. Since the data owner uses
pseudonym to hide his/her real identity, the adversaryA compares
side information with location sent by data owners to connect some
pseudonym with the true identity.
4.1.2 Trajectory Identification. While location identification is to
identify some location of a data owner, the purpose of trajectory
identification is to connect some pseudonym with the true identity
by comparing side information with trajectories from data owners.
In this attack, side information is a set of trajectories of data owners,
each of which is a combination of continuous locations.
4.2 Privacy Techniques
Both the degree of privacy and data utility for each data owner is
decided by privacy techniques. There are a large number of various
techniques that were proposed to ensure privacy. Here, we select
and list several important and efficient approaches, including mix
zones [3, 13], ğ‘˜-anonymity [1, 15].
4.2.1 Mix Zones. It is a simple and useful approach for each data
owner. In some regions called mix zones, each data owner considers
whether to change his/her pseudonym. For the threat of location
identification, it greatly decreases the probability of distinguishing
by the adversary. Meanwhile, it is inevitable to cause some cost
for data owners. For example, Freudiger et. al [13] pointed out that
the cost may be the delay on packets since the data owner cannot
communicate in silent mix zones or increase the communication
by a mobile proxy.
4.2.2 ğ‘˜-Anonymity. ğ‘˜-Anonymity is one of the most common pri-
vacy metrics. In mobile network, its objective is to have at least ğ‘˜âˆ’1
same records for a location or a trajectory. In general, the existing
methods can be divided into two types, including the centralized
and the distributed. For the former, there is a trusted third party to
generate dummy locations or trajectories, while for the latter each
data owner utilizes his/her own mobile devices to finish the same
task. Meanwhile, both of them cause a certain amount of delay and
energy overhead.
4.2.3 Cloaking. In general, cloaking directly perturbs spatial or
temporal dimensions of location information. Its main idea is to
add some noise or reduce the true data under no or little influence
on service quality. It is widely used to automotive traffic counts
and cartographic material and so on [6, 16]. In other words, the
technique can be applied to scenes that requires low accuracy but
high privacy.
5 PRIVACY GAME IN MOBILE NETWORK
Inmobile network, data owners offer their own location information
to data collectors so as to get high-quality service. However, location
is sensitive for data owners and cannot be leaked due to illegal
adversaries or untrusted data collectors. So, data owners needs
to balance between service quality and privacy leakage. Here, we
classify location privacy games in mobile network to the following
sections according to players, including OOG, OCG, OAG, CAG
and MD.
5.1 OOG
OOG is a set of privacy games, in which a large number of data own-
ers consider privacy and utility. The degree of someoneâ€™s privacy
is correlated to not only his/her own privacy preservation but also
that of others. However, it always brings the loss of service quality
due to inaccuracy of location or communication delay. Therefore,
each data owner has to consider various cases, including himself
and others.
For a game, there are three key components, including players,
strategy and payoff. For players in OOG, they are data owners. For
the others, we consider them according to different game types.
BSCI Session 3  BSCI '20, October 6, 2020, Taipei, Taiwan
109
Table 1: Strategy and Payoff of 2-players in OOG
ğ‘ƒ1 ğ‘£ğ‘ . ğ‘ƒ2 C D
C (ğ´1 âˆ’ ğ›¿ğ¶ğ¶1 , ğ´2 âˆ’ ğ›¿ğ¶ğ¶2 ) (ğ‘¢1 âˆ’ ğ›¿ğ¶ğ·1 , ğ‘¢2)
D (ğ‘¢1, ğ‘¢2 âˆ’ ğ›¿ğ·ğ¶2 , ) (ğ‘¢âˆ—1, ğ‘¢
âˆ—
2)
5.1.1 Non-cooperative Games. In a non-cooperative game, each
data owner just considers to maximize the profit according to
his/her own self-interest.
Pseudonym Change Game (PCG). In [12], it assumes that each
data owner must decide whether to leverage mix zones to protect
his/her location privacy.
Strategy. Each data owner has two strategies listed as follows:
â€¢ Cooperation (C). Once some data owner adopts this strat-
egy, he/she needs to change some pseudonym in multiple
times. Meanwhile, it causes a certain amount of cost, i.e.,
utility loss.
â€¢ Defection (D). The data owner does nothing without any
cost but faces risks of location identification.
Payoff. According to different strategies, each data owner has re-
spective payoff. Payoff is the most important and most complex
component in privacy games. Payoff of each data owner is influ-
enced by multiple factors. Here, we take a 2-player game as an
example shown in Table 1, in which ğ›¿ğ¶ğ¶1 = ğ›¿ğ¶ğ¶2 = ğ›¿ğ¶ğ·1 = ğ›¿ğ·ğ¶2 = ğ›¿ .
It is easy to see that the payoff of a data owner is decided by ini-
tial utility and privacy cost. In detail, ğ‘¢ğ‘– = ğ´ğ‘– âˆ’ ğ›¿ âˆ’ ğ›½ğ‘– âˆ’ ğ›¿ Â· ğ›¼ğ‘– . ğ´ğ‘–
is evaluated by information entropy. ğ›¿ is the cost, including new
pseudonyms, updating routing tables and remaining silent. ğ›½ is
a location privacy loss function. ğ›¼ is the number of pseudonyms
wasted.
Equilibrium Analysis. According to whether the players know
the payoff type of the others, the authors considered two models,
including complete information game and incomplete informa-
tion game. In the former, there is at least one and at most two
pure-strategy Nash equilibrium for ğ‘›-player game, including all
detection strategy. In the latter, it derives the existence of Bayesian
Nash equilibrium for 2-play game. Meanwhile, the cost of changing
pseudonym and the number of players influence the achievement
of high location privacy.
External C-Game for Privacy (ECG). In [37], it analyses the coor-
dination of pseudonym changes for vehicles to protect privacy by
mix zones in vehicular networks.
Strategy. Similar to PCG, each player has two strategies, i.e., C and
D.
Payoff. For each vehicle, his/her payoff is the degree of privacy
protection.
Equilibrium Analysis. It constructs a static game with complete
information. By simple computation and derivation, they get the
number of vehicles in Nash Equilibrium that want to change their
name.
Dummy User Generation Game (DUGG). In [24], each data owner
utilizes ğ‘˜-anonymity to prevent privacy leakage from trajectory
identification.
Strategy. Similar to PCG, each data owner in DUGG has two strate-
gies, i.e., C and D. For strategy C, the player should use his/her
mobile devices to generate ğ‘˜ âˆ’ 1 dummy trajectories.
Payoff. If none of players choose strategy C, the payoff of all play-
ers is 0. For other cases, if some player chooses strategy C, it causes
a certain amount of loss. We also take an example of Table 1. That is,
ğ‘¢âˆ—1 = ğ‘¢âˆ—2 = 0, ğ›¿ğ¶ğ¶1 = ğ›¿ğ¶ğ¶2 = ğ›¿ğ·ğ¶1 = ğ›¿ğ¶ğ·2 = ğ›¿ , ğ´1 = ğ‘¢1 and ğ´2 = ğ‘¢2.
Equilibrium Analysis. The authors construct a incomplete infor-
mation game, in which each player only has his/her own payoff and
doesnâ€™t know that of others. They also demonstrate that there are
multiple pure Nash equilibria that only one player chooses strategy
C and the others choose strategy D.
Trajectory Privacy Preservation Game (TPPG). In [19], it mainly
analyses the actions of selfish and compromised data owner in
mobile Wireless Sensor Networks (mWSNs).
Strategy. In addition to strategy C and D, it adds a new strategy
â€˜Attack (A)â€™ for each data owner. That is, the data owner may attack
his/her neighbours to get illegal profit.
Payoff. Each data owner may be selfish or malicious. When he/she
is selfish, the payoff is the same as that in DUGG. However, if the
neighbour of some player is malicious, his/her initial payoff is âˆ’ğ‘¢ğ‘– .
That is, his/her partition doesnâ€™t get any profit, but brings some
loss.
Equilibrium Analysis. The authors consider equilibrium analy-
sis for Bayesian games. In a static game, there is a pure-strategy
Bayesian Nash equilibrium if the non-malicious level is greater
than some value. In a dynamic game, there is at least one perfect
Bayesian Nash equilibrium.
Collaborative Location Privacy Game (CLPG). In [33], it assumes
that mobile users donâ€™t seek geographic information from the ser-
vice provider, but get them from the neighbour users. If so, the user
has no risk of privacy leakage. The authors investigate whether or
not the overall level of cooperation among users is sufficient by
game theory.
Strategy. Similar to PCG and DUGG, each data owner has two
strategies, i.e., C and D. That is, the condition of the data owner to
execute C is that his/her cumulative cooperation effect exceeds a
threshold, which is the number of sharing users.
Payoff. When someone requests location, his/her payoff is just like
Table 1, in which ğ‘¢âˆ—1 = ğ‘¢âˆ—2 = 0, ğ›¿ğ‘– is the cost of communication or
the cost of requesting to service provider, ğ‘¢ğ‘– and ğ´ğ‘– are the utility.
Equilibrium Analysis. The authors proved the existence of Nash
equilibrium for 2-player and multiple-player games. The results
show that rational data owners will attempt to maximize their
utility by sharing data.
5.1.2 Mechanism Design. In mobile network especially of mobile
crowdsourcing, there is a third party (e.g., data collector) to collect
location information of users. To make up their loss of privacy, the
third party should give a certain amount of compensation. The
challenge is how to motive data owners to honestly report their
cost.
There are two different cases in terms of the degree of privacy.
The first one is that all of data owners have the same privacy degree,
while the second one is that different data owners have different
degrees of privacy. For example, some data owner doesnâ€™t care
BSCI Session 3  BSCI '20, October 6, 2020, Taipei, Taiwan
110
about leakage of his/her location information. Zhang et al. [45] pro-
posed auction-based mechanisms to solve the latter, which greatly
adds the number of data owners willing to protect privacy by ğ‘˜-
anonymity. Yang et al. [42] proposed two different auction-based
mechanisms (i.e., KASD and KADD) to solve the cases, respectively.
All of the above approaches needs a trusted third party to execute
auction. In the case of no third party, Wu et al. [39] constructed
a setting in which data owner generates dummy trajectories to
overcome trajectory identification and get the payment from the
others. Based on auction protocols, they proposed a cost sharing
mechanism to incentive users to report their true cost and ensure
the effective degree of privacy for all data owners.
5.2 OCG
The players in OCG are data owners and collectors. The latter offer
location-based services or monetary profit according to location
information of the former. Here, the challenge is how to motive the
former to report more accurate location.
5.2.1 Non-Cooperative Game.
Privacy Game between Owners and Collectors (PGOC). In [5],
it mainly considers how to motive data owners to report more
accurate location with proper profit.
Strategy. For data owners, their strategy is to adjust location ac-
curacy evaluated by information entropy. For data collectors, their
strategy is to design the proper incentive measures.
Payoff. For data owners, their payoff is profit from data collectors
minus privacy risk. For data collectors, their payoff is location value
minus its cost.
Equilibrium Analysis. The authors introduce the idea of mecha-
nism design and take data collectors as a designer whose objective
is to improve the accuracy of location information from data own-
ers. They attempt to converge Nash equilibrium as a desirable point.
Therefore, they propose iterative distributed algorithm and regres-
sion learning methods to solve the problem.
5.2.2 Mechanism Design. Li et al. [21] consider taxi allocation
and location privacy of passengers in online taxi-hailing systems.
They first propose a Vickrey-Clarke-Groves (VCG)-based auction
protocol to select the winner of passengers. Then, an exponential
differential privacy mechanism is presented to protect passengersâ€™
privacy and allocate the winner to the taxi.
5.3 OAG
In OAG, the players are data owners and adversaries. The data
owners may be users to enjoy some location-based services.
5.3.1 Non-cooperative Games.
Stochastic Game between Users and Adversaries (SGUA). Wang
et al. [38] discuss location-based services, in which users (i.e., data
owners) offer their personal data to the service providers and face
risks of privacy leakage from global adversaries.
Strategy. In SGUA, strategy of data owners is to control the re-
leased data granularity of each sensor via the privacy-preserving
middleware. Strategy of adversaries is to select a proper subset of
sensing data for retrieval.
Table 2: Strategy and Payoff of 2-players in OAG
ğ‘‚ ğ‘£ğ‘ . A E T
P (_ğ‘‚ âˆ’ ğ‘ğ‘ , _ğ´ âˆ’ ğ‘ğ‘  ) (_ğ‘‚ âˆ’ ğ‘ğ‘ , 0)
T (0, _ğ´ âˆ’ ğ‘ğ‘  ) (0, 0)
Payoff. Payoff of data owners is decided by the quality of service
ğ‘„ and weight penalty ğ¿ on privacy loss, i.e., ğ‘„ âˆ’ğ‘¤ Â· ğ¿, while the
objective of adversaries is to minimize the utility of data owners. In
detail, ğ‘„ is expressed as usersâ€™ degree of satisfaction with service
and ğ¿ is evaluated by context privacy.
Equilibrium Analysis. The authors model a zero-sum stochastic
game between users and adversaries. Then, The existence of Nash
equilibrium with maximizing usersâ€™ utility is changed as a unique
minimax equilibrium problem. They solve it by a minimax learning
algorithm.
Game between Users andAdversaries (GUA). Different from SGUA,
GUA [18] assumes that there is a local adversary with a limited
budget to eavesdrop on communications in only certain regions of
mobile network.
Strategy. Different players have different strategies. For adver-
saries, the strategy is listed as follows:
â€¢ Eavesdrop (E). The adversary eavesdrops on communica-
tions to get private information of data owners. Meanwhile,
the strategy needs a certain amount of cost to deploy his/her
devices or applications.
â€¢ Abstrain (T). The adversary does nothing.
Faced with possible attack, the strategy of data owners is listed as
follows:
â€¢ Protection (P). The data owner adopts mix zones with a
certain amount of cost to prevent his/her data from leakage.
â€¢ Abstain (T). The data owner does noting.
Payoff. The payoff of data owners and adversaries is shown in
Table 2. When both data owners and adversaries have operations,
their initial utilities are _ğ‘‚ and _ğ´ , respectively. In addition, the
cost for mix zones is ğ‘ğ‘ while that of eavesdropping is ğ‘ğ‘  .
Equilibrium Analysis. The authors construct two games with
complete and incomplete information according to whether or not
data ownersâ€™ know about the adversaryâ€™s payoff and strategy. In a
complete information game, there is a single Nash equilibrium (i.e.,
(P, T) or (T, T)), which is computed by they proposed algorithm.
Meanwhile, they shows that strategies in NE highly depend on the
traffic profiles. In an incomplete information game, there is at least
one pure Bayesian Nash equilibrium, including (P, T), (T, T) and (T,
E).
Attack and Defense Game (ADG). In [17], it analyses the interac-
tion between vehicles (e.g., drivers or passengers) and adversaries
in Vehicular Sensor Networks.
Strategy. There are two different adversaries, including passive
and active ones. The difference is that passive adversaries donâ€™t
actively track users and thus get noisy data. Therefore, for passive
adversaries, their strategy is to perform Bayesian inference or use
the maximum likelihood estimation to get the best estimation. For
BSCI Session 3  BSCI '20, October 6, 2020, Taipei, Taiwan
111
active adversaries, they directly compare their side information
with usersâ€™ true data to get the desirable estimations. For users,
they adopt cloaking technique to protect their privacy. That is,
they have two types of defence strategies, including inserting some
bogus traces or deleting data.
Payoff. The payoff of both data owners and adversaries is the
degree of privacy minus attack/defence cost. In order to maximize
attack, they assume that the attack cost is zero.
Equilibrium Analysis. The authors construct games with com-
plete (CG) and incomplete (IG) information. They analyze NE and
BNE for CG and IG by experiments, respectively. If adversaries are
passive, the strategy of users in NE depends on the value of the
cost of privacy preservation in CG and IG. If adversaries are active,
the optimal defence strategies depend on system parameters.
5.3.2 Stackelberg Game.
Zero-Sum Stackelberg Game between Users and Adversaries (ZS-
GUA). In [34, 35], the authors analyse optimal strategies for data
owners against attacks from adversaries.
Strategy. In Stackelberg game, the data owner is a leader, while
the adversary is a follower. At first, the data owner finds his/her
owner location by mobile devices and then chooses a pseudoloca-
tion by a private mechanism under the constraint of service quality.
Next, according to data ownersâ€™ perturbed location, the adversary
estimates a location for the data owner.
Payoff. The payoff of data owners is to maximize his/her condi-
tional expected privacy, while the objective of the adversary is to
minimize.
EquilibriumAnalysis. The authors construct a zero-sumBayesian
Stackelberg game with incomplete information. They change the
Bayesian Nash equilibrium to two linear programs for data owners
Table 3: Problems Solved by Location Privacy Games
Class SPM SPP SSA
Freudiger et al. [12] OOG âœ— âœ” âœ—
Wang et al.[37] OOG âœ— âœ” âœ—
Liu et al. [24] OOG âœ— âœ” âœ—
Jin et al. [19] OOG âœ— âœ” âœ—
Santos et al. [33] OOG âœ— âœ” âœ—
Wang et al. [38] OAG âœ— âœ” âœ”
Humbert et al. [18] OAG âœ— âœ” âœ”
He et al. [17] OAG âœ” âœ” âœ”
Shokri et al. [34, 35] OAG âœ— âœ” âœ”
Chorppath et al. [5] OCG âœ— âœ” âœ—
Ying et al. [43] CAG âœ— âœ” âœ”
Zhang et al. [45] OOG âœ— âœ” âœ—
Yang et al. [42] OOG âœ— âœ” âœ—
Wu et al. [39] OOG âœ— âœ” âœ—
Li et al. [21] OCG âœ— âœ” âœ—
Figure 3: Classifications of location privacy games.
and adversaries, respectively. Each participant only considers to
solve the linear program.
5.4 CAG
In CAG, there is an interaction between data collectors and adver-
saries. Assume that data collectors are trusted with objective to
prevent privacy leakage of data owners from attacks of adversaries.
5.4.1 Non-Cooperative Game.
Hide-and-Seek Game (HSG). In [43], it mainly considers location
privacy preservation in mobile social networks. There is a trusted
third party (i.e., data collector) to execute request aggregation from
mobile users (i.e., data owners).
Strategy. For the third party, it should response the request from
users that satisfy ğ‘-destination. That is, the number of usersâ€™ request
with perturbed location is greater than ğ‘ . The strategies in CAG
is similar to those in OAG. In other words, each third party also
two strategies P and T, while each adversary has E and T. Here, P
represents the aggregation of requests, while E is to track users.
Payoff. The payoff of the adversary is to get howmuch information
of a specified user with a certain amount of cost. The payoff of the
third party is the gain of usersâ€™ privacy with query processing cost.
Its payoff matrix is very similar to Table 2.
Equilibrium Analysis. The authors construct a game with com-
plete information. They prove that the game has no pure Nash
equilibrium, but has one mixed-strategy Nash equilibrium.
BSCI Session 3  BSCI '20, October 6, 2020, Taipei, Taiwan
112
Table 4: Brief Description of Location Privacy Games
Game Model Problem Formulation Equilibrium Analysis Protection Technique
Freudiger et al. [12] non-cooperative
game
games with complete information (CG) and in-
complete information (IG), in which each data
owner tries to maximize his/her privacy at a
minimum cost
NE for CG; BNE for
IG
mix zones
Wang et al.[37] non-cooperative
game
complete information game in which each ve-
hicle attempts to maximize his/her degree of
privacy in vehicular networks
NE mix zones
Liu et al. [24] non-cooperative
game
incomplete information game, in which each
player attempts to maximize payoff and protect
trajectory
BNE ğ‘˜-anonymity
Jin et al. [19] non-cooperative
game
incomplete information Bayesian game (IBG),
in which each player is selfish or malicious to
maximize expected payoff
BNE for the static
IBG; perfect BNE for
the dynamic IBG
-
Santos et al. [33] non-cooperative
game
incomplete information game in which each
player considers whether to cooperate and at-
tempts to maximize his/her utility
BNE -
Wang et al. [38] non-cooperative
game
zero-sum stochastic game inwhich data owners
maximizes their utility and a global adversary
minimizes it
a unique NE changed
to a minimax equilib-
rium problem
-
Humbert et al. [18] non-cooperative
game
games with complete and incomplete informa-
tion in which each player (i.e., data owners or
adversaries) attempts to maximize their utility
NE for CG; BNE for
IG
mix-zones for data
owners
He et al. [17] non-cooperative
game
games with complete and incomplete informa-
tion in which users attempt to maximize their
privacy and passive/active adversaries to mini-
mize it
NE for CG; BNE for
IG
cloaking
Shokri et al. [34, 35] Stackelberg
Bayesian games
a zero-sum Stackelberg game between data
owners and adversaries, in which the objective
of the former optimize service quality under
privacy guarantee and the latter attempt to get
private information
BNE changed to lin-
ear program
ğ‘˜-anonymity/mix
zones/cloaking
Chorppath et al. [5] non-cooperative
game
how to motive data owners to report their accu-
rate location with proper profits and take Nash
equilibrium as a desirable point
NE -
Ying et al. [43] non-cooperative
game
a game with complete information between
a trusted third party (i.e., data collector) and
adversaries. The former is to guarantee high-
quality service with privacy preservation for
users (i.e., data owners).
NE ğ‘-destination
Zhang et al. [45] mechanism
design
a problem how to design proper mechanisms
to incentive data owners that are not willing to
protect privacy
auction-based truth-
ful mechanisms
ğ‘˜-anonymity
Yang et al. [42] mechanism
design
how to incentivize data users to honestly report
their cost of privacy
KASD & KADD ğ‘˜-anonymity
Wu et al. [39] mechanism
design
a cost-sharing problem in which data owner
generates dummy trajectories and get payment
auction with incen-
tive compatibility
and budget balance
ğ‘˜-anonymity
Li et al. [21] mechanism
design
how to protect passengersâ€™ location privacy and
properly allocate passengers to taxies in online
taxi services
a VCG-based mecha-
nism for passengers
differential privacy
BSCI Session 3  BSCI '20, October 6, 2020, Taipei, Taiwan
113
6 DISCUSSION AND FUTURE RESEARCH
DIRECTIONS
Here, we first conclude the existing works about location privacy
games and then present possible problems and challenges in the
future.
6.1 Discussion of The Existing Works
As illustrated in Section 1, the key problems concerned by adver-
saries, data owners and collectors are SPM, SPP and SSA. Table 3
lists the problems solved by the existing location privacy games.
It is obvious to find that SPP is the most fundamental problem
while SPM receives little attention. In addition, the most of location
privacy games focus on OOG while little focus is on CAG. There
are two main reasons to explain the phenomenon. The first one
is that in the context of in mobile network it generally assumes
that service providers are untrusted and each data owner needs to
consider his/her own location privacy. The second one is that there
are a few works to motive data owners to protect their location pri-
vacy. In summary, each mobile user is viewed as the most important
defender. This is the biggest difference from privacy-preserving
data publishing (PPDP) [14] and privacy-preserving data mining
(PPDM) [2].
Table 4 presents a brief description of location privacy games.
The most of privacy games are non-cooperative while the others
utilizes mechanism design. In the literatures based on mechanism
design, all of them use auction mechanisms to motive data owners
to report their true privacy cost or execute operations to protect
their location privacy. For works based on non-cooperative games,
the most of them are to analyse the existence of pure and/or mixed
(Bayesian) Nash equilibrium. In addition, there are a small part
of works to analyse NE or BNE by experiments. The most used
techniques are mix zones and ğ‘˜-anonymity. In contrast, differential
privacy is less leveraged. This is because that differential privacy is
generally used in the central setting, which is not suited to mobile
network. This is also different from PPDP and PPDM, the most of
which utilize differential privacy.
Fig. 3 introduces game model used by location privacy games.
It is easy to find that nCG, nIG and DIG are the most common. In
detail, the most of privacy games in OOG are based on games with
incomplete information. The main reason is that some data owner
in mobile network canâ€™t know the payoff of the others. Different
from OOG, the games in OAG are based on both CG and IG. Despite
this, we still think games with incomplete information are more
realistic. In besides, there are little works about OCG and CAG,
which we donâ€™t analyse.
6.2 Future Research Directions
After analysis of the existingworks, we give some possible problems
and challenges as future research directions.
6.2.1 Games with Local Differential Privacy. Recently, local differ-
ential privacy (LDP) has been proposed as a novel privacy metric
in the local setting. It has been widely applied to heavy hitters iden-
tification, itemset mining, marginal release and graph data mining
[23]. Different from ğ‘˜-anonymity, LDP provides a strong privacy
preservation for mobile network.
However, to the best of our knowledge, there are few works to
construct a game model with LDP in the previous works. Therefore,
there are two possible directions worthy of study. The first one is
to implement new privacy protection techniques that satisfy LDP,
especially for mobile location data. The second one is to construct
the models of location privacy game with LDP. Since LDP provides
a strong privacy guarantee, privacy parameter is a key factor that
influences the interactions of data owners with others. Thus, how
to set up the proper privacy parameter for data owners in various
interactions is a research direction.
6.2.2 Games for Selection of Private Mechanisms. At present, there
are little attention to games for selection of private mechanisms. In
fact, it is key and important to select a proper mechanism to defend
the attack. More importantly, the selection of private mechanisms of
data owners has influences on both adversaries and data collectors.
For service providers, data utility or accuracy is correlated to the
selection of private mechanisms. On the other hand, for adversaries,
it may increase the hardness of attack.
Unfortunately, it is difficult to construct the game among ad-
versaries, data owners and collectors about various private mecha-
nisms. The reason is that there is not a framework to analyse and
compare the existing private mechanisms, especially for data clus-
tering and differential privacy. Therefore, how to design a proper
platform to aggregate the existing private mechanisms into a math-
ematical model is challenging.
6.2.3 Games for OCG. In mobile network, the most of works as-
sume that service providers (i.e., data collectors) are untrusted,
which is fully different from PPDP and PPDM. This implies that
there are more and more interactions between mobile users (i.e.,
data owners) and untrusted collectors. However, there are few lit-
eratures to research it.
The challenge for users is to consider the balance between service
quality and location privacy. In addition, it is hard for users to
distinguish the credibility of service providers. This is up to their
confidence for service providers. Analysing the interaction between
data owners and collectors helps to improve the degree of privacy
and reduce the cost. On the other hand, for data collectors, their
service quality and value of information are up to perturbed data
from users. Thus, it is important to construct and analyse the game
between data owners and collectors about active preservation and
trust.
6.2.4 Diverse Game Models for Location Privacy . The most of
models used in the existing location privacy games are nCG, nIG
and OIG. Relatively speaking, there are few types of models. The
reason is that it is challenging to apply the existing game models
to location privacy problems.
In fact, it is still possible to make full use of diverse game models
to analyse location privacy, especially of dynamic Bayesian games
with incomplete information. Therefore, it is a challenging future
direction.
To the best of our knowledge, we think the solutions to the above
challenges and problems are up to the development of location
privacy metrics and techniques in terms of theory and applications.
Meanwhile, it is also important how to utilize these metrics and
BSCI Session 3  BSCI '20, October 6, 2020, Taipei, Taiwan
114
techniques to construct location privacy models and analyse the
interactions.
7 CONCLUSIONS
In this survey, we have comprehensively presented the recent game-
theoretic works about mobile location privacy. We have demon-
strated the necessity and given a taxonomy of location privacy
games among adversaries, data owners and collectors. We have
surveyed and concluded game models and equilibrium analysis in
mobile location privacy. We have presented a certain number of
literatures based on mechanism design to motive users to improve
location privacy. Our object is to help readers to understand the
existing works and the possible future directions.
ACKNOWLEDGMENTS
Our thanks to the reviewers for their constructive comments and
suggestions to improve the quality of the manuscript. This research
was partially supported by the National Key Research and Devel-
opment Program of China (No. 2017YFB1400600).
REFERENCES
[1] Osman Abul, Francesco Bonchi, and Mirco Nanni. 2008. Never Walk Alone:
Uncertainty for Anonymity in Moving Objects Databases. In Proceedings of the
24th International Conference on Data Engineering, ICDE. IEEE, 376â€“385.
[2] Charu C. Aggarwal and Philip S. Yu. 2008. Privacy-Preserving Data Mining: A
Survey. In Handbook of Database Security - Applications and Trends. Springer,
431â€“460.
[3] Alastair R. Beresford and Frank Stajano. 2004. Mix Zones: User Privacy in
Location-aware Services. In Proceedings of Conference on Pervasive Computing
and Communications Workshops, PerCom. IEEE, 127â€“131.
[4] David Bernhard, VÃ©ronique Cortier, David Galindo, Olivier Pereira, and Bogdan
Warinschi. 2015. SoK: A Comprehensive Analysis of Game-Based Ballot Privacy
Definitions. In Proceedings of Symposium on Security and Privacy, SP. IEEE, 499â€“
516.
[5] Anil Kumar Chorppath and Tansu Alpcan. 2013. Trading privacy with incentives
in mobile commerce: A game theoretic approach. Pervasive Mob. Comput. 9, 4
(2013), 598â€“612.
[6] Chi-Yin Chow, Mohamed F. Mokbel, and Xuan Liu. 2006. A peer-to-peer spatial
cloaking algorithm for anonymous location-based service. In Proceedings of 14th
International Symposium on Geographic Information Systems, GIS. ACM, 171â€“178.
[7] Cuong T. Do, Nguyen H. Tran, Choong Seon Hong, Charles A. Kamhoua, Kevin A.
Kwiat, Erik Blasch, Shaolei Ren, Niki Pissinou, and Sundaraja Sitharama Iyengar.
2017. Game Theory for Cyber Security and Privacy. ACM Comput. Surv. 50, 2
(2017), 30:1â€“30:37.
[8] John C. Duchi, Michael I. Jordan, and Martin J. Wainwright. 2013. Local Privacy
and Statistical Minimax Rates. In Proceedings of 54th Annual Symposium on
Foundations of Computer Science, FOCS. IEEE, 429â€“438.
[9] Cynthia Dwork. 2008. Differential Privacy: A Survey of Results. In Proceedings of
International Conference on Theory and Applications of Models of Computation,
TAMC, Vol. 4978. Springer, 1â€“19.
[10] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam D. Smith. 2006. Cal-
ibrating Noise to Sensitivity in Private Data Analysis. In Proceedings of Third
Theory of Cryptography Conference, TCC, Vol. 3876. Springer, 265â€“284.
[11] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam D. Smith. 2016. Cali-
brating Noise to Sensitivity in Private Data Analysis. J. Priv. Confidentiality 7, 3
(2016), 17â€“51.
[12] Julien Freudiger, Mohammad Hossein Manshaei, Jean-Pierre Hubaux, and
David C. Parkes. 2009. On non-cooperative location privacy: a game-theoretic
analysis. In Proceedings of the Conference on Computer and Communications
Security, CCS. ACM, 324â€“337.
[13] Julien Freudiger, Reza Shokri, and Jean-Pierre Hubaux. 2009. On the Optimal
Placement of Mix Zones. In Proceedingsof Privacy Enhancing Technologies, 9th
International Symposium, PETS, Vol. 5672. Springer, 216â€“234.
[14] Benjamin C. M. Fung, Ke Wang, Rui Chen, and Philip S. Yu. 2010. Privacy-
preserving data publishing: A survey of recent developments. ACM Comput.
Surv. 42, 4 (2010), 14:1â€“14:53.
[15] Bugra Gedik and Ling Liu. 2008. Protecting Location Privacy with Personalized
k-Anonymity: Architecture and Algorithms. IEEE Trans. Mob. Comput. 7, 1 (2008),
1â€“18.
[16] Marco Gruteser and Dirk Grunwald. 2003. Anonymous Usage of Location-Based
Services Through Spatial and Temporal Cloaking. In Proceedings of the First
International Conference on Mobile Systems, Applications, and Services. USENIX.
[17] Yunhua He, Limin Sun, Weidong Yang, and Hong Li. 2014. A Game Theory-Based
Analysis of Data Privacy in Vehicular Sensor Networks. IJDSN 10 (2014).
[18] Mathias Humbert, Mohammad Hossein Manshaei, Julien Freudiger, and Jean-
Pierre Hubaux. 2010. Tracking Games in Mobile Networks. In Proceedings of
International Conference on Decision and Game Theory for Security - First, GameSec,
Vol. 6442. Springer, 38â€“57.
[19] Xinyu Jin, Niki Pissinou, Sitthapon Pumpichet, Charles A. Kamhoua, and Kevin A.
Kwiat. 2013. Modeling cooperative, selfish and malicious behaviors for Trajectory
Privacy Preservation using Bayesian game theory. In Proceedings of 38th Annual
Conference on Local Computer Networks. IEEE, 835â€“842.
[20] Daniel Kifer and Ashwin Machanavajjhala. 2011. No free lunch in data privacy.
In Proceedings of the SIGMOD International Conference on Management of Data,
SIGMOD. ACM, 193â€“204.
[21] Donghe Li, Qingyu Yang, Wei Yu, Dou An, and Xinwen Fu. 2018. Towards
Incentive Mechanism for Taxi Services Allocation with Privacy Guarantee. In
Proceedings of 37th IEEE International Performance Computing and Communica-
tions Conference, IPCCC. IEEE, 1â€“8.
[22] Ninghui Li, Tiancheng Li, and Suresh Venkatasubramanian. 2007. t-Closeness: Pri-
vacy Beyond k-Anonymity and l-Diversity. In Proceedings of the 23rd International
Conference on Data Engineering, ICDE. IEEE, 106â€“115.
[23] Ninghui Li and Qingqing Ye. 2019. Mobile Data Collection and Analysis with
Local Differential Privacy. In Proceedings of 20th International Conference on
Mobile Data Management, MDM. IEEE, 4â€“7.
[24] Xinxin Liu, Kaikai Liu, Linke Guo, Xiaolin Li, and Yuguang Fang. 2013. A game-
theoretic approach for achieving k-anonymity in Location Based Services. In
Proceedings of the INFOCOM. IEEE, 2985â€“2993.
[25] Ashwin Machanavajjhala, Johannes Gehrke, Daniel Kifer, and Muthuramakrish-
nan Venkitasubramaniam. 2006. l-Diversity: Privacy Beyond k-Anonymity. In
Proceedings of the 22nd International Conference on Data Engineering, ICDE. IEEE,
24.
[26] Mohammad Hossein Manshaei, Quanyan Zhu, Tansu Alpcan, Tamer Basar, and
Jean-Pierre Hubaux. 2013. Game theory meets network security and privacy.
ACM Comput. Surv. 45, 3 (2013), 25:1â€“25:39.
[27] Noam Nisan and Amir Ronen. 1999. Algorithmic Mechanism Design (Extended
Abstract). In Proceedings of the Thirty-First Annual Symposium on Theory of
Computing. ACM, 129â€“140.
[28] M. J. Osborne and A. Rubinstein. 1994. A course in game theory. (1994).
[29] Jeffrey Pawlick, Edward Colbert, and Quanyan Zhu. 2019. A Game-theoretic
Taxonomy and Survey of Defensive Deception for Cybersecurity and Privacy.
ACM Comput. Surv. 52, 4 (2019), 82:1â€“82:28.
[30] Lianyong Qi, Haolong Xiang, Wanchun Dou, Chi Yang, Yongrui Qin, and Xuyun
Zhang. 2017. Privacy-Preserving Distributed Service Recommendation Based
on Locality-Sensitive Hashing. In Proceedings of International Conference on Web
Services, ICWS. IEEE, 49â€“56.
[31] Lianyong Qi, Rutao Yang, Wenmin Lin, Xuyun Zhang, Wanchun Dou, and Jinjun
Chen. 2010. A QoS-aware Web Service Selection Method Based on Credibil-
ity Evaluation. In Proceedings of International Conference on High Performance
Computing and Communications, HPCC. IEEE, 471â€“476.
[32] Tim Roughgarden. 2010. Algorithmic game theory. Commun. ACM 53, 7 (2010),
78â€“86.
[33] Francisco Santos, Mathias Humbert, Reza Shokri, and Jean-Pierre Hubaux. 2011.
Collaborative Location Privacywith Rational Users. In Proceedings of International
Conference on Decision and Game Theory for Security, GameSec, Vol. 7037. Springer,
163â€“181.
[34] Reza Shokri, George Theodorakopoulos, and Carmela Troncoso. 2017. Privacy
Games Along Location Traces: A Game-Theoretic Framework for Optimizing
Location Privacy. ACM Trans. Priv. Secur. 19, 4 (2017), 11:1â€“11:31.
[35] Reza Shokri, George Theodorakopoulos, Carmela Troncoso, Jean-Pierre Hubaux,
and Jean-Yves Le Boudec. 2012. Protecting location privacy: optimal strategy
against localization attacks. In Proceedings of the Conference on Computer and
Communications Security, CCS. ACM, 617â€“627.
[36] Latanya Sweeney. 2002. k-Anonymity: A Model for Protecting Privacy. Interna-
tional Journal of Uncertainty, Fuzziness and Knowledge-Based Systems 10, 5 (2002),
557â€“570.
[37] Jian Wang, Nan He, Fang Mei, Daxin Tian, and Yuming Ge. 2019. Optimization
and non-cooperative game of anonymity updating in vehicular networks. Ad
Hoc Networks 88 (2019), 81â€“97.
[38] Wei Wang and Qian Zhang. 2014. A stochastic game for privacy preserving
context sensing on mobile phone. In Proceedings of Conference on Computer
Communications, INFOCOM 2014. IEEE, 2328â€“2336.
[39] Xiaotong Wu, Shu Li, Jun Yang, and Wanchun Dou. 2017. A cost sharing mecha-
nism for location privacy preservation in big trajectory data. In Proceedings of
International Conference on Communications, ICC. IEEE, 1â€“6.
BSCI Session 3  BSCI '20, October 6, 2020, Taipei, Taiwan
115
[40] Xiaolong Xu, Qingxiang Liu, Xuyun Zhang, Jie Zhang, LianyongQi, andWanchun
Dou. 2019. A Blockchain-Powered Crowdsourcing Method With Privacy Preser-
vation in Mobile Environment. IEEE Trans. Comput. Social Systems 6, 6 (2019),
1407â€“1419.
[41] Xiaolong Xu, Xuyun Zhang, Honghao Gao, Yuan Xue, Lianyong Qi, andWanchun
Dou. 2020. BeCome: Blockchain-Enabled Computation Offloading for IoT in
Mobile Edge Computing. IEEE Transactions on Industrial Informatics 16, 6 (2020),
4187â€“4195.
[42] Dejun Yang, Xi Fang, and Guoliang Xue. 2013. Truthful incentive mechanisms for
k-anonymity location privacy. In Proceedings of the INFOCOM. IEEE, 2994â€“3002.
[43] Bidi Ying and Amiya Nayak. 2017. Location privacy-protection based on p-
destination in mobile social networks: A game theory analysis. In Proceedings of
Conference on Dependable and Secure Computing, DSC 2017. IEEE, 243â€“250.
[44] Shui Yu. 2016. Big Privacy: Challenges and Opportunities of Privacy Study in
the Age of Big Data. IEEE Access 4 (2016), 2751â€“2763.
[45] Yuan Zhang, Wei Tong, and Sheng Zhong. 2016. On Designing Satisfaction-Ratio-
Aware Truthful Incentive Mechanisms for k-Anonymity Location Privacy. IEEE
Trans. Information Forensics and Security 11, 11 (2016), 2528â€“2541.
BSCI Session 3  BSCI '20, October 6, 2020, Taipei, Taiwan
116
	Abstract
	1 Introduction
	2 The Necessity of Privacy Game
	3 Preliminaries of Location Privacy Games
	3.1 Privacy Metrics
	3.2 Players
	3.3 Classification of Privacy Games
	4 Attack and Defence in Mobile Network
	4.1 Threat Model
	4.2 Privacy Techniques
	5 Privacy Game in Mobile Network
	5.1 OOG
	5.2 OCG
	5.3 OAG
	5.4 CAG
	6 Discussion and Future Research Directions
	6.1 Discussion of The Existing Works
	6.2 Future Research Directions
	7 Conclusions
	Acknowledgments
	References