A Blockchain-Based Non-Invasive Cyber-Physical Occupational Therapy Framework: BCI Perspective
SPECIAL SECTION ON NEW TRENDS IN BRAIN
SIGNAL PROCESSING AND ANALYSIS
Received February 12, 2019, accepted February 25, 2019, date of publication March 5, 2019, date of current version April 1, 2019.
Digital Object Identifier 10.1109/ACCESS.2019.2903024
A Blockchain-Based Non-Invasive Cyber-
Physical Occupational Therapy
Framework: BCI Perspective
MD. ABDUR RAHMAN 1, (Senior Member, IEEE),
M. SHAMIM HOSSAIN 2, (Senior Member, IEEE),
MD. MAMUNUR RASHID2, (Member, IEEE),
STUART J. BARNES 3, MOHAMMED F. ALHAMID2, (Senior Member, IEEE),
AND MOHSEN GUIZANI 4, (Fellow, IEEE)
1Department of Cyber Security and Forensic Computing, University of Prince Mugrin, Madinah 41499, Saudi Arabia
2Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh 11543, Saudi Arabia
3Consumer and Organizational Digital Analytics (CODA) Research Centre, King’s Business School, King’s College London, London WC2R 2LS, U.K.
4Department of Electrical and Computer Engineering, University of Idaho, Moscow, ID 83944-1023, USA
Corresponding Author: M. Shamim Hossain (mshossain@ksu.edu.sa)
ABSTRACT Although ElectroEncephaloGram (EEG) signals allow subjects suffering from neuromuscular
disorders to interface their brains with the cyber-physical world, occupational therapy can be enhanced
with the introduction of further modalities better assist the disabled person. In this paper, we propose
an in-home occupational therapy environment, which leverages a rich set of occupational therapy-related
activity recognition modalities, namely, EEG signals to understand brain activity, ElectroMyoGram (EMG)
signals for muscle activity, gesture-tracking sensors for forward and inverse kinematics activities, and smart
home appliance control sensors. To support a wide variety of disabled people’s in-home occupational therapy,
we have incorporated both selective attention and motor imagery processes for mapping a mental command
with that of an occupational therapy-related command within a serious game environment. To attain higher
accuracy and to avoid a higher number of false positives, a subject is first recommended to use a selective
attention-based serious game in which a digital avatar of the subject acting as a model therapist will
guide the therapy session. Once familiar with the generation of proper motor imagery, an advanced user
can use self-paced motor imagery signals to perform occupational therapy activities within the serious
game environment. The occupational therapy consists of a serious game environment in which smart home
appliances are mapped with therapeutic activities through forward and inverse kinematics. The therapy data
has been secured through blockchain and off-chain-based distributed repositories. The test results show the
viability of using the framework in a clinical environment.
INDEX TERMS Brain computer interface, blockchain, off-chain, serious games, digital virtual avatar.
I. INTRODUCTION
Occupational therapy (OT) is intended to allow daily life
activities independently [1]. The purpose of OT is to allow
an individual to live as close as possible to their normal
day-to-day living. For effectiveness, OT governs therapeutic
features such as type, length, and frequency of motor imagery
and therapeutic exercises, and change in difficulty level or
course of activities to support quality of improvement [2].
The associate editor coordinating the review of this manuscript and
approving it for publication was Victor Hugo Albuquerque.
Although much work has been done in the area of OT, under-
standing the Brain Computer Interface (BCI) and how it can
help in certain types of disabilities remains an open challenge
[3]. BCI leverages collaboration between the brain and any
external hardware and software-based computing system [4].
BCI is used for mind state reading by probing brain activity,
which is reflected in the electrical signals generated within
the brain neurons. The signals portray a disabled person’s
mental desires to do an action [5]. A BCI intercepts these
brain electrophysiological signals through an invasive or non-
invasive computing hardware and software and finally maps
34874
2169-3536 
 2019 IEEE. Translations and content mining are permitted for academic research only.
Personal use is also permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.
VOLUME 7, 2019
https://orcid.org/0000-0002-4105-0368
https://orcid.org/0000-0001-5906-9422
https://orcid.org/0000-0001-6480-7100
https://orcid.org/0000-0002-8972-8094
M. A. Rahman et al.: Blockchain-Based Non-Invasive Cyber-Physical OT Framework
each distinct brain signal with a certain action [6]. In the case
of OT, the BCI is designed to understand mapping between
the brain signals identified by the BCI and the corresponding
occupational therapy commands [7]. The hardware interfaces
with the brain, collects electrical signals, and relays them
to a software component, which analyzes signals, maps the
signals with a certain occupational therapy command, and
actuates an external device or system that can be part of the
OT environment. BCI-based research has gained attraction
due to its support of neurofeedback, external IoT device
interactions with brain signals, and the possibility of brain
enhancement [7].
The brain generates rhythmical potentials in response to
certain sensory-motor stimulus [8], which can be interpreted
by EEG. The motor imagery is very popular in augmenting
the rehabilitation process of disabled people [9]. In partic-
ular, the brain state signature of a disabled person, which is
decoded by the interpretation of EEG signals can help during
the physical rehabilitation process. Although several meth-
ods of capturing neuro signals exist, such as EEG, Magne-
toEncephaloGraphy (MEG), FunctionalMagnetic Resonance
Imaging (fMRI), and Near Infrared Spectroscopy (NIRS),
EEG data is widely used as neurofeedback for mapping the
brain with a set of activities being performed [10]. This is
because of its non-invasive usage, ease of use, support of
portability, and cost-effectiveness [11]. Being able to map
brain activity with certain motor functions has the potential
to support disabled people [12].
When a person’s mental state of ‘‘wanting to do certain
action’’ change, corresponding oscillatory components of
EEG signals also change [13]. Event-Related Synchroniza-
tion (ERS) is a notion which is characterized by an increase
of EEG signal power in a certain band of brain signal fre-
quency [14] and Event-Related Desynchronization (ERD)
happens when the signal power decreases [15]. For example,
during and after the imagination of a left hand movement
related to an OT exercise exhibits an ERD and ERS respec-
tively in the beta and gamma frequency bands [16], [17].
ElectroEncephaloGram (EEG) and ElectroMyoGram
(EMG) are used primarily to probe the nervous system [18].
EEG data represent the electrical waves of the brain whereas
EMG data evaluate nerve and muscle function in the arms or
legs [10]. For example, EEG data available from the motor
cortex area of the brain, which controls the muscles of the
body that help in moving the arms, fingers, legs, and torso,
can indicate initiation of the kinematic actions [19]. In other
words, knowing which part of the brain controls which parts
of muscles allows the right therapy to be given to the muscles
of interest [13]. For example, Broca’s area in themotor cortex
controls the muscles in the mouth so that a person can express
him/herself in an intelligent and coordinated way [3]. On the
other hand, EMG data provides an indication of the electrical
activities in the muscle, which is being stimulated by the
nervous system [20]. EMG measures the electrical activity
of a muscle when a person does kinematic gestures [21].
Once a person contracts any muscle, for example, by making
a wrist flexion and extension, the muscle around the wrist
joint responds to nerve stimulation [11].
Each brain signal acquired against a thought can be
divided into various frequency bands [22], namely, delta
δ (1 – 3Hz), theta θ (4 – 7Hz), alpha α (8 – 12Hz), beta β
(12 – 30Hz) and gamma γ (30 – 100Hz). Each frequency
band represents a specific feature. Each frequency range con-
tains information related to a different aspect of human think-
ing. For example, the β and γ rhythms ranging from 12Hz
to 100Hz are related to motor activities, more specifically
the visualization of motion [23]. The higher the frequency
in brainwaves, the larger the number of neurons that fire up
synchronously at the same time [24]. When there is increased
availability of β and γ waves, a person becomes alert with
complete focus and an engaged mind and can have an active
conversation, play sports, or drive a car [25]. Although all
the types of frequency signals are generated at any given
time, a particular type of signal becomes dominant which
allows the body to determine what type of activity is to take
place. For example, during the day time when one needs to
do some hard work, the beta or gamma wave is assumed
to have higher dominance over other signals [26]. Hence,
researchers have found a correlation between EEG signal’s β
(12 – 30Hz) and γ (30 – 100Hz) waves and the EMG signal
available at the muscles during a typical working time [7].
Hence, wanting to do a motor task to perform a therapy can
be correlated to a particular therapy performed by a subset
of muscles around a subset of joints [22]. Understanding
the EEG and EMG signal gives more latitude of information
during an occupational therapy [2].
Li et al. [24] target spastic cerebral palsy (CP) children to
evaluate their sensory-motor response and beta waves in the
frontal lobe area of the brain, as it is responsible for human
motor and sensory functions: the left part of the frontal lobe
is the primary motor area, while the right part is the primary
somatosensory area. During analysis, two parameters were
studied: one is sensory-motor response (SMR) amplitude,
which is higher when the corresponding sensorimotor area
is immobile or in an idle state and lower during activation
of motor areas, i.e., at the time of motion or motor imagery.
The second parameter is Beta amplitude, that increases at the
motor cortex region as muscles contract or when the move-
ment is resisted. The study results demonstrate the effective-
ness of the system on the basis of improved SMR and beta
values in CP children.
Scherer et al. [27] used the motor imagery technique for
allowing a user to navigate in a virtual environment using
three commands, rotate-left, rotate-right and move forward.
They used the mental commands of the right/left hand and
foot movement. The same technique has been used to allow
a tetraplegic patient to control his wheelchair in a Virtual
Environment [28]. After an excessive amount of training
lasting approximately 4 months, he was able to move his
avatar in a VR environment by movement imagination of
his paralyzed feet. The results of the study showed that the
subject was able to execute some predefined tasks in a virtual
VOLUME 7, 2019 34875
M. A. Rahman et al.: Blockchain-Based Non-Invasive Cyber-Physical OT Framework
environment with a success rate of 90%-100% and that the
methods could be easily transferred from the laboratory to a
real-world application.
Brain computer interfaces (BCI) have been applied
to motor rehabilitation in stroke patients with promising
results [29]. In order to interact with different disabled
patients, different modalities can be used such as manual
interaction, using voice commands, gestures, eye movement,
and thoughts [30]. Combining thought, gesture, eye move-
ment, and voice as modalities for therapy allows various
factors to be optimized, such as in different situations: when
a disabled person is at home alone, is surrounded by peo-
ple, or desires to do something him/herself [31]. Forward
kinematics data provides the therapeutic gesture data, which
shows the wellbeing or improvement of target body joints.
Inverse kinematics allow a subject to achieve a target goal in
terms of forward kinematics [32]. For example, if a person
has a disability in moving the left hand, an IoT-based door
lock can be interfaced such that during occupational therapy,
the door will open through the elbowflexion-extensionmove-
ment of a certain range of motion. It is assumed that cortical
areas control the movements of the contralateral limbs as well
as playing a role in ipsilateral movements [18].
FIGURE 1. (a) 10-20 system of placing EEG signal collection electrodes,
and (b) an EEG headband with electrodes touching the desired location
of the brain [6].
In order to interface the brain signals with the BCI,
the international 10-20 system is widely used an industry
standard [33] (see Figure 1). The 10-20 systemmaps a certain
portion of the brain with that of the spatial location of the
interfaced electrodes. Researchers use the 10-20 notations to
represent certain EEG signals originating from certain por-
tion of the brain in terms of 10-20 electrode IDs. For example,
researchers have found that imagination about movement of
left and right-hand can be detected by placing electrodes
in C3 and C4 or F7 and F8 locations [14], [34]. On the
other hand, researchers have found that eyeball movement
influences brain waves’ F7 and F8 electrodes [35]. The sug-
gested placement of the corresponding electrodes is shown
in Figure 1. One important aspect of knowing such distinct
patterns, researchers can identify high level motor actions
related to OT that is created within the brain and place
the electrodes accordingly. For example, if an OT exercise
requires both hand and eye movement motor actions to be
monitored, the BCI can be configured to acquire signals from
C3, C4, F7, and F8 [24], [35]. Existing occupational therapy
research shows that motor imagery can help stroke patients
who have problems moving their arms and hands, and legs
after a stroke [14], [36]–[38]. Stroke sufferers have shown
increased neural awareness due to motor imagery exercise
during their regular occupational therapy, instead of just reg-
ular therapy alone [39].
Data originated duringOT requires privacy, confidentiality,
and integrity while in storage, or transmission or processing.
Also, a large volume of multimedia data is being generated
during each OT session. In order to provide occupational
data security, recent advancement in blockchain and off-
chain-based decentralized digital repository shows promising
options [40]. The new generation of blockchain and off-
chain solutions even guarantees availability and scalability
of OT data [41], proper end-to-end encryption, digital wallet
with secure cryptographic public/private keys, and high speed
transaction overlays such as Lightning Network (LN).
In this paper, we propose a novel in-home occupational
therapy environment, which incorporates off-the-shelf EEG,
EMG, eye tracking sensors, smart home IoT sensors [42], and
kinematic gesture tracking non-invasive sensors to support
forward and inverse kinematic actions. We have developed
a 3D game environment in which the sensory data from the
brain, muscles, joint range of motion and eye positions are fed
to a digital avatar. The occupational therapy environment has
been created with a subset of therapies that incorporate the
brain commands, the hand muscle movement, and different
hand and eye gestures to interact with the serious game
environment in which different smart home IoT devices can
be controlled with gestures. The game environment consists
of two phases: during the first phase, a digital model occu-
pational therapist guides a subject with model occupational
therapy movements. During this time, the subject develops
motor imagery in his/her brain. During the actual therapy
time, the subject performs the action, which is recorded by
the multimodal sensors. At the end of the therapy session,
a summary of the kinematic data and quality of improvement
is saved in the secure therapy blockchain while the raw EEG,
EMG, and other kinematic data are saved in an off-chain
repository for immutable storage. The therapeutic data can be
shared with a remote therapist, which consists of an improve-
ment in terms of motor movement, muscle power gain, and
the ability to do certain motor tasks, as defined within the
therapy.
The remainder of this paper is organized as follows.
Section II outlines some preliminary background. Section III
describes the proposed research framework, while Section IV
presents the implementation, results, and discussion. Finally,
Section V concludes the paper.
II. BACKGROUND
1) MOTOR IMAGERY FOR OCCUPATIONAL
THERAPY APPLICATIONS
Motor imagery is a form of neurophysiological therapy that
allows a disabled person to mentally rehearse the movement
34876 VOLUME 7, 2019
M. A. Rahman et al.: Blockchain-Based Non-Invasive Cyber-Physical OT Framework
of the affected body parts, without actually needing to per-
form the movement. In other words, a subject imagines doing
the movement as shown or guided by a computer system, e.g.
a virtual or augmented reality game. A subject may imagine
opening a door using their right hand or moving an object
from left to right using his/her left hand [34], [36], [37].
Motor imagery can be integrated within the OT lifecycle in
many ways, for example:
• Model therapy – serious games containing a virtual ther-
apist showing the steps required to complete an occupa-
tional therapy task (e.g. switching on/off a light using
wrist flexion/extension). The serious game incorporates
those actions and tasks the patient has difficulty with
performing on a daily basis.
• Imagining the therapeutic actions – the subject is
instructed to recall the mistakes made.
• Following the model therapist – the subject practices the
prescribed tasks through imagination and subsequently
performs that OT in self-paced mode.
FIGURE 2. Motor imagery can help in actual occupational therapy
activities [14].
Figure 2 shows a sample scenario in which a person is
intending to perform an elbow flexion operation. Appropriate
motor signals are sensed by the EEG headset from the motor
cortex area and the corresponding EMG signal is sensed by
the EMG armband.
2) MULTIMODAL OCCUPATIONAL THERAPY SENSORS
Adding multiple dimensions to occupational therapy brings
richer immersiveness and greater insights. For example,
during a motor imagery session, the coordination of eye
and motor signals together make the intercepted signal
higher in power for recognition of the movement intention.
FIGURE 3. Eye tracking used for occupational therapy: (a) an eye tracking
device has been setup, (b) the proper field of view for the gaze tracker is
maintained, and (c) sample left and right eye movement can be tracked
by the device.
FIGURE 4. Hand kinematic data recognition for OT: (a) 50 Hz Hand
Kinematic Data available from the Leap Motion Kinematic Sensor,
(b) samples of different gestures recognized by Leap Motion,
(c) Microsoft Hololens for hand gesture tracking, and (d) an augmented
reality view of gesture based sensors.
FIGURE 5. (a) 200 Hz, 8-channel EMG Sensors, 9-axis IMU with haptic
feedback MYO Armband, (b) Position of placing at the hand, and (c) ability
to recognize different hand gestures from the analysis of EMG signals.
Further, the intention imagery can be recognized and verified
by actual eye movement data available from eye tracking
sensor, the EMG data, and the subsequent gesture tracking
data available from gesture tracking sensors. Figure 3 shows
a sample eye tracking environment. Figures 4, 5, and 6 show
gesture tracking sensors, different joints and body parts each
sensor can track and their coverage. A mashup of these sen-
sors provides a rich set of human joint movements for our
research. Figure 7 shows how these gesture tracking sensors
play a role within the framework. Figure 7(a) shows sample
VOLUME 7, 2019 34877
M. A. Rahman et al.: Blockchain-Based Non-Invasive Cyber-Physical OT Framework
FIGURE 6. Microsoft Kinect V2 sensor, which can detect the motions
around 25 joints of a human body within its field of view.
FIGURE 7. (a) Different gestures from various parts of the body that are
used for occupational therapy, (b) human body joint anatomy and
muscles around joints of interest help in making the required
gestures [courtesy 44].
motions around different joints of the body, Figure 7(b) shows
the motions around each joint, and how the muscles around
each joint respond to each motion type. All of these different
sensors together provide real-time maps of joints, motions
and muscle tones around the hand [43].
3) FORWARD AND INVERSE KINEMATICS-BASED
SERIOUS GAMES
Forward kinematics data, after classification, are fed into a
serious game to be able to follow the model therapist avatar.
The objective of the controller is to move the suggested
joints to the desired set point and return the kinematic data
of the attempted action. The therapy engine controller [32]
measures the difference between the desired position of the
model therapist in the cyber world and the actual position,
and help drive the BCI interface with a signal proportional to
this. Figure 8 (a) shows the collection of kinematic data from
different joints while the occupational therapy exercise takes
place. Figure 8(b) shows a scenario a user is shown for target
hand position in augmented reality view. The user follows
the suggested skeletal position and adjusts his hand position,
as shown in Figure 8(c).
III. SYSTEM DESIGN
A. BCI SYSTEM OVERVIEW
Figure 9 shows high level BCI data processing framework.
Frequency and spatial filtering is performed prior to feature
FIGURE 8. Forward kinematic data obtained from gesture tracking sensor
shown in Figure 7 is applied to deduce inverse kinematic principles in
order to follow the virtual occupational therapist in an augmented reality
view.
FIGURE 9. BCI data processing (image courtesy [48]).
extraction process. The Common Spatial Pattern (CSP) algo-
rithm is employed to optimally discriminate oscillatory band
powers [8], [45]. Classifiers are used to classify between
EEG of two different motor actions due to imaginary motor
function. Classifiers must be chosen according to the set
of the features. Linear discriminant analysis (LDA) is used
for a two-class problem [46] while Quadratic Discrimi-
nant Analysis (QDA) is used when the hyperplane shows a
quadratic signature instead of linear [46]. A Support Vec-
tor Machine (SVM) classifier [47] is used as a discrimi-
nant hyperplane to further identify classes with maximized
margins.
B. HIGH-LEVEL SYSTEM AND SOFTWARE COMPONENTS
Figure 10 (a) shows the high-level architecture of the pro-
posed system. A subject is assumed to be interfaced and
34878 VOLUME 7, 2019
M. A. Rahman et al.: Blockchain-Based Non-Invasive Cyber-Physical OT Framework
FIGURE 10. (a) High-level multisensory occupational therapy
environment, and (b) high-level system components.
within the sensory coverage of the EEG, EMG, eye tracker,
smart home IoT, and the gesture tracking sensors. The sub-
ject is presented with an occupational therapy serious game,
which is designed, customized and personalized for the sub-
ject, i.e., the gameplay actions and objects are presented
such that the person can either use it in observation mode,
motor imagery mode or actual therapy mode. The serious
games can be in different visual metaphors, such as virtual
reality, augmented reality or mixed reality. The subject first
creates an image map from the game environment, in which
a model digital therapist shows how to perform the therapy.
This creates an impression in the motor cortex area, which is
intercepted by the EEG sensor.When the user actually intends
to start the action, the motor actions are recorded by the other
sensors.
Figure 10 (b) shows the software system for supporting
the therapy exercise. The Sensory Data Manager houses
the Live Data Manager component which receives the raw
sensory data from different sensory media. It also hosts the
Session Recorder, which provides a recorder suitable for cap-
turing different types of raw data from different User Inter-
face components. The Storage component is responsible for
storing each occupational therapy Session Data, Knowledge
Base and Blockchain-based Therapy Profile. The Cyber-
Physical Cognitive Intelligence engine incorporates several
key components. The Inverse Kinematics Analyzer helps in
achieving the goal of a therapy session by working with
other components such as the Rendering Engine and Spatio-
Temporal Analyzer. The Rendering Engine updates the sen-
sory data to the appropriate User Interface components. The
Reporting Engine provides live and historical reports, which
can be shared with one’s community of interest. The Recom-
mender System is an AI-based system, which leverages the
knowledge and data available in the Blockchain, Off-chain,
Knowledge Base and suggestions available from the Model
Therapist interface to assist in performing the occupational
therapy at home.
C. BCI-BASED SERIOUS GAMES DESIGN
The system is designed based on a research concept of mak-
ing the brain simulate [49] the action of ‘‘want to move’’ by
incorporating the following notions:
FIGURE 11. BCI-based occupational therapy scenario.
• The BCI based Virtual Reality (VR) therapy [49] will
provide rich photorealistic virtual environments, along
with matching 3D body sensor networks that will be
controlled via sensory data generated from the brain and
the physical movement of the body in an Omni tread-
mill that is connected with the head mounted display
(see Figure 11).
• A VR environment will be provided to the patient to
stimulate his brain into generating a ‘‘desiring to make
an action’’ signal. A patient fitted with the setup shown
VOLUME 7, 2019 34879
M. A. Rahman et al.: Blockchain-Based Non-Invasive Cyber-Physical OT Framework
in Figure 11 can move and interact within a virtual
environment just by thinking.
• This thought of ‘‘wanting to move’’ is detected by the
BCI wearable device, such as the Emotiv EPOC EEG.
• This will strongly motivate the patient, as it will provide
a fully immersive environment with fun activities to per-
form. If a goal is achieved, the patient will be rewarded
in the virtual environment and become motivated to try
harder goals.
• Through regular sessions using this system, patients will
have higher rates of recovery.
FIGURE 12. Blockchain and off-chain solution for BCI-based occupational
therapy data security.
Figure 12 (a) shows the blockchain and off-chain thera-
peutic data repository architecture while Figure 12 (b) shows
a sample architecture of a transaction. While the blockchain
stores key OT transactions and other performance related
metrics, the off-chain is used to store raw EEG/EMG/skeletal
data, and other types ofmultimedia data related to the therapy.
As shown in Figure 12, a certain user’s OT data related to one
session is stored in one of the blocks in the blockchain, which
includes a link of the raw OT data as Electronic Medical
Record (EMR) within the off-chain to be able to maintain
a global view of a particular OT session [13], [21]. The OT
transactions can be automated using smart contract, a sample
of which is shown in Figure 12 (b).
IV. IMPLEMENTATION
We have tested the framework with healthy subjects via an
EEG cap mounted on the participants’ heads, performing
a standard signal quality check for all electrodes, follow-
ing by the calibration of the eye-tracking, Leap Motion,
and Kinect V2 devices. One test session per subject took
around 20minutes to complete, including the mounting of the
psychophysiology measurement equipment and pre-testing.
Participants were seated in a comfortable condition and were
asked to keep as motionless as possible during the entire
procedure, to minimize possible signal interference due to
movement. We have used both Emotiv and MUSE EEG
headsets as suggested by Zaki et al. [6]. We have used a
Node.js and AngularJS based framework to access data from
the Emotiv EPOC brain sensor or the open dataset available
from Emotiv. This supports the Emotiv EPOC EEG headset,
analyzing a Raw EEG data stream of 14 electrodes with
128Hz sample rate. Using the API, we can log events such as
a person smiling, looking up, down, left or right, blinking an
eye, winking left or right, laughing or not, spatial coordinates
from gyroscope, and cognitive actions [24], [35], [50].
To record EMG signal, we chose the MYO EMG armband,
which was placed over four selected forearm muscles as
suggested by Hashimoto et al. [19]. This helps in identi-
fying EMG signals responsible for wrist flexion with ulnar
deviation, wrist flexion, extension of four fingers and exten-
sion of the wrist, and extension and radial abduction of the
wrist [51], [53], [54]. Eye-tracking data was recorded using
the stationary Eye Tribe eye-tracker with a 60 Hz sampling
rate [52]. The eye-tracker was calibrated using the native Eye
Tribe calibration system. During the experiment, the follow-
ing eye data was tracked and recorded: i) x and y coordinates
for the on-screen gaze positions of the eyes, ii) pupil dilation
for right and left eyes, iii) x and y coordinates for on-screen
left and right eye positions. Each on-screen gaze position
recorded by the eye-tracker was converted to a fixation point.
For classification of a fixation point, the maximum gaze
position was set to a 160 pixels distance from the previous
sampled gaze position and the minimum number of samples
was set to 6 Hz.
To run the aforementioned experimental design condi-
tions, a custom-made stimulus presentation therapy environ-
ment was implemented using Unity3D. The application was
implemented to handle the following functions: i) present the
stimuli via immersive and game-based event, ii) present base-
line experimental conditions, iii) assign unique identification
triggers to each of the presented conditions, and iv) send
the triggers to the EEG/EMG/IoT/Gesture tracking software
components.
Through our developed smart home cyber physical game
environment. A subject sees a natural daily life environment
with appliances which he/she interacts or intends to interact
on a daily basis. The OT environment has been interfaced
such that the OT exercise comprises those brain and gesture
commands that will allow interacting with the surrounding
34880 VOLUME 7, 2019
M. A. Rahman et al.: Blockchain-Based Non-Invasive Cyber-Physical OT Framework
smart home IoT devices through virtual reality, augmented
reality, or mixed reality serious game metaphors. This will
make one engaged and immersed and allow a therapist to
know how many of the daily life activities are performed by
the subject. While a subject interacts with the IoT appliances,
the corresponding EEG/EMG/eye position/skeletal data is
recorded and analyzed by the system.
V. TEST RESULTS
In this paper, we have proposed a smart home appliance
control serious game environment based on motor imagery
tasks and present the preliminary experimental results. Two
types of experiments are being performed: a guided and a
self-paced therapeutic exercise. The self-paced BCI paradigm
supports two different benefits of occupational therapy.
Firstly, it increases the degrees of freedom of brain excitation
area. Secondly, it improves the independence and control-
lability of the BCI system. Finally, it allows adding more
dimensions of modality at any given motor imagery session.
Hence, the EEG headset will pick up greater number of
determinant spatial signals from the brain. Figure 13 shows
the EEG signals received from C3, C4, F7, and F8 elec-
trodes containing motor imagery and ERD/ERS stimulation.
The results are in line with the findings of Li et al. [24].
FIGURE 13. EEG signals originated during multi-class occupational
therapy mental tasks.
Figure 13 shows the time varying beta and gamma frequency
bands (13-100 Hz), which cover most of the frequency infor-
mation in sensorimotor rhythm, and provide a comprehensive
view of the current frequency band used for classification and
analysis.
As shown in Figure 13, we have found correlation among
different obtained signals such as EEG, EMG, Kinematic, eye
tracking sensors and the corresponding occupational thera-
peutic exercise. For example, in our experiment, the occu-
pation therapy named ‘‘70 degrees flexion followed by
75 degrees extension of left hand wrist joint’’ was bro-
ken down into ‘‘motor imagery’’ and ‘‘actual therapeutic
movement’’ sessions. During the motor imagery session,
a subject follows a model therapist in the VR/AR mode.
During this mode, the intention along with the eye move-
ment is tracked from the respective EEG and eye tracking
sensors. Subsequently, the subject actually performs the wrist
flexion-extension movement as shown to a subject during the
motor imagery session. The recorded session data analysis
shows that adding multi-dimensional occupational data bring
more confidence into how a subject’s brain, muscle and joints
work as a combined unit while performing daily life activities
in its normal state. Since occupational therapy is aimed at
helping each patient going to his/her normal life, tracking
multiple human body parts that allows a subject in performing
a certain high level task through occupational therapy will
bring better insight about the quality of improvement.
During the analysis of the dataset as shown in Figure 13,
we have found that there is a strong correlation between
the motor imagery session and the afterwards actual motor
actions’ data available from the additional sensory data.
This follows the pattern shown in Figure 2 and Figure 11.
In other words, the excitation of neuronal activities through
the motor imagery session in which a particular occupational
therapy session is being shown in a screen is found to be
mapped with the subsequent motor neuronal actions that is
available through EMG signal at the hand FCU, ED, PL,
and ECR muscles, the eye movement data available from
the eye tracker and the kinematic data available from hand
gesture tracking sensors. This result shows that the occu-
pational therapy can be augmented with the effective EEG,
EMG monitoring systems to enhance the interaction with
the brain functionality. In particular, the neuro-occupational
therapy research would bring more in depth knowledge about
a disabled user’s quality of improvement in all the arenas such
as brain activity, disabled joints, muscle tone and other types
of therapeutic gains.
However, we have found several challenges while perform-
ing the tests with the dataset. The EEG data is extremely
noisy as the off-the-shelf sensors such as emotive and MUSE
have to carefully setup to intercept the frequency bands. For
example, the beta and gamma wave’s discrimination of EEG
signal originated due to left and right hand movement motor
imagery along with gaze movement captured from C3 and C4
electrodes and F7 and F8 electrodes exhibit different patterns.
In addition, the pattern recognition algorithms and the filter
VOLUME 7, 2019 34881
M. A. Rahman et al.: Blockchain-Based Non-Invasive Cyber-Physical OT Framework
designs are highly sensitive to the available dataset. Using a
completely automated and tightly synched occupational ther-
apy in which brain though is part of the therapeutic process is
highly challenging given the fact that the brain signal controls
certain hardware such as smart bulb, smart lock or other types
of IoT devices. In our future research, we will address these
challenges of improving the recognition rate and the better
correlation with brain and other therapeutic movements.
VI. CONCLUSION
In this paper, we have proposed an occupational therapy envi-
ronment in which a multimodal set of media is used to track
the quality of improvement of a subject. The occupational
therapy consists of using motor imagery stimulation for an
exercise, which is followed by the actual therapeutic exercise.
The motor imagery phase is assisted by an online virtual
model therapist, during which the EEG signal is recorded
about the intention of the user. Afterwards, during the actual
exercise, the affected and utilized body joints and motions are
recorded through EEG, eye tracker, gesture tracking and IoT
sensors. The multisensory occupational therapy data gives a
therapist rich insights and greater dimensions of the inner
conditions of a subject. In the near future, we intend to stabi-
lize the testing procedure through real-life disabled subjects.
ACKNOWLEDGMENT
The authors extend their appreciation to the International
Scientific Partnership Program ISPP at King Saud University,
Riyadh, Saudi Arabia for funding this research work through
ISPP-121.
REFERENCES
[1] B. Hooper, R. King, W. Wood, A. Bilics, and J. Gupta, ‘‘An international
systematic mapping review of educational approaches and teaching meth-
ods in occupational therapy,’’ Brit. J. Occupat. Therapy, vol. 76, no. 1,
pp. 9–22, 2013.
[2] M. S. Hossain and G. Muhammad, ‘‘Cloud-based collaborative media
service framework for health-care,’’ Int. J. Distrib. Sensor Netw., vol. 10,
no. 3, Jan. 2016, Art. no. 858712.
[3] G. Gupta, S. Pequito, and P. Bogdan, ‘‘Re-thinking EEG-based non-
invasive brain interfaces: Modeling and analysis,’’ in Proc. ACM/IEEE 9th
Int. Conf. Cyber-phys. Syst. (ICCPS), Apr. 2018, pp. 275–286.
[4] L. Yao, X. Sheng, N. Mrachacz-Kersting, X. Zhu, D. Farina, and N. Jiang,
‘‘Performance of brain–computer interfacing based on tactile selective
sensation and motor imagery,’’ IEEE Trans. Neural Syst. Rehabil. Eng.,
vol. 26, no. 1, pp. 60–68, Jan. 2018.
[5] X. Zhang, L. Yao, D. Zhang, X. Wang, Q. Z. Sheng, and T. Gu, ‘‘Multi-
person brain activity recognition via comprehensive EEG signal analysis,’’
in Proc. 14th EAI Int. Conf. Mobile Ubiquitous Syst., Comput., Netw.
Services, Nov. 2017, pp. 28–37.
[6] M. Zaki, A. Alquraini, and T. R. Sheltami, ‘‘Home Automation using
EMOTIV: Controlling TV by Brainwaves,’’ J. Ubiquitous Syst. Pervasive
Netw., vol. 10, no. 1, pp. 27–32, 2018.
[7] M. S. Hossain and G. Muhammad, ‘‘Emotion recognition using deep
learning approach from audio-visual emotional big data,’’ Inf. Fusion,
vol. 49, no. 2019, pp. 69–78, Sep. 2019.
[8] H. Sun, Y. Zhang, B. J. Gluckman, X. Zhong, and X. Zhang, ‘‘Optimal-
channel selection algorithms in mental tasks based brain-computer inter-
face,’’ in Proc. 8th Int. Conf. Biosci. Biochem. Bioinformat. (ICBBB),
Jan. 2018, pp. 118–123.
[9] J. Pereira, P. Ofner, A. Schwarz, A. I. Sburlea, and G. R. Putz-Müller,
‘‘EEG neural correlates of goal-directed movement intention,’’ NeuroIm-
age, vol. 149, pp. 129–140, Apr. 2017.
[10] P. Jensen, N. J. Jensen, C. U. Terkildsen, J. T. Choi, J. B. Nielsen, and
S. S. Geertsen, ‘‘Increased central common drive to ankle plantar flexor
and dorsiflexor muscles during visually guided gait,’’ Physiol. Rep., vol. 6,
no. 3, pp. 1–11, 2018.
[11] G. Lange, C. Y. Low, K. Johar, F. A. Hanapiah, and F. Kamaruzaman,
‘‘Classification of electroencephalogram data from hand grasp and release
movements for BCI controlled prosthesis,’’ Procedia Technol., vol. 26,
pp. 374–381, Dec. 2016.
[12] P. Tirupattur, Y. S. Rawat, C. Spampinato, and M. Shah, ‘‘ThoughtViz’
visualizing human thoughts using generative adversarial network,’’ in
Proc. ACM Multimed. Conf., Oct. 2018, pp. 950–958.
[13] E. López-Larraz, T. C. Figueiredo, A. Insausti-Delgado, U. Ziemann,
N. Birbaumer, and A. Ramos-Murguialday, ‘‘Event-related desynchro-
nization during movement attempt and execution in severely paralyzed
stroke patients: An artifact removal relevance analysis,’’NeuroImage Clin.,
vol. 20, pp. 972–986, Oct. 2018.
[14] G. Pfurtscheller and C. Neuper, ‘‘Motor imagery and direct brain-
computer communication,’’ Proc. IEEE, vol. 89, no. 7, pp. 1123–1134,
Jul. 2001.
[15] G. Pfurtscheller and F. H. L. Da Silva, ‘‘Event-related EEG/MEG synchro-
nization and desynchronization: Basic principles,’’ Clin. Neurophysiol.,
vol. 110, no. 11, pp. 1842–1857, 1999.
[16] G. Schulte-Körne, and J. Bruder, ‘‘Clinical neurophysiology of visual and
auditory processing in dyslexia: A review,’’ Clin. Neurophysiol., vol. 121,
no. 11, pp. 1794–1809, 2010.
[17] M. S. Hossain, S. U. Amin,M. Alsulaiman, and G.Muhammad, ‘‘Applying
deep learning for epilepsy seizure detection and brain mapping visualiza-
tion,’’ ACM Trans. Multimedia Comput. Commun. Appl., vol. 15, no. 1s,
Feb. 2019, Art. no. 10.
[18] L. Yao, X. Sheng, D. Zhang, N. Jiang, D. Farina, X. Zhu, ‘‘A BCI system
based on somatosensory at tentional orientation,’’ IEEE Trans. Neural Syst.
Rehabil. Eng., vol. 25, no. 1, pp. 81–90, Jan. 2017.
[19] Y. Hashimoto, T. Ota, M. Mukaino, M. Liu, and J. Ushiba, ‘‘Functionaly
from chronic Writer’s cramp by brain-computer interface rehabilitation: A
case report,’’ BMC Neurosci., vol. 15, no. 1, pp. 1–7, 2014.
[20] M. Masud, M. S. Hossain, and A. Alamri, ‘‘Data interoperability and
multimedia content management in e-health systems,’’ IEEE Trans. Inf.
Technol. Biomed., vol. 16, no. 6, pp. 1015–1023, Nov. 2012.
[21] F. Artoni, A. Barsotti, E. Guanziroli, S. Micera, A. Landi, and F. Molteni,
‘‘Effective synchronization of EEG and EMG for mobile brain/body
imaging in clinical settings,’’ Front. Hum. Neurosci., vol. 11, pp. 1–9,
Jan. 2018.
[22] M. Spüler, E. López-Larraz, and A. Ramos-Murguialday, ‘‘On the design
of EEG-based movement decoders for completely paralyzed stroke
patients,’’ J. Neuroeng. Rehabil., vol. 15, no. 1, p. 110, 2018.
[23] N. Swann et al., ‘‘Deep brain stimulation of the subthalamic nucleus alters
the cortical profile of response inhibition in the beta frequency band: A
scalp EEG study in Parkinson’s disease,’’ J. Neurosci., vol. 31, no. 15,
pp. 5721–5729, 2011.
[24] Z. Li, J. Xu, and T. Zhu, ‘‘Recognition of brain waves of left and
right hand movement imagery with portable electroencephalographs,’’
2015, pp. 1–13.
[25] A. Tiwari, O. P. Singh, and D. Bhatia, ‘‘Comparison of EEG signals of
cerebral palsy patients after standard and rTMS therapy,’’ Neurol. Neuro
Disorder, vol. 1, no. 1, pp. 9–16, 2018.
[26] Q. Qiu, L. Cao, D. Hao, L. Yang, R. Hillstrom, and D. Zheng, ‘‘Mus-
cle extremely low frequency magnetic stimulation eliminates the effect
of fatigue on EEG-EMG coherence during the lateral raise task: A
pilot quantitative investigation,’’ Biomed Res. Int., vol. 2018, pp. 1–8,
Jul. 2018.
[27] R. Scherer, F. Lee, A. Schlogl, R. Leeb, H. Bischof, and G. Pfurtscheller,
‘‘Toward self-paced brain-computer communication: Navigation through
virtual worlds,’’ IEEE Trans. Biomed. Eng., vol. 55, no. 2, pp. 675–682,
Feb. 2008.
[28] Y. Yu et al., ‘‘Self-paced operation of a wheelchair based on a hybrid
brain–computer interface combining motor imagery and P300 potential,’’
IEEE Trans. Neural Syst. Rehabil. Eng., vol. 25, no. 12, pp. 2516–2526,
Dec. 2017.
[29] J. Ushiba and S. R. Soekadar, ‘‘Brain–machine interfaces for rehabilita-
tion of poststroke hemiplegia,’’ Prog. Brain Res., vol. 228, pp. 163–183,
Jul. 2016.
34882 VOLUME 7, 2019
M. A. Rahman et al.: Blockchain-Based Non-Invasive Cyber-Physical OT Framework
[30] M. Salous, F. Putze, T. Schultz, J. Hild, and J. Beyerer, ‘‘Investigating static
and sequential models for intervention-free selection using multimodal
data of EEG and eye tracking,’’ in Proc. Working Modeling ‘Aumme
Coding’ Cogn. Process. Multimodal Data, Boulder, CO, USA, Oct. 2018,
p. 7.
[31] A. R. Babu, A. Rajavenkatanarayanan, J. R. Brady, and F. Makedon,
‘‘Multimodal approach for cognitive task performance prediction from
body postures, facial expressions and EEG signal,’’ in Proc. Workshop
Modelimg Cogn. Process. Multimodal Data, Oct. 2018, p. 14.
[32] A. Qamar, M. A. Rahman, and S. Basalamah, ‘‘Adding inverse kinematics
for providing live feedback in a serious game-based rehabilitation system,’’
in Proc. Int. Conf. Intell. Syst. Modeling Simulation, (ISMS), Jan. 2014,
pp. 215–220.
[33] T. Kosch, ‘‘Real-time brain mapping for treating substance abuse using
neurofeedback,’’ no. 46, p. 81, 2015.
[34] Y. Yu, Y. Liu, J. Jiang, E. Yin, Z. Zhou, and D. Hu, ‘‘An asynchronous
control paradigm based on sequential motor imagery and its application in
wheelchair navigation,’’ IEEE Trans. Neural Syst. Rehabil. Eng., vol. 26,
no. 12, pp. 2367–2375, Dec. 2018.
[35] C. G. Lim, C. Y. Lee, and Y. M. Kim, ‘‘A performance analysis of user’s
intention classification from EEG signal by a computational intelligence
in BCI,’’ in Proc. 2nd Int. Conf. Mach. Learn. Soft Comput. (ICMLSC),
vol. 18, Feb. 2018, pp. 174–179.
[36] K. K. Ang and C. Guan, ‘‘EEG-based strategies to detect motor imagery
for control and rehabilitation,’’ IEEE Trans. Neural Syst. Rehabil. Eng.,
vol. 25, no. 4, pp. 392–401, Apr. 2017.
[37] Z. Qiu et al., ‘‘Optimized motor imagery paradigm based on imagining
Chinese characters writing movement,’’ IEEE Trans. Neural Syst. Rehabil.
Eng., vol. 25, no. 7, pp. 1009–1017, Jul. 2017.
[38] M. Alhussein, G. Muhammad, and M. S. Hossain, ‘‘EEG pathology detec-
tion based on deep learning,’’ IEEE Access, vol. 7, pp. 27781–27788, 2019.
[39] C. I. Penaloza, M. Alimardani, and S. Nishio, ‘‘Android feedback-based
training modulates sensorimotor rhythms during motor imagery,’’ IEEE
Trans. Neural Syst. Rehabil. Eng., vol. 26, no. 3, pp. 666–674, Mar. 2018.
[40] R. Lai and D. L. K. Chuen, Blockchain: From Public to Private, 1st ed.
vol. 2. Amsterdam, The Netherlands: Elsevier, 2018.
[41] W. Li, A. Sforzin, S. Fedorov, and G. O. Karame, ‘‘Towards scalable
and private industrial blockchains,’’ in Proc. ACM Working Blockchain,
Cryptocurrencies Contract. (BCC), vol. 17, 2017, pp. 9–14.
[42] A. I. N. Alshbatat, P. J. Vial, P. Premaratne, and L. C. Tran, ‘‘EEG-based
Brain–computer interface for automating home appliances,’’ J. Comput.,
vol. 9, no. 9, pp. 2159–2166, 2014.
[43] M. A. Rahman andM. S. Hossain, ‘‘m-Therapy: Amulti-sensor framework
for in-home therapy management: A social therapy of things perspective,’’
IEEE Int. Things J., vol. 5, no. 4, pp. 2548–2556, Aug. 2018.
[44] E. De Buyser, E. De Coninck, B. Dhoedt, and P. Simoens, ‘‘Exploring
the potential of combining smart glasses and consumer-grade EEG/EMG
headsets for controlling iot appliances in the smart home,’’ in Proc. 2nd
IET Int. Conf. Technol. Act. Assist. Living (TechAAL), Oct. 2016, p. 6.
[45] A. Chowdhury, H. Raza, A. Dutta, and G. Prasad, ‘‘EEG-EMG based
hybrid brain computer interface for triggering hand exoskeleton for neuro-
rehabilitation,’’ in Proc. Adv. Robot., Jul. 2017, pp. 45:1–45:6.
[46] H. Bashashati, R. K. Ward, G. E. Birch, and A. Bashashati, ‘‘Comparing
different classifiers in sensory motor brain computer interfaces,’’ PLoS
ONE, vol. 10, no. 6, pp. 1–17, Jun. 2015.
[47] S. U. Amin, M. Alsulaiman, G. Muhammad, M. A. Bencherif, and M. S.
Hossain, ‘‘Multilevel weighted feature fusion using convolutional neural
networks for EEG motor imagery classification,’’ IEEE Access, vol. 7,
pp. 18940–18950, Jan. 2019.
[48] S. Navigation and N. S. Route, ‘‘Biology,’’ OpenStax, 2017. [Online].
Available: Avialble https://d3bxy9euw4e147.cloudfront.net/oscms-
prodcms/media/documents/Biology2e-OP_aHSFm3Y.pdf
[49] A. Brouwer, J. S. Van Der Waa, and H. Stokking, ‘‘A feasible BCI in real
life?: Using predicted head rotation to improve HMD imaging,’’ in Proc.
ACM Workshop Appl. Approach BCI Lab., 2017, pp. 35–38.
[50] D. P. Salgado et al., ‘‘A QoE assessment method based on EDA, heart rate
and EEGof a virtual reality assistive technology system,’’ inProc. 9th ACM
Multimed. Syst. Conf. (MMSys), vol. 18, pp. 517–520, Jun. 2018.
[51] M. A. Rahman and M. S. Hossain, ‘‘A cloud-based virtual caregiver for
elderly people in a cyber physical IoT system,’’ in Proc. Cluster Comput.,
Feb. 2018, pp. 1–14.
[52] M. A. Rahman, E. Hassanain, M. M. Rashid, S. J. Barnes, and
M. S. Hossain, ‘‘Spatial blockchain-based secure mass screening frame-
work for children with dyslexia,’’ IEEE Access, vol. 6, pp. 61876–61885,
Oct. 2018.
[53] M. S. Hossain, ‘‘Cloud-supported cyber-physical localization framework
for patients monitoring,’’ IEEE Syst. J., vol. 11, no. 1, pp. 118–127,
Mar. 2017.
[54] M. S. Hossain, S. Hardy, A. Alamri, A. Alelaiwi, V. Hardy, and
C. Wilhelm, ‘‘Ar-based serious game framework for post-stroke rehabil-
itation,’’Multimedia Syst., vol. 22, no. 6, pp. 659–674, 2016.
MD. ABDUR RAHMAN (SM’17) received the Ph.D. degree in electrical and
computer engineering from the University of Ottawa, Canada, in 2011. He is
currently an Assistant Professor with the Department of Forensic Computing
and Cyber Security, University of Prince Muqrin (UPM), Madinah, Saudi
Arabia, where he is also the Chairman. He has authored and co-authored
around 100 publications, including refereed IEEE/ACM/Springer/Elsevier
journals, conference papers, and book chapters. He has seven US patents and
several are pending. His research interests include serious games, cloud and
multimedia for healthcare, the IoT, smart city, secure systems, multimedia
big data, and next generation media. He has received more than 12 million
SAR as research Grant. He received the Best Researcher Award from the
UPM, in 2018. Recently, he received three best paper awards from ACM and
IEEE Conferences. He is a member of the ACM.
M. SHAMIM HOSSAIN (SM’09) received the Ph.D. degree in electrical
and computer engineering from the University of Ottawa, Canada. He is
currently a Professor with the Department of Software Engineering, Col-
lege of Computer and Information Sciences, King Saud University, Riyadh,
Saudi Arabia. He is also an Adjunct Professor with the School of Elec-
trical Engineering and Computer Science, University of Ottawa, Canada.
He has authored and co-authored approximately 200 publications, including
refereed journals, conference papers, books, and book chapters. Recently,
his publication is recognized as the ESI Highly Cited Paper. His research
interests include cloud networking, smart environment (smart city and smart
health), social media, the IoT, edge computing and multimedia for health
care, deep learning approach to multimedia processing, and multimedia
big data. He has served as a member for the organizing and technical
committees of several international conferences and workshops. He was a
recipient of a number of awards, including the Best Conference Paper Award,
the 2016 ACM Transactions on Multimedia Computing, Communications
and Applications (TOMM) Nicolas D. Georganas Best Paper Award, and
the Research in Excellence Award from the College of Computer and Infor-
mation Sciences (CCIS), King Saud University (3 times in a row). He has
served as a Co-Chair, General Chair, Workshop Chair, Publication Chair,
and TPC for over 12 IEEE and ACM conferences and workshops. He is
currently the Co-Chair of the 2nd IEEE ICME workshop on Multimedia
Services and Tools for smart-health (MUST-SH 2019). He serves on the
editorial board of the IEEE TRANSACTIONSONMULTIMEDIA, the IEEENETWORK,
the IEEEMULTIMEDIA, the IEEEWIRELESSCOMMUNICATIONS, the IEEEACCESS,
the Journal of Network and Computer Applications (Elsevier), Computers
and Electrical Engineering (Elsevier),Human-centric Computing and Infor-
mation Sciences (Springer), Games for Health Journal, and the Interna-
tional Journal of Multimedia Tools and Applications (Springer). He also
currently serves as a Lead Guest Editor of the IEEE NETWORK, Future
Generation Computer Systems (Elsevier), and the IEEE ACCESS. Previ-
ously, he served as a Guest Editor of the IEEE Communications Magazine,
the IEEE TRANSACTIONSON INFORMATIONTECHNOLOGY INBIOMEDICINE (currently
JBHI), the IEEE TRANSACTIONS ON CLOUD COMPUTING, the International Jour-
nal of Multimedia Tools and Applications (Springer), Cluster Computing
(Springer), Future Generation Computer Systems (Elsevier), Computers and
Electrical Engineering (Elsevier), Sensors (MDPI), and the International
Journal of Distributed Sensor Networks. He is a SeniorMember of the ACM.
VOLUME 7, 2019 34883
M. A. Rahman et al.: Blockchain-Based Non-Invasive Cyber-Physical OT Framework
MD. MAMUNUR RASHID received the Ph.D. degree from the University
of Cranfield. He received the Ph.D. Scholarship to work at the European
Organization for Nuclear Research (CERN), Switzerland. He was with the
Physics Department, Imperial College London, for three years. He was a
Scientific Research Computing Specialist with the Department of Engi-
neering Science, University of Oxford, for three years. He is currently a
Senior Research Fellow with the King’s Business School, King’s College
London, where he is also with the Consumer and Organizational Digital
Analytics Research Centre (CODA). He now works on solving the diverse
set of problems for finding impacts of the state-of-the-technology in the
area of IoT, big data, blockchain, pattern recognition, smart infrastructure,
future cities, and distributed HPC. In his research career, he has successfully
secured a number of scientific research and travel grants from the Natural
Environment Research Council (NERC) and Newton Fund (British Coun-
cil) with Brazil, Thailand, Turkey, Peru, China, Bangladesh, Kazakhstan,
Azerbaijan, Dubai, Vietnam, and Azerbaijan. He is also involved in a num-
ber of international multidisciplinary collaborative research activities. His
research interests include multi-disciplinary research spectrums focusing on
a force for innovation, scientific discovery, and potentially those can make a
worldwide impact.
STUART J. BARNES has been holding chair positions at other universities,
since 2005. He joined King’s College London, in 2015, where he is currently
a Chaired Professor and the Director of the Centre for Consumer and Orga-
nizational Digital Analytics (CODA), King’s Business School. A polymath,
he is opposed to disciplinary silos and enjoys working across a number
of academic disciplines. He has published five books (one a bestseller for
Butterworth-Heinemann) and more than 150 articles in leading outlets. His
recent research interests include the sharing economy, social media, big
data, mobile communications, virtual reality, and virtual worlds. He has
been involved in more than 50 academic conferences, as a Programme
Committee Member or Track Chair. He is a reviewer for many leading
research grant bodies and journals and an Associate Editor of the Information
and Management.
MOHAMMED F. ALHAMID (M’10) received the Ph.D. degree in computer
science from the University of Ottawa, Canada. He is currently an Assistant
Professor with the Software Engineering Department, King Saud University,
Riyadh, Saudi Arabia. His research interests include recommender systems,
social media mining, big data, and ambient intelligent environment.
MOHSEN GUIZANI (S’85–M’89–SM’99–F’09) is currently a Professor
and the ECEDepartment Chair with the University of Idaho. He has authored
nine books and more than 400 publications in refereed journals and confer-
ences. He served as a member, Chair, and the General Chair of a number of
international conferences. He was the Chair of the IEEE Communications
Society Wireless Technical Committee and the TAOS Technical Committee.
He currently serves on the editorial boards of several international technical
journals, including IEEEWireless Communications Magazine the Editor-in-
Chief (EIC) of IEEE Network Magazine, and the Founder and the EIC of
theWireless Communications and Mobile Computing (Wiley). He serves on
the Advisory board of IEEE INTERNET OF THINGS JOURNAL. He guest edited a
number of special issues in IEEE journals and magazines. He served as the
IEEE Computer Society Distinguished Speaker from 2003 to 2005.
34884 VOLUME 7, 2019
	INTRODUCTION
	BACKGROUND
	MOTOR IMAGERY FOR OCCUPATIONAL THERAPY APPLICATIONS
	MULTIMODAL OCCUPATIONAL THERAPY SENSORS
	FORWARD AND INVERSE KINEMATICS-BASED SERIOUS GAMES
	SYSTEM DESIGN
	BCI SYSTEM OVERVIEW
	HIGH-LEVEL SYSTEM AND SOFTWARE COMPONENTS
	BCI-BASED SERIOUS GAMES DESIGN
	IMPLEMENTATION
	TEST RESULTS
	CONCLUSION
	REFERENCES
	Biographies
	MD. ABDUR RAHMAN
	M. SHAMIM HOSSAIN
	MD. MAMUNUR RASHID
	STUART J. BARNES
	MOHAMMED F. ALHAMID
	MOHSEN GUIZANI