Game-Theoretic Analysis of an Incentivized Verifiable Computation System
Game-Theoretic Analysis
of an Incentivized Verifiable
Computation System
Mahmudun Nabi(B), Sepideh Avizheh,
Muni Venkateswarlu Kumaramangalam, and Reihaneh Safavi-Naini
University of Calgary, Calgary, AB, Canada
{mahmudun.nabi1,sepideh.avizheh1,munivenkateswarlu.ku,rei}@ucalgary.ca
Abstract. Outsourcing computation allows a weak client to outsource
its computation to a powerful server and receive the result of the compu-
tation. Verifiable outsourcing enables clients to verify the computation
result of untrusted servers. Permissionless distributed outsourcing sys-
tems provide an attractive marketplace for users to participate in the
system as a problem-giver who needs solution to a problem, or problem-
solver who is willing to sell its computational resources. Verification of
computation in these systems, that do not assume trusted computational
nodes, is a challenging task. In this paper we provide a game-theoretic
analysis of an incentivized outsourcing computation system, proposed
by Harz and Boman [Harz et al. 2018] (HB), at WTSC 2018 (FC Work-
shop), and show that the system is vulnerable to collusion and Sybil
attacks, that result in incorrect solutions to be accepted by the sys-
tem. We also show that malicious computational node can succeed in
polluting the blockchain. We propose modifications to the system that
incentivizes honest behavior, and improve the system’s correctness guar-
antee. We provide a high-level analysis of the modified system using
our game theoretic approach, and show the effectiveness of the proposed
modifications.
Keywords: Outsourcing computation · Verifiable distributed
computation · Rational adversaries · Incentivized security
1 Introduction
Outsourcing computation is an intriguing concept that enables clients to expand
their computational power when needed. The rise of cloud computing in recent
years has been the driving force of outsourcing computation in a variety of set-
tings. Outsourcing to cloud has made computationally expensive applications,
such as complex analytics, available to small mobile devices, and has enabled
clients to run resource intensive applications by purchasing the required compu-
tational resources from cloud providers. In both these cases the user interacts
c© International Financial Cryptography Association 2020
A. Bracciali et al. (Eds.): FC 2019 Workshops, LNCS 11599, pp. 50–66, 2020.
https://doi.org/10.1007/978-3-030-43725-1_5
http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-030-43725-1_5&domain=pdf
https://doi.org/10.1007/978-3-030-43725-1_5
Game-Theoretic Analysis of an Incentivized Verifiable Computation System 51
with a single cloud provider, and the service is paid for indirectly (e.g. through
purchase of a device), or directly, from the cloud. The idea of computation as
a commodity that can be bought and sold in a market-place has gained attrac-
tion with the development of cryptocurrencies that enable payment for services
using blockchains. Outsourcing however has many security and privacy challenges.
The outsourcer (O) and the computational nodes (contractors) in general are not
mutually trusting, and each party may attempt to subvert the system for their
own goals. The most basic security goal of the outsourcer is the correctness of the
computation. Verifiable computation enables the outsourcer to verify the correct-
ness of the result using efficient verification algorithms. Cryptographic schemes for
verifiable computation [5,10,13] guarantee high level of security but are inflexible
and incur heavy computational cost. A second approach is by assuming rational
adversaries and designing mechanisms to incentivize honest behavior, and guar-
antee correctness of the results [2,7,9,12]. These systems however need complex
management processes (e.g. managing rewards, punishments, auditing) to arrive
at the correct result, and so may not be appealing to average user.
Two recently proposed systems, TrueBit [8,14], and a system proposed by
Harz and Boman (HB) [6], attempt to remove this complexity introducing an
intermediate layer between the outsourcer and the contractors. The intermediate
layer receives a request from the outsourcer, recruits contractors, and runs a
public protocol with the guarantee that correct results will be delivered to the
outsourcer, and that the contractors are paid for their services. Both systems
are implemented in Ethereum platform, and use the trustable computation of
Ethereum as the ultimate truth in arriving at the correct result. The goal is
to achieve the same correctness guarantee of Ethereum while minimizing the
actual request from computation Ethereum. This can be seen as performing
computation “off-chain”, and use Ethereum to verify the results.
The correctness guarantee in both systems relies on rewards, bounties, jack-
pots and similar incentives, and assumes rational entities. TrueBit has a detailed
white paper that discusses possible attacks, which are further discussed in blog
posts, and other platforms. HB paper provides a high level argument about pos-
sible attacks and security of the system. None of the systems have formal game
theoretic analysis in part due to the complexity of modelling the range of attack
goals and colluding strategies in a highly distributed and permissionless systems.
Our Work. Our motivation is to provide game a theoretic framework for analy-
sis of non-permissioned incentivized verifiable computation systems that use an
intermediate layer. The variety of attack goals and possible collusions, make this
analysis a daunting task. We start with HB, which compared to TrueBit, uses
stronger trust assumptions which makes in more amenable to analysis. The HB
system, is implemented as the Arbiter, an Ethereum smart contract that enforces
the execution of the required steps of the verifiable computation process.
In HB, there is an outsourcer, called problem-giver, who outsources a compu-
tation. Following [2,9], we assume that the outsourced computation is composed
of a finite number of atomic operations. Also, we define the inner state of an
algorithm as the concatenation of all the input/outputs of the atomic operations
52 M. Nabi et al.
of the algorithm. Computational nodes (contractors) are problem-solvers and
verifiers, the former providing a solution to the outsourced computation, and
the latter verifying the solution.
Our game theoretic analysis of HB system, although primarily focuses on the
rational contractors (solver and verifiers) that have well-defined utilities, will
also allow us to evaluate security against irrational behaviour where contractors
are not driven by their utilities. This approach was first considered in [2,9] in
which each contractor may behave rationally (diligent or lazy), or be honest
or malicious irrespective of their utilities. In Sect. 6 we also consider goal driven
contractors (irrational and malicious) who are not bounded by a utility function.
The goal of these malicious contractors is to corrupt the blockchain.
For rational behaviors, we first derive a payoff matrix for the HB system when
each contractor behaves independently (chooses to be diligent or lazy on its own),
assuming the same q-algorithm is used by all lazy contractors. Table 2 shows the
payoff of a solver and verifier when the set of other verifiers consist of all lazy,
all diligent, or a combination of the two. The analysis shows that, depending
on the system parameters, for an independent contractor (solver/verifier) being
diligent results in the highest utility. To analyze the system, we consider all
possible scenario in the system, for instance, one contractor (solver/verifier)
being diligent or lazy against the rest of the system that is lazy and, show that
being diligent is better for an independent contractor (see Sect. 4.1).
We then consider collusions where the colluding contractors agree to follow
a single behavior (diligent or lazy), and share the reward equally. We obtain the
system’s payoff matrix when the set of N contractors, that are chosen by the
Arbiter, consists of a colluding set, and two sets of contractors that are work-
ing lazily and diligently, but without any coordination (independently choosing
their behaviour). Our analysis shows that, being part of a collusion maximizes a
contractor’s utility. We also analyze the system for Sybil attacks where a single
contractor participate in the system using multiple identities (see Sect. 4.2). Our
analysis shows that existing incentive structure of HB system cannot guarantee
correct result.
In Sect. 5 we propose modifications to the HB system with the goal of improv-
ing the correctness guarantee. These consists of modifications that are necessary
to ensure the incentives for diligent behavior to guarantee correct result, and
make the system robust against the lazy behavior in both collusion and Sybil
attacks. In HB, if all the contractors (independently or colluding) return the
same incorrect results, the Arbiter accepts this as a correct result. We propose
changes to HB system and show that the modified system alleviates such vul-
nerabilities and, guarantees high correctness (see Sect. 5). These modifications
although improve the correctness of HB system but does not prevent collusion
and Sybil attacks. We also propose modifications that would intuitively make the
system more socially fair. In particular using the deposits of the lazy contractors
to encourage diligent behavior.
Paper Organization: Sect. 2 gives an overview of the HB system, and Sect. 3
presents its game analysis. In Sect. 4, two attacks (collusion and Sybil) using
Game-Theoretic Analysis of an Incentivized Verifiable Computation System 53
different attack strategies are analyzed. Our modifications of HB system and
their analysis are in Sects. 5 and 6, respectively. Section 7 is the related work,
and Sect. 8 concludes the paper.
2 HB System
Ethereum is a permissionless blockchain that is known as consensus computer,
meaning that a computation that is sent to Ethereum will be executed by all
agents and as long as more than 50% of agents are honest, the computation result
will be correct. To prevent attacks such as denial of service however, Ethereum
introduces a gas limit to put a bound on the complexity of the requested com-
putation, and so larger computations must be performed off-chain. HB [6] aims
to extend correctness guarantee of Ethereum to off-chain computations.
Table 1. HB incentive structure for different behaviors of a solver and verifier
Verifier V Solver S
Incorrect Correct
Challenge S: receives nothing, loses Ds
V : receives vfee + sfee + fee shares of
all accepting verifiers
(accepting verifiers receives nothing,
loses Dv)
S: receives sfee + fee shares of all
challenging verifiers
V : receives nothing, loses Dv
(accepting verifiers receives vfee)
Accept S: receives sfee
V : receives vfee
S receives sfee
V : receives vfee
The entities of the HB system are: Problem-giver, Problem-solver, Verifier,
Arbiter and the Judge. Problem-givers are Ethereum users who outsource their
computations for rewards. The solver is a computational contractor who provides
computation power to solve computation problems in exchange for receiving
a reward, sfee. Verifiers are computational contractors who are contracted to
provide computation power to correctly verify the solver’s solutions for a reward,
vfee, by redoing the computation. Both these types of contractors must pay a
deposit to participate in the computation. Arbiter is an Ethereum smart contract
that enforces the execution of the required steps of the verifiable computation
process. Arbiter acts as an intermediary between the problem-giver and the
other entities. For each computation request that it receives from problem-giver,
Arbiter randomly selects N contractors from the pool of registered contractors,
and randomly chooses one as the problem-solver and the remaining (N − 1)
as verifiers V = {v1, . . . , vN−1}. The solver publishes a solution together with
a hashed trace of computation in the form of a Merkle tree to allow efficient
checking of the results. The assumption is that the computational steps run
by different contractors will produce the same values and so the same hashes.
Verifiers also perform the computation and construct their own local hash tree,
and publish the solution. The solution that is provided by the solver will be
54 M. Nabi et al.
challenged by the verifiers who find inconsistencies between solver’s solution
and their own. Arbiter compares the provided solutions and initiate a dispute
resolution if the solutions do not match, in which case a step-by-step comparison
of the hash tree of the solver and a verifier is performed, and inconsistencies will
be resolved by sending a random computational step to the Ethereum (Judge).
Judge resolves the dispute and find whether the solver’s computation is correct
or not. If it is correct, the process continues as long as a verifier challenges the
solver’s solution. After all challenges are resolved, the problem-giver receives
the results of the computation. If the solver is found incorrect the computation
terminates.HB assumes that Arbiter, judges and problem-givers are trusted and
correctly follow the protocol. Table 1 shows the distribution of rewards in HB for
different behaviors of a solver and verifier.
3 Game-Theoretic Analysis of HB
In HB, a problem-giver outsources its computation to a registered subset of
contractors who are randomly selected by Arbiter. The registration fee of the
contractors will be returned if they are not caught violating the verifiable com-
putation algorithm. The deposits of the selected contractors will be used as part
of rewards and fines that will be applied to the contractors, in addition to the
fee which will be paid by the problem-giver to the contractors whose work have
not been challenged. We assume a contractor will participate in a computation
when the received reward is higher than the cost of performing the task. A ratio-
nal contractor, solver or verifier, perform the computation honestly as long as
the utility of performing the task correctly is greater than doing it otherwise. A
diligent rational contractor performs the task honestly, and returns the correct
result. A lazy contractor uses a tricky algorithm that can return the correct
result with probability q (see Definition 1).
Definition 1 (q-algorithm). An algorithm, composed of a finite number of
atomic operations, is called a q-algorithm if it generates the correct solution with
probability q, and such that 0 ≤ cost(q) < cost(1). Here, cost(q) denotes the cost
of employing a q-algorithm and cost(1) is the cost of the honest computation.
We assume that the chance of a guessed solution being correct is nearly zero.
In HB a solution will be accompanied with the hash tree of the computation
steps. Thus even if the q-algorithm can find the solution, the chance of generating
the same inner state hashes as the original algorithm, will be negligible (i.e.,
q ≈ 0). The inner state of an algorithm can be captures at different granularity
and will include the computational module input and output. We also assume
all lazy nodes use the same (best) q-algorithm.
Payoffs When Contractors Behave Independently. We consider a multi-
contractor game with one solver s and N−1 verifiers V = {v1, . . . , vN−1}, N > 1,
and assume each contractor chooses its behaviour independently. The fee for a
Game-Theoretic Analysis of an Incentivized Verifiable Computation System 55
solver’s correct solution is sfee and so a diligent solver will always receive this
fee. The fee for a verifier whose result is accepted by the Arbiter is vfee. If a
lazy contractor is caught (with probability 1 − q), his reward is distributed to
contractors who have challenged it.
We first analyze the system assuming contractors work independently. Let
ux,y
z (q) denotes the utility function of a contractor of type x, whose behavior is
of type y, when there are total z lazy contractors (among the selected contractors)
for the given computation. We use x ∈ {s, v, c}, where s denotes the solver, v
denotes the verifier and c denotes the colluder, y ∈ {d, �} where d and � denote
the diligent and lazy behaviors, respectively, and z ∈ {0, 1, . . . , N}. For diligent
contractors, q = 1, otherwise q < 1. Also, the utility of any contractor ux,y
z (q) is
linear in the reward and losses. Table 2 shows the utility of contractors.
If a contractor of type x behaves diligently, and challenges a lazy contractor’s
incorrect solution, its utility will be, ux,d
z (1) = r + b(1 − q) − cost(1), where r
denotes the reward for honest computation, r = sfee if x = s or r = vfee if x = v,
and b will be the additional reward (reward share of the lazy contractor) that a
diligent contractor receive by challenging the lazy contractor. A lazy contractor
cannot win a challenge against a diligent contractor because Ethereum will be
used as the ultimate truth. In HB, a solver can challenge the verifiers, and
the verifiers can challenge the solver. But, a verifier cannot challenge the other
verifier. If a contractor x is lazy its utility is, ux,l
z (q) = rq − f(1 − q) − cost(q),
where f is the fine that a lazy contractor, who is caught, pays for providing an
incorrect solution. As long as there is one diligent contractor, the system’s final
result will be correct and all the lazy contractor will be caught. Table 2 gives
the payoff matrix of the game. Using the Table 2, in Sect. 4 we analyze the HB
system for collusion and Sybil attacks.
Table 2. The payoff table of a solver against all verifiers, when each contractor (s and
v) choose their behaviour (diligent or lazy) independently, assuming all lazy contractors
use the same q-algorithm.
Verifiers Solver
Diligent Lazy
k2 lazy
(k3 =
N − 1 − k2
diligent)
u
s,d
k2
(1) = sfee + k2vfee(1 − q) − cost(1)
u
v,d
k2
(1) = vfee − cost(1)
u
v,l
k2
(q) = vfeeq − Dv(1 − q) − cost(q)
u
s,l
k2+1(q) = sfeeq − Ds(1 − q) − cost(q)
u
v,d
k2+1(1) = vfee +
sfee+k2.vfee
k3
(1 − q) − cost(1)
u
v,l
k2+1(q) = vfeeq − Dv(1 − q) − cost(q)
All diligent
(k2 = 0,
k3 =
N − 1)
u
s,d
0 (1) = sfee − cost(1)
u
v,d
0 (1) = vfee − cost(1)
u
s,l
1 (q) = sfeeq − Ds(1 − q) − cost(q)
u
v,d
1 (1) = vfee +
sfee
k3
(1 − q) − cost(1)
All lazy
(k2 =
N − 1,
k3 = 0)
u
s,d
N−1(1) = sfee + k2vfee(1 − q) − cost(1)
u
v,l
N−1(q) = vfeeq − Dv(1 − q) − cost(q)
u
s,l
N
(q) = sfee − cost(q)
u
v,l
N
(q) = vfee − cost(q)
56 M. Nabi et al.
In Table 2, k2 and k3 represents the number of independent lazy and inde-
pendent diligent verifiers, respectively. Note that, row 2 and row 3 in the Table 2
can be obtained by substituting the respective k2 and k3 values in row 1. We
presented them separately here to show the utilities of all the involved parties
in all the possible scenarios.
4 Attacks on HB System
We consider two attacks: (i) Collusion attack where multiple contractors who
have been selected by the Arbiter, form a collusion. The colluders divide the
computation task among themselves, each performing a fraction of the compu-
tation and sharing the results to construct a common output. They also share
the payment from the system. And, (ii) Sybil attack where a single contractor
registers under multiple identities in the hope of being selected multiple times
in the set chosen by the Arbiter to increase their utility.
4.1 Collusion Attack in HB System
Let k1 be the collusion group size where 1 < k1 ≤ N . When k1 �= N , we
also assume that the system may have two other sets of contractors, say k2,
0 ≤ k2 < N who are independently lazy and k3 = N − (k1 + k2), 0 ≤ k2 < N ,
who are independently diligent. Note that, for a computation task, the values of
k2 and k3 are unknown to the collusion group k1. We consider the following two
cases to analyze the collusion attack.
The Solver is in the Collusion. The colluder’s set consists of a solver and a
set of verifiers. The remaining verifiers may be independently lazy or diligent.
The k1 colluders can either act diligently (i.e. share the computation of the
correct algorithm) or lazily (i.e., by sharing the computation cost of the same
q-algorithm). Let δc be an indicator value, δc ∈ {0, 1} defined as, δc = 1 if the
solution of lazy participant is challenged, and δc = 0, if it is not. Table 3 shows
the utilities in the game between the colluding contractors (solver and verifiers)
and the remaining independent contractors.
Table 3. Utility table for solver-verifier collusion game.
Verifiers Colluders
Diligent Lazy
k2 lazy
verifiers
u
c,d
k2
(1) = r +
k2.vfee
k1
(1 − q) − cost(1)
k1
u
v,l
k2
(q) = rq − Dv(1 − q) − cost(q)
u
c,l
k1+k2
(q) = rq + r(1 − q)(1 − δc) − D(1 − q)δc − cost(q)
k1
u
v,l
k1+k2
(q) = rq + r(1 − q)(1 − δc) − D(1 − q)δc − cost(q)
k3
diligent
verifiers
u
v,d
k2
(1) = r − cost(1) u
v,d
k1+k2
(1) = r +
(k1+k2).vfee
k3
(1 − q) − cost(1)
Game-Theoretic Analysis of an Incentivized Verifiable Computation System 57
We use the table to evaluate stability of a collusion. That is, a member of
the colluding group will have a higher utility to stay in the collusion. Note that
the colluding group also have two behaviour, diligent and lazy. If the colluders
behave diligently, the collusion will be stable if the colluders have higher utility
than being independent contractors. That is,
– Case 1: uc,d
k2
(1) > uv,l
k2
(q) (when k2 verifiers are independently lazy), and
– Case 2: uc,d
k2
(1) > uv,d
k2
(1) (when k3 verifiers are independently diligent).
For a given set of system parameters, we will have uv,l
k2
(q) > uv,d
k2
(1), or the
reverse. So, we choose uc,d
k2
(1) > max{uv,l
k2
(q), uv,d
k2
(1)}. This gives the following
results (using Table 3):
– if uc,d
k2
(1) > uv,l
k2
(q), we get k1 > cost(1)
(r+Dv)(1−q)+cost(q) , and
– if uc,d
k2
(1) > uv,d
k2
(1), we get k1 > 1.
This implies that for a given set of system parameters as long as the collusion
size is higher than the corresponding k1, the diligent colluding strategy will have
higher pay-off than working independently (diligent or lazy), and so the collusion
will be stable.
Similarly, if the colluders behave lazily, to have higher utility than indepen-
dent contractors, the following should be true:
– Case 3: uc,l
k1+k2
(q) > uv,l
k1+k2
(q) (when k2 verifiers are independently lazy), &
– Case 4: uc,l
k1+k2
(q) > uv,d
k1+k2
(1) (when k3 verifiers are independently diligent).
Using a similar argument as above, a collusion remains stable if the follow-
ing is satisfied: uc,l
k1+k2
(q) > max{uv,l
k1+k2
(q), uv,d
k1+k2
(1)}. Using the utilities from
Table 3 we get the following results:
– if uc,l
k1+k2
(q) > uv,l
k1+k2
(q), then k1 > 1, and
– if uc,l
k1+k2
(q) > uv,d
k1+k2
(1), k1 > cost(q)
cost(1)−(1−q)[(N−1)Vfee+r+D] .
Note that the bounds only depend on the system parameters and so can be
computed by a contractor. In other words, a contractor can decide to be inde-
pendent, or stay in the collusion based on the size of the colluding set. The above
analysis leads to the following theorem.
Theorem 1. (a) For a given set of system parameters, there are values for the
colluding set size k1, for which being diligent, or being lazy has higher utility
than being an independent contractor.
(b) For values of k1 for which both collusion behaviours (diligent and lazy) allow
stable collusion, one can find the best strategy (the strategy with the highest
utility) of colluders (diligent or lazy) that maximizes their utility.
58 M. Nabi et al.
Note that based on the system parameters of HB, solver-verifier collusion is
possible as long as the collusion size is higher than the corresponding k1.
In HB, if colluders act diligently when k1 < N , we get k1 > cost(1)− cost(q)
(r+D)(1− q) .
Since cost(q) < cost(1) ≤ r and q ≈ 0 (e.g. by using inner state hash [2]),
r + D > cost(1) − cost(q). So, cost(1)− cost(q)
(r+D)(1− q) < max{1, cost(1)
(r+D)(1− q)+cost(q)}.
So, in this case, the best strategy is to act diligently. However, when k1 = N ,
since δc = 0 and q = 0 (in HB), from Table 3 we get r − cost(q)
k1
> r − cost(1)
k1
. So,
in this case being lazy is the best strategy.
Collusion of Verifiers Only. Assume that k1 verifiers are colluding and doing
the computation jointly. The colluders may act diligently, or lazily. The remain-
ing contractors, consist of k2 lazy, and k3 = N − (k1 + k2) diligent, contractors.
As the solver is an independent contractor, it may be in the diligent, or in the
lazy group. Table 4 shows the payoff of a colluding verifier against the payoff of
an independent verifier in each case.
Table 4. Pay-off matrix for verifiers collusion game
Remaining contractorsColluding verifiers (k1)
Solver Verifiers Diligent Lazy
Diligentk2 Lazy u
(c,d)(s,d)
k2
(1) = vfee − cost(1)
k1
u
(c,l)(s,d)
k1+k2
(q) =
vfeeq − Dv(1 − q) − cost(q)
k1
k3 − 1
Diligent
u
(v,l)(s,d)
k2
(q) =
vfeeq − Dv(1 − q) − cost(q)
u
(v,l)(s,d)
k1+k2
(q) =
vfeeq − Dv(1 − q) − cost(q)
u
(v,d)(s,d)
k2
(1) = vfee − cost(1) u
(v,d)(s,d)
k1+k2
(1) = vfee − cost(1)
Lazy k2 − 1
Lazy
u
(c,d)(s,l)
k2
(1) =
vfee +
sfee+(k2−1)vfee
k1+k3
(1−q)− cost(1)
k1
u
(c,l)(s,l)
k1+k2
(q) = vfeeq + vfee(1 − q)(1 −
δc) − Dv(1 − q)δc − cost(q)
k1
k3
Diligent
u
(v,l)(s,l)
k2
(q) =
vfeeq − Dv(1 − q) − cost(q)
u
(v,l)(s,l)
k1+k2
(q) = vfeeq + vfee(1 − q)(1 −
δc) − Dv(1 − q)δc − cost(q)
u
(v,d)(s,l)
k2
(1) =
vfee +
sfee+(k2−1)vfee
k1+k3
(1−q)−cost(1)
u
(v,l)(s,l)
k1+k2
(1) = vfee +
sfee+(k1+k2−1)vfee
k3
(1 − q) − cost(1)
Using an argument similar to the above case (solver is in the collusion),
we will have: u
(c,d)(s,d)
k2
(1) > max(u(v,l)(s,d)
k2
(q), u(v,d)(s,d)
k2
(1)) and u
(c,d)(s,l)
k2
(1) >
max(u(v,l)(s,l)
k2
(q), u(v,d)(s,l)
k2
(1)).
For colluders behaving lazily a collusion remains stable if the followings
are satisfied: u
(c,l)(s,d)
k1+k2
(1) > max(u(v,l)(s,d)
k1+k2
(q), u(v,d)(s,d)
k1+k2
(1)) and u
(c,l)(s,l)
k1+k2
(1) >
max(u(v,l)(s,l)
k1+k2
(q), u(v,d)(s,l)
k1+k2
(1)).
These give lower bounds on collusion sizes for which colluders will have higher
utility with their corresponding strategies, compared to playing independently.
From the above analysis it is proved that HB system cannot protect against
colluding attacks.
Game-Theoretic Analysis of an Incentivized Verifiable Computation System 59
4.2 Sybil Attack in HB System
Consider an attacker who creates K Sybil identities hoping that k1 of them are
selected. Additionally, consider n identities in the system and N of them are
selected for a given task. Then K can be estimated as follow: If n and N are
large, then the proportion of identities that belongs to the attacker, K
n , is equal
to the proportion of identities chosen for the given task, k1
N . In another way,
k1
N = K
n . So, attacker should create K = k1
N n identities in order to gets k1 of
them accepted for a given task. Sybil attack can happen when all the selected
identities of the Sybil node are verifiers, or it also includes the solver.
We consider two cases: k1 < N and k1 = N . If k1 < N , we consider k2 inde-
pendently lazy verifiers and k3(= N − k1 − k2) independently diligent verifiers.
Otherwise, if k1 = N , k2 = k3 = 0. Sybil attack can be seen as a realization of
collusion attack with the difference that the Sybil attacker must provides deposit
for all k1 identities and will receive all the rewards, and so instead of considering
the utility of a member of the collusion, we will consider the utility of the whole
colluding. Using the analysis similar to previous section we have the following.
Sybil Identities Includes the Solver. Let U(a, b) represents the total utility
of the Sybil attacker for strategy a ∈ {d, l}, when b ∈ {0, 1, . . . , N} is the number
of identities that are selected by the Arbiter. If the solver is in k1, then,
– when k1 < N the total utility for the diligent strategy is: U(d, k1) = k1.[r +
k2.vfee
k1
(1 − q)] − cost(1).
– when k1 = N the total utility for the lazy strategy is: U(l, N) = N.r−cost(q)
Here, r = sfee for solver (or vfee for verifier), and D is the registration cost (i.e.,
deposit) by contractor. As these utilities are greater than one diligent identity,
Theorem 1 holds, Sybil attack of solver-verifiers is possible.
We note that the probability of k1 = N will be very small for large values of
N , the registration cost of registered identities would become formidable.
Sybil Attack of Verifiers. Analysis of collusion attack showed that for a given
k1, being diligent is the better strategy. Where as a Sybil attacker does not know
how the solver would act, so we have two cases:
– If solver is diligent, the total utility for the attacker is: U(d, k1) = k1(vfee) −
cost(1).
– If solver is lazy, the total expected utility for the attacker is: U(l, k1) =
k1[vfee + sfee +(k2 − 1)vfee
k1 + k3
(1 − q)] − cost(q).
These utilities are higher than the utility of a single diligent identity and
using the similar analysis we can show that Sybil attack of verifiers is possible.
60 M. Nabi et al.
4.3 Shortcoming of HB
The above analysis of HB showed that it is vulnerable to both collusion and
Sybil attacks. Below are additional shortcoming of the system.
– In HB, when a contractor is lazy and is caught, the diligent contractors who
catch the lazy contractor gets its reward shares (additional reward) that is
committed by the problem-giver prior to the computation. We suggest that
the additional reward should be harvested from the fine that the lazy con-
tractor pays rather than charging the problem-giver.
– In HB, the deposit (D) amount is set by the Arbiter and the contractors
pay this amount before the problem-giver requests for a computation to the
Arbiter. This deposit works as a commitment to the system and will not be
returned to the contractor if it gets caught by cheating. However, as the task
difficulty is unknown to the Arbiter, the deposit value set might be so little
to ensure the honest computation. The deposit value should be fixed based
on the task difficulty.
5 HB+ System
The analysis in of HB showed that it is vulnerable to both collusion and Sybil
attacks. In this section, to improve the correctness guarantee of HB system, for
the attacks presented in Sect. 4, we propose the following modifications to the
original HB system, and we call it HB+. Finally, we analyze the effectiveness of
these modifications on the HB system.
Random Audit. We propose the following changes to HB system to alleviate
the Sybil attack discussed in Sect. 4.2. The idea is, when all the contractors return
same result, Arbiter randomly audits (i.e., probabilistic auditing) the results
using the Judge (Ethereum). The random auditing involves of two parties: the
Arbiter, who triggers this auditing by sending an intermediary result of a step
stored in a Merkle tree and input, if any, to Judge for the given computation.
The Judges, who are the set of miners in Ethereum, returns a boolean value to
Arbiter: If the judge returns true, the solver and the verifiers get their reward.
Otherwise, the Arbiter penalize the solver and the verifiers by taking away their
deposits and reassign the computation to another group of contractors.
Operational Flow of HB+ System. In HB, each contractor commits a
deposit to Arbiter for participating in the system that is independent of problem-
giver’s computation. It may so happen that the deposit amount is much smaller
than the reward (that is calculated based on the complexity of the computa-
tion) for computing results. Because of this, the system is vulnerable to attacks
such as Sybil. For example, within its financial limits, a rational contractor
(Sybil attacker) may create multiple identities to increase its chances of being
selected for the computation expecting huge rewards. This causes questioning
Game-Theoretic Analysis of an Incentivized Verifiable Computation System 61
the correctness guarantee of the system. To avoid such scenarios, we propose
that the Arbiter should determine the deposit amount independently for each
computation requested based on computation complexity. In more detail, the
deposit amount should be fixed after receiving the computation request from
the problem-giver. Then, the interested contractors commit this fixed deposit
and register to the Arbiter for the computation.
HB+ Incentive Structure. In HB, when a diligent contractor challenges an
incorrect solution published by a lazy contractor, the diligent contractor receive
an additional reward (bonus) for helping the system to catch the cheating con-
tractor and the lazy contractor loses his deposit. The bonus given to the diligent
contractor is actually the reward that is originally committed by the problem-
giver (when the computation is requested) for the contractor who has been
caught for his lazy behavior. Since HB assumes that the problem-givers are
rational, they always try to optimize (minimize) their cost (payment) for their
requested computation. Therefore, to encourage the problem-givers to use the
system often and for social good, we propose to use the deposits paid by the
cheating contractors to reward diligent contractors instead of using problem-
givers payment.
Based on the proposed idea of using lazy contractors deposits to reward dili-
gent contractors and the probabilistic auditing mechanism presented in Sect. 5,
we modify the HB incentive structure (given in Table 1) and present a modified
incentive structure in Table 5. To be consistent, in Table 5 we use the notations
that are defined already (see Sect. 2) and, with an additional one, β to denote
the probability of an Arbiter performing random auditing.
Table 5. New incentive structure of a solver and verifier with different behaviors in
the modified HB system
Verifier V Solver S
Incorrect Correct
Challenge S losses Ds S receives sfee + Dv
V receives vfee + Ds V losses Dv
Accept S receives sfee(1 − β) S receives sfee
S losses Dsβ
V receives vfee(1 − β) V receives vfee
V losses Dvβ
In Table 5, when a solver’s incorrect solution is challenged by a verifier, S
does not receive reward (sfee) and losses his deposit Ds and (each) challenger
(verifier) receives its reward (vfee) with an additional reward, a share of Ds,
as a bonus (for example, if there are Nc challengers, then each challenger will
get vfee + Ds/Nc. If a verifier challenges correct solution of a solver, it losses
Dv and does not receive any reward and, S gets his reward and deposits of all
62 M. Nabi et al.
the challengers as a bonus. When the results are same, using the Judge, Arbiter
verifies the results randomly with probability β. For example, in the Table 5,
when the solver’s solution is incorrect and the verifier accepts it (i.e., the results
are same), both S and V either loss their deposits with probability β or receive
their rewards with (1 − β) probability.
5.1 Analysis of HB+
Let β ∈ [0, 1] be the probability of auditing by the Arbiter when the returned
results are same. We assume that Arbiter sets the deposit D based on the task
difficulty. Although each contractor provides the same amount of deposit for
participation, we use Ds (solver’s deposit) and Dv (verifier’s deposit) same as
before (in Sect. 3) to distinguish them, where D = Ds = Dv. However, in this
modified model the usage of the deposit is different than the original HB system.
That is instead of burning the deposits of the cheating parties they will be
distributed among the honest parties as a bonus. Based on these assumptions
and changes, the game pay-off Table 2 of original HB updated and new utilities
are shown in Table 6.
Table 6. Pay-off matrix of the modified HB
Verifiers Solver
Diligent Lazy
All diligent u
s,d
0 (1) = sfee − cost(1) u
s,l
0 (q) = sfeeq − Ds(1 − q) − cost(q)
u
v,d
0 (1) = vfee − cost(1) u
v,d
0 (1) = vfee + Ds
N−1 (1 − q) − cost(1)
k lazy N − 1 − k
diligent
u
s,d
k
(1) = sfee + kDv
N−k
(1 − q) − cost(1) u
s,l
k
(q) = sfeeq − Ds(1 − q) − cost(q)
u
v,d
k
(1) = vfee + kDv
N−k
(1 − q) − cost(1) u
v,d
k
(1) = vfee+
Ds+kDv
N−1−k
(1−q)−cost(1)
u
v,l
k
(q) = vfeeq − Dv(1 − q) − cost(q) u
v,l
k
(q) = vfeeq − Dv(1 − q) − cost(q)
All lazy u
s,d
N−1(1) =
sfee + (N − 1)Dv(1 − q) − cost(1)
u
s,l
N−1(q) = sfeeq + sfee(1 − q)(1 − β)
−Ds(1 − q)β − cost(q)
u
v,l
N−1(q) = vfeeq − Dv(1 − q) − cost(q)
u
v,l
N−1(q) = vfeeq + vfee(1 − q)(1 − β)
−Dv(1 − q)β − cost(q)
Using the above utilities, and the analysis presented in Sect. 4, it can be
shown that with the modified utilities presented in Table 6, collusion attack
is still possible. But, the possibility of Sybil attack is reduced, because of the
probabilistic auditing, even if all sybil identities output the same solution.
5.2 Malicious Contractors
Malicious contractors aim at polluting the blockchain by making the Arbiter
accept an incorrect solution. They will collude and share their budgets to harm
the system. To have enough, non-negative, balance to participate in the tasks
they will act honestly time to time. The following theorem shows the best strat-
egy for malicious contractors.
Game-Theoretic Analysis of an Incentivized Verifiable Computation System 63
Theorem 2. The best strategy for malicious contractors is to all collude when
they are selected for a given task.
Proof. As we have previously shown in Table 6, whenever all contractors reveal
the same incorrect solution and when there is no auditing by judges, β = 0,
Arbiter accepts the incorrect solution and the utility of each contractor is,
ux,m
z (0) = r(1 − β) = r.
Theorem 3 shows the bound for the expected false rate which is the number
of incorrect solutions broadcasted to blockchain if malicious contractors follow
strategy given in Theorem 2.
Theorem 3. The expected false rate in the system is pN (1−β), where N is the
number of computation services, p, is the prior probability that a contractors is
malicious in the system, and β is probability of auditing by the judges.
Proof. If all the N chosen contractors are malicious they can collude and reveal
an incorrect solution. The probability of this case is pN . However, they may
be challenged by judges with probability β if all reveal the same solution. The
probability that they are not challenged is 1−β, therefore the attackers succeed
with probability pN (1 − β).
According to Theorem 3, we gain a reduction on the expected false rate
proportional to 1 − β compared to HB. In the next section we compare our
result with HB assuming some values for p, N and β.
6 Evaluation and Comparison
Table 7 shows the expected false solutions broadcasted to blockchain in HB+
versus HB. The prior probability of being lazy is selected to be 0.3, 0.5 and
0.7 to facilitate the comparison to HB. According to HB, if solver reveals a
wrong solution and verifiers accept it then false solution goes to blockchain; if
the probability that a computation service be lazy and output a wrong solution
is p, and the number of verifiers is n, then the probability of false solution to be
accepted is pn+1 (N = n + 1). In our scheme, however, the expected false rate
also depends on the probability of auditing; if a task is audited by judges with
probability β then the probability of false solution accepted will be pn+1(1−β).
For comparison, we have considered β to be 0.1, 0.5, and 0.9. According to table,
the probabilistic auditing reduces the expected false percentage proportional to
1 − β. We expect to see more reductions in practice as the auditing time is
unknown to computation services.
7 Related Work
In blockchain, transactions must be validated and processed at every node in the
network. So, any blockchain system experiences limitations in scalability. Out-
sourcing computation techniques have been proposed in various papers address-
ing the scalability and security challenges of a blockchain [6,8,14]. Trust models
64 M. Nabi et al.
Table 7. Comparison between expected false in our scheme and HB.
Prior p Verifiers n Expected false [%] Expected false HB [%]
β = 0.1 β = 0.5 β = 0.9
0.3 1 8.1 4.5 0.9 9.0
2 2.43 1.35 0.27 2.7
3 0.729 0.405 0.081 0.81
4 0.2187 0.1215 0.0243 0.243
5 0.06561 0.03645 0.00729 0.0729
6 0.019683 0.010935 0.002187 0.02187
0.5 1 22.5 12.5 2.5 25.0
2 11.25 6.25 1.25 12.5
3 5.625 3.125 0.625 6.25
4 2.8125 1.5625 0.3125 3.125
5 1.40625 0.78125 0.15625 1.5625
6 0.703125 0.390625 0.078125 0.78125
0.7 1 44.1 24.5 4.9 49.0
2 30.87 17.15 3.43 34.3
3 21.609 12.005 2.401 24.01
4 15.1263 8.4035 1.6807 16.807
5 10.58841 5.88245 1.17649 11.7649
6 7.411887 4.117715 0.823543 8.23543
(based on incentive mechanism) [6,8,14] are proposed to off-chain the compu-
tations to third parties to inherit transparency and particular trust for imple-
menting smart contracts in permission-less blockchains. ZoKrates [4], shares the
same spirit of off-chaining computations to third parties by supplying a non-
interactive zero-knowledge proof with the results. Moreover, several works have
been proposed to incorporate multiparty computation onto blockchains [1,11].
In addition, Dong et al. [3] provide a game theoretical analysis for verifiable out-
sourced computation in cloud computing that involves blockchain technology.
The authors assume only two rational clouds who can collude and later one can
secretly deviate from the collusive agreement to maximize their own profit. The
authors design smart contracts to sabotage collusion. In case of our analysis,
we assume that once collusion is formed, colluders do not deviate from their
agreement and the goal is to prevent collusion from happening. Moreover, we
have considered both rational and malicious adversaries for our analysis. Finally,
their system needs a trusted third party to resolve conflicts where the HB system
resolves the dispute through the distributed consensus algorithms (i.e., by using
Ethereum as Judge) and removes the need of a trusted third party. In [12] the
authors researched the outsourced verification computation from an economics
aspect. They provided a general approach based on game theory for optimal
Game-Theoretic Analysis of an Incentivized Verifiable Computation System 65
contract design for outsourcing computation. They considered the cheating or
lazy behavior of the service providers and analyzed it with one and multiple
server settings. In the follow up work [7], they identified the optimal settings for
the multi-server case when collusion is allowed.
8 Conclusion
Security of incentivized verifiable computation system is an intriguing challenge
because of the range of possible attacks and possible collusions. Our goal was to
examine the security claims of such an incentivised outsourcing system proposed
by Harz and Boman [Harz et al. 2018] (HB), at FC WTSC 2018. We analyse the
system, considering rational contractors, using a game-theoretic approach and
discuss its correctness guarantee considering two attacks, collusion and Sybil.
Interestingly, our analysis shows that the incentive structure of HB can not pro-
tect the system against these attacks. We propose modifications for HB (HB+)
that helps the system to improve its correctness guarantee by motivating dili-
gent behavior in contractors by incentivizing contractors with bonus rewards.
We analyse HB+ and show that the modifications alleviates vulnerabilities of
the attacks and, guarantee high correctness in results, however it can not pre-
vent the attacks. We also propose to utilize the deposits of lazy contractors to
encourage diligent behavior in rational contractors for social fair. Fixing the HB
system from collusion and Sybil attacks for any behaviors (diligent and lazy) is
however our future work. Finally, we extend our analysis to malicious contrac-
tors whose goal is to corrupt the blockchain. We show that HB+ alleviates the
expected false rate compared to the original HB system.
References
1. Andrychowicz, M., Dziembowski, S., Malinowski, D., Mazurek, L.: Secure multi-
party computations on bitcoin. In: IEEE Symposium on Security and Privacy, pp.
443–458 (2014)
2. Belenkiy, M., Chase, M., Erway, C.C., Jannotti, J., Küpçü, A., Lysyanskaya, A.:
Incentivizing outsourced computation. In: Proceedings of International workshop
on Economics of networked systems, pp. 85–90. ACM (2008)
3. Dong, C., Wang, Y., Aldweesh, A., McCorry, P., van Moorsel, A.: Betrayal, dis-
trust, and rationality. In: Proceedings of ACM SIGSAC Conference on Computer
and Communications Security, pp. 211–227 (2017)
4. Eberhardt, J., Tai, S.: ZoKrates-scalable privacy-preserving off-chain computa-
tions. In: IEEE International Conference on Blockchain (2018)
5. Gennaro, R., Gentry, C., Parno, B.: Non-interactive verifiable computing: outsourc-
ing computation to untrusted workers. In: Rabin, T. (ed.) CRYPTO 2010. LNCS,
vol. 6223, pp. 465–482. Springer, Heidelberg (2010). https://doi.org/10.1007/978-
3-642-14623-7 25
6. Harz, D., Boman, M.: The scalability of trustless trust. In: Zohar, A., et al. (eds.)
FC 2018. LNCS, vol. 10958, pp. 279–293. Springer, Heidelberg (2019). https://doi.
org/10.1007/978-3-662-58820-8 19
https://doi.org/10.1007/978-3-642-14623-7_25
https://doi.org/10.1007/978-3-642-14623-7_25
https://doi.org/10.1007/978-3-662-58820-8_19
https://doi.org/10.1007/978-3-662-58820-8_19
66 M. Nabi et al.
7. Khouzani, M., Pham, V., Cid, C.: Incentive engineering for outsourced computa-
tion in the face of collusion. In: Proceedings of WEIS (2014)
8. Koch, J., Reitwiessner, C.: A predictable incentive mechanism for TrueBit. arXiv
preprint arXiv:1806.11476 (2018)
9. Küpçü, A.: Incentivized outsourced computation resistant to malicious contractors.
IEEE Trans. Dependable Secure Comput. 14(6), 633–649 (2017)
10. Parno, B., Raykova, M., Vaikuntanathan, V.: How to delegate and verify in public:
verifiable computation from attribute-based encryption. In: Cramer, R. (ed.) TCC
2012. LNCS, vol. 7194, pp. 422–439. Springer, Heidelberg (2012). https://doi.org/
10.1007/978-3-642-28914-9 24
11. Paul, S., Shrivastava, A.: Robust multiparty computation with faster verification
time. In: Susilo, W., Yang, G. (eds.) ACISP 2018. LNCS, vol. 10946, pp. 114–131.
Springer, Cham (2018). https://doi.org/10.1007/978-3-319-93638-3 8
12. Pham, V., Khouzani, M.H.R., Cid, C.: Optimal contracts for outsourced compu-
tation. In: Poovendran, R., Saad, W. (eds.) GameSec 2014. LNCS, vol. 8840, pp.
79–98. Springer, Cham (2014). https://doi.org/10.1007/978-3-319-12601-2 5
13. Setty, S.T., McPherson, R., Blumberg, A.J., Walfish, M.: Making argument systems
for outsourced computation practical (sometimes). In: NDSS, vol. 1, p. 17 (2012)
14. Teutsch, J., Reitwießner, C.: A scalable verification solution for blockchains (2017).
https://people.cs.uchicago.edu/teutsch/papers/truebitpdf
http://arxiv.org/abs/1806.11476
https://doi.org/10.1007/978-3-642-28914-9_24
https://doi.org/10.1007/978-3-642-28914-9_24
https://doi.org/10.1007/978-3-319-93638-3_8
https://doi.org/10.1007/978-3-319-12601-2_5
https://people.cs.uchicago.edu/teutsch/papers/truebitpdf
	Game-Theoretic Analysis of an Incentivized Verifiable Computation System
	1 Introduction
	2 HB System
	3 Game-Theoretic Analysis of HB
	4 Attacks on HB System
	4.1 Collusion Attack in HB System
	4.2 Sybil Attack in HB System
	4.3 Shortcoming of HB
	5 HB+ System
	5.1 Analysis of HB+
	5.2 Malicious Contractors
	6 Evaluation and Comparison
	7 Related Work
	8 Conclusion
	References