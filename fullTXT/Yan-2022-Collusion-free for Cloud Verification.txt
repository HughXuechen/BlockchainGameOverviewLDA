Collusion-free for Cloud Verification toward the View of Game Theory
33
Collusion-free for Cloud Verification toward the View of
Game Theory
HONGYANG YAN, Institute of Artificial Intelligence and Blockchain, Guangzhou University, Guangzhou
and Peng Cheng Laboratory
NAN JIANG, School of Information Engineering, East China Jiaotong University
KANG LI, Department of Computing, Hong Kong Polytechnic University
YILEI WANG and GUOYU YANG, School of Information Science and Engineering, Qufu Normal
University
At present, clients can outsource lots of complex and abundant computation, e.g., Internet of things (IoT),
tasks to clouds by the “pay as you go” model. Outsourcing computation can save costs for clients and fully
utilize the existing cloud infrastructures. However, it is hard for clients to trust the clouds even if blockchain
is used as the trusted platform. In this article, we utilize the verification method as SETI@home by only two
rational clouds, who hope to maximize their utilities. Utilities are defined as the incomes of clouds when
they provide computation results to clients. More specifically, one client outsources two jobs to two clouds
and each job contains n tasks, which include k identical sentinels. Two clouds can either honestly compute
each task or collude on the identical sentinel tasks by agreeing on random values. If the results of identical
sentinels are identical, then client regards the jobs as correctly computed without verification. Obviously,
rational clouds have incentives to deviate by collusion and provide identical random results for a higher
income. We discuss how to prevent collusion by using deposits, e.g., bit-coins. Furthermore, utilities for each
cloud can be automatically assigned by a smart contract. We prove that, given proper parameters, two rational
clouds will honestly send correct results to the client without collusion.
CCS Concepts: • Security and privacy;
Additional Key Words and Phrases: Cloud computing, collusion free, IoT, blockchain, game theory, sequential
equilibrium
ACM Reference format:
Hongyang Yan, Nan Jiang, Kang Li, Yilei Wang, and Guoyu Yang. 2021. Collusion-free for Cloud Verification
toward the View of Game Theory. ACM Trans. Internet Technol. 22, 2, Article 33 (November 2021), 21 pages.
https://doi.org/10.1145/3423558
This paper is funded by China Postdoctoral Science foundation (No. 2020M682658).
Authors’ addresses: H. Yan, The Institute of Artificial Intelligence and Blockchain, Guangzhou University, Guangzhou and
Peng Cheng Laboratory; email: hyang.yan@foxmail.com; N. Jiang, The School of Information Engineering, East China
Jiaotong University, China; email: jiangnan@ecjtu.edu.cn; K. Li, The Department of Computing, Hong Kong Polytechnic
University; email: kang.li@connect.polyu.hk; Y. Wang (corresponding author) and G. Yang, The School of Information Sci-
ence and Engineering, Qufu Normal University, China; emails: wang_yilei2019@qfnu.edu.cn, yangguoyu1020@163.com.
Authors updated affiliation: Yilei Wang and Guoyu Yang, School of Computer Science.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from permissions@acm.org.
© 2021 Association for Computing Machinery.
1533-5399/2021/11-ART33 $15.00
https://doi.org/10.1145/3423558
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
https://doi.org/10.1145/3423558
mailto:permissions@acm.org
https://doi.org/10.1145/3423558
http://crossmark.crossref.org/dialog/?doi=10.1145%2F3423558&domain=pdf&date_stamp=2021-11-11
33:2 H. Yan et al.
1 INTRODUCTION
Verifiable computing meets the need of outsourced computations, where computation tasks are
outsourced to more powerful but untrusted computation services like clouds. Note that although
blockchain may provide a trust platform due to their “decentralization” property, it still cannot
prevent clouds from colluding. Collusion-free protocols guarantee that the client can efficiently
verify the correctness of the computation results from the untrusted (or even trusted) services [37].
Verification is also applied widely in the Internet of Things (IoT) [11], which often outsource
expensive computation to servers [5, 10]. Normally, homomorphic encryption [15] and proba-
bilistically checkable proofs (PCPs) [31, 32] can provide a proof of correctness for outsourced
computation. However, these methods may introduce an expensive preparation step before a less
expensive computation. Another line of verification is redundancy proposed in Reference [25],
which is widely used in large research project such as SETI@Home [1] and Folding@Home [30].
It is a good choice for the client to outsource these kind of computation on professional in-
frastructures, e.g., clouds. Cloud computing can provide such outsourced services for clients by
returning correct results with some computation cost. However, clients pay clouds some rewards
for the services. As profit organization, clouds devoted themselves to maximize their profits, which
is defined as the rewards minus service costs. If profit is formalized as utility, then clouds can be
considered as rational. Thus we can analyze the behaviors or strategies for clouds toward the view
of game theory [13, 18].
1.1 Related Works
Gennaro, Gentry, and Parno coined the term “verifiable computing” for the scenario of outsourced
computation between a weak client and more powerful but untrusted computation service. Simi-
lar terms include “checking computations” [2], “delegating computations” [17], and “certified com-
putation” [23, 38]. The main target of verifiable computing is to enforce honest computation of
servers such that clients can learn correct results. Fei et al. [33] propose a CCIoT-CMfg framework
by combining IoT and cloud computing [34].
Verifiable computing can be achieved by redundancy [25], which is widely used in large research
project such as SETI@Home and Folding@Home. Cannetti, et al. [8] delegates the computation to
more than two servers and they provide correct computation results when at least one server is
honest. The honest server may convince the third party when other servers cheat, who will be pe-
nalized for these dishonest behaviors. Therefore, it is better for rational servers to honestly follow
the protocol, since it is a dominated strategy. Furthermore, there is no overhead if all servers agree
upon one identical result in Reference [8]. The distinctions of this article lie in (1) the computation
is outsourced to no more than two servers, both of whom are rational; (2) no one will detect cheat-
ing once two servers agree upon an identical result; and (3) there is overhead for client once he
receives the identical result. Therefore, in this article, we should solve the problem how to detect
cheating without an honest server. Meanwhile, we should also guarantee honest computation the
protocol to be a dominated strategy for rational servers. Li et al. discuss the cooperation incentives
in cloud networks in the presence of two rational parties [35].
Kamara and Rakova [19] proposed a protocol, where the client delegates computation to multi-
tenant cloud. The correctness of the result is captured in ideal/real paradigm. Carbunar and
Tripunitara [9] proposed a unifying trust framework relying on an off-line third party (like an
off-line bank). Results can be verified through rewarding correct participation by the third party.
However, the rewards from the off-line bank are not credible, since there are so many notorious
problems about centralized currency systems. In this article, we choose digital currency system,
e.g., bit-coins [24] as the rewards and penalties to servers. In fact, bit-coins are already used in the
field of verifiable computation [22]. In fact, Kumaresan and Bentov [22] discuss the incentives in
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
Collusion-free for Cloud Verification toward the View of Game Theory 33:3
lots of cryptographic fields, e.g., verifiable computation, fairness and restricted leakage in SMPC,
and so on. In this article, they use a special ideal claim-or-refund transaction functionality [4],
which can be efficiently implemented by bitcoin systems.
Another line of verifiable computation includes homomorphic encryption [15] and PCPs [31, 32].
Backes et al. [3] propose a practical and efficient verification scheme based on a primitive homo-
morphic message authenticators [16]. Pinocchio supports zero-knowledge verifiable computation,
proposed by Parno, et al. [28]. Recently, Cannetti et al. [7] discuss how to delegate computation
on large database to an untrusted server. They assume the existence of indistinguishability obfus-
cation for circuits and regular collusion-resistant hash functions. However, these methods may
introduce an expensive preparation step before a less expensive computation. Therefore, more
practical and economic verifiable computation should be considered.
Pham et al. [29] proposed an optimal contract by utilizing Principal-Agent model derived from
game theory. They provided proper incentives (e.g., rewards, penalties) for agents and efficiently
circumvent the above expensive cryptographic method. Their contracts achieve correct compu-
tation with minimal expense for the client. Furthermore, they proved that honest computation
is Nash equilibrium for agents without collusion. Khouzani et al. [20] extend the work in Ref-
erence [29] to allow collusion between agents and propose a hybrid scheme of direct auditing
and redundancy computation. They discuss how to set proper parameters such that agents have
enough incentives not to collude. More specifically, they prove that honest computation is Nash
equilibrium for both agents. Consequently, the clients can receive correct computation result with
minimize cost. Wang et al. [36] address the problem of verifying the validity of smart contracts by
introducing random variables. The main task of our work is similar to that of References [20, 29].
That is, we wish to provide enough incentives for parties such that two agents behave honestly.
Meanwhile, the client receives correct result with minimize cost. There are some distinctions be-
tween [29] and this article. (1) Reference [29] use a hybrid scheme, where at most two agents are
hired, while we use definitely two agents to execute the computation. (2) In Reference [29], the
clients should prove the auditing fee by himself, which will obvious increase the cost of the client,
while in this article, the auditing fee is provided from the agents’ deposit. (3) It hard for the clients
to mandatory charge the penalty from agents in Reference [29]. However, in our work, penalties
can be deducted from agents’ deposit by using smart contract [6, 12]. (4) In Reference [29], rational
agents can arbitrarily abort from the protocol without punishment. However, in this article, ratio-
nal agents will be punished by the smart contract once they prematurely abort. (5) In this article,
we provide a stronger equilibrium-dominated strategy equilibrium rather than Nash equilibrium.
1.2 Motivations and Contributions
Although previous works about verifiable computing provide various methods like PCPs, most of
them have expensive preparation computation cost. Redundant computation with rewards seems
reasonable and less expensive, where clients accept the consensus results by majority. However,
large number of servers lead to heavy cost for the client. Furthermore, clients can hardly detect
cheating when majority servers collude and return an incorrect result. Dong et al. [14] subverts
the collusion by utilizing smart counter-collusion contracts, where verifiable computing can be
achieved by two rational clouds. Their work adapts to the scenario, where each cloud is outsourced
with single task and leave multi-task as an open problem. We revisit this problem (but with more
complex scenario) in this article and strongly inherit the basic work flow in Reference [14].
A concrete setting for IoT outsourcing is presented in Figure 1. An IoT Client consists of one
mobile phone and smart parking lock, both of which communicate wirelessly. IoT client may out-
source cloud servers processing a mass of raw data and hope to learn the results, which may
optimize the parameters in smart parking lock.
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
33:4 H. Yan et al.
Fig. 1. A concrete setting for IoT outsourcing.
Recall that in Reference [14], only one job is outsourced. However, in reality, client prefer to
assign more jobs for the sake of efficiency. Therefore, in this article, we consider the scenario
where one client outsources two different jobs J1 and J2 to cloud servers C1 and C2, respectively,
where k sentinels are identical in J1 and J2. Cloud servers deposit d before they are assigned jobs.
The client refunds the deposits and rewards the cloud servers if they complete the jobs correctly.
Here the jobs are regarded as correctly completed if the client receives identical results from two
clouds with respect to k sentinels. Deposits and rewards are enforced by a smart contract. We
prove that, given proper parameters, correctly completing the job without collusion is dominating
strategy for each cloud. Note that two clouds may collude by a gentleman’s agreement, where
no punishment for deviating from the gentleman’s agreement. However, this kind of collusion is
an empty threat for the client. Knowing this, two clouds will strengthen the collusion by a secret
smart contract, where they deposit t and C1 bribe C2 with b if the latter follows the secret smart
contract. Consequently, two clouds have incentives to collude by agreeing on k random values and
successfully cheat the client. Recall the client regard two servers complete the jobs correctly if k
sentinels from two clouds are identical. Therefore, two clouds get rewards without any cost with
the secret smart contract, since deviation is not free anymore and collusion is dominating strategy
for each cloud.
The crux of this article is how to construct a side smart contract, which is a secret smart contract
between the client and one cloud (say,C2), to resist collusion. Following the basic idea in Reference
[14], we utilize the rationality of the clouds to design a signal smart contract, where C2 sends the
correct results and a signal indicating that C1 tries to bribe him for collusion. The client calls
TTP (third trusted party) to verify the correctness of the returned results even if k sentinels are
identical. The client refunds and rewards C2 if collusion is detected. Furthermore, C2 gets d (the
detained deposit of C1) as a bonus for sending signals. However, C2 should afford ch by calling
TTP, since he triggers the action of calling TTP. ThusC2 should afford for the unnecessary calling
if C1 returns the correct results; otherwise, no money can be deducted from C1 except for the
deposit d . Recall that d is given toC2 as a bonus. We prove that, given proper parameters, honestly
completing the jobs is dominating strategy for each cloud under the signal smart contract. The
main contributions of this article are as follows.
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
Collusion-free for Cloud Verification toward the View of Game Theory 33:5
(1) We extend the work in Reference [14] from single task to multi-task. We first discuss the
possibility of honestly computation without verification when the collusion is only an empty
threat. We prove that, the client may bias the dominant strategy by setting proper parameters
like d .
(2) We construct a collusion contract toward the view of two clouds, whereC1 enforces the collu-
sion by mutual deposit and bribery to C2. We prove that, two clouds can successfully cheat
the client under the collusion contract by secretly setting proper parameters like mutual
deposit t and bribery b.
(3) Finally, the client designs a signal contract to resist the collusion contract such that C2 has
no incentives to accept the latter contract. That is,C2 obtains additional payment by sending
a signal to the client when two clouds reach a collusion contract. We prove that the signal
contract can effectively deter the collusion such that both clouds correctly complete the jobs.
The organization of this article is as follows. Section 2 presents some basic notions in game
theory. The baseline game for verifying computation is shown in Section 3, where the collusion
is invalid, since no strengthen effect exists between two clouds. The client learns correct results
without verifying them. However, as rational clouds, they dedicate to maximize their utilities by
collusion. Therefore, a collusion contract is proposed in Section 4 to successfully cheat the client.
Knowing this, the client is bound to prevent such collusion contract to avoid being deceived. A
collusion-free contract is put forward in Section 5 such that C1 has no incentives to initialize a
collusion contract andC2 has no incentives to accept it. The dominate strategy is the same as that
of the baseline game under the promotion of collusion-free contract. Section 6 concludes this work
and presents some future directions with respect to verifying computation.
2 PRELIMINARIES
Game theory shows how to design optimal strategies for individuals or groups under specific
conditions. In game theory, individuals are assumed to be rational and they care about how to
maximize their payoffs. In this article, two clouds and the client are assumed to be rational and they
hope to maximize their payoffs by adopting proper strategies. Generally, games can be presented
as strategic and extensive form. More formally, we rephrase the notions of extensive games with
imperfect information following the work of Osborne [26].
Definition 2.1. An extensive game with imperfect information < P,A,H , P , fc , (IPi
)i ∈{1,2},�i>
has the following components.
(1) The set of two parties P = {P1, P2}.
(2) The action set A = A1 × A2. Pi (i ∈ {1, 2}) chooses his action from the set of Ai . The action
profile a = (a1,a2) ∈ A.
(3) A set H of sequences (finite or infinite) that satisfies the following three properties.
(a) The empty sequence ∅ is a member of H .
(b) If (ak )k=1,2, ...K ∈ H (where K may be infinite) and L < K , then (ak )k=1,2, ...,L ∈ H .
(c) An infinite sequence ((ak ))∞
k=1
∈ H .
Each member in the set of H is a history that is composed by a sequence of actions pro-
files. A history (ak )k=1,2, ...,K ∈ H is terminal if it is infinite or if there is no ak+1 such that
(ak )k=1,2, ...,K+1 ∈ H . The set of actions available after the nonterminal histories h is denoted
A(h) = {a : (h,a) ∈ H } and the set of terminal histories is denoted Z .
(4) A function P that assigns to each nonterminal history a member coming from {P1, P2} � c. P
is the party function and P (h) (h ∈ H ) assigns the party who should take actions after the
history h. P (h) = c means that an exterior chance will determine the actions after the history
h. Note that P (h) = c occurs only at the initial round of the protocol.
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
33:6 H. Yan et al.
(5) A function fc where P (h) = c assigns an independent probability measure fc (·|h) on A(h).
Note that fc (a |h) is the probability that a ∈ A occurs after history h.
(6) For each party, a partition is denoted by IPi
(i ∈ {1, 2}) such that h ∈ H : P (h) = Pi . The
property of the partition is that A(h) = A(h′) whenever h and h′ are the same member
of partition. For each Ii ∈ Ii , denote A(Ii ) as the set A(h) and P (Ii ) as the party P (h) for
any h ∈ Ii . Note that, Ii is the information partition of Pi (i ∈ {1, 2}), while Ii ∈ Ii is an
information set of party Pi .
(7) For each party, a preference relation �i on lotteries over Z (the preference relation of
party Pi ) that can be described as the expected value of a payoff function defined on Z .
2.1 Strategies, Beliefs, and Sequential Equilibrium
Definition 2.2. A pure strategy of player i ∈ {1, 2} is an extensive game < P,A,H , P , fc ,
(IPi
)i ∈{1,2},�i> is a function that assigns an action in A(Ii ) to each information set Ii ∈ Ii .
Definition 2.3. A mixed strategy of player i in an extensive game < P,A,H , P , fc ,
(IPi
)i ∈{1,2},�i> is a probability measure over the set of player i’s pure strategies. A behavioral
strategy of player i is a collection (βi (Ii ))Ii ∈Ii of independent probability measures, where βi (Ii )
is a probability measure over A(Ii ).
For any history h ∈ Ii ∈ Ii and action a ∈ A(h) we denote by βi (h) (a) the probability βi (Ii ) (a)
assigned by βi (Ii ) to the action a. For any profile β = (βi )i ∈N of either mixed or behavioral strate-
gies in an extensive game, we define the outcome O(β ) of β to be the probability distribution over
the terminal histories that results when each player i follows the precepts of βi . Let β−i be (n-1)-
dimensional vector derived from β by suppressing the ith coordinate. Therefore (β ′i , β−i ) denotes
the strategy profile where Pi adopts β ′i and other parties adopt strategies in βj ∈ β (j � i).
Sometimes the decision-maker’s preferences are specified by giving a utility function U : O →
R, which defines a preference relation �i by the condition x �i y if and only if U (x ) ≥ U (y).
A Nash equilibrium in mixed strategies of an extensive game is (as before) a profile β∗ of mixed
strategies with the property that for every player i ∈ N we have O(β∗) �i O(β ′i , β−i ) for every
mixed strategy βi of player i . A Nash equilibrium in behavioral strategies is defined analogously.
While for extensive games with imperfect information, Nash equilibrium is not enough, a strong
equilibrium is needed to include all equilibriums in each sub-game. In effect, the equilibrium of
extensive games with imperfect information is an assessment (β , μ) that is formally defined as
follows.
Definition 2.4. An assessment in an extensive game with imperfect information is a pair (β, μ ),
where β is a profile of behavioral strategies and μ is a function that assigns to every information
set a probability measure on the set of histories in the information set.
μ is denoted as a belief system, where μ (I ) (h) is the probability that party P (I ) assigns to
the history h ∈ I under the assumption that the information set I can be reached. Let outcome
O(β, μ |I ) of (β , μ ) conditional on I be the distribution over terminal histories determined by β and
μ conditional on I being reached. If I is the information set consisting of the initial history, then
O(β, μ |I ) is just the outcome O(β ) defined.
Definition 2.5. Let <P,H , P , fc , (IPi
)i ∈{1,2},�i> be an extensive game with perfect call and im-
perfect information. The assessment (β, μ ) is sequentially rational, if for each party Pi (i ∈ {1, 2})
and each information set Ii ∈ Ii , we have
O (β, μ |Ii ) �i O ((β−i , β
′
i )), μ |Ii ),
where β ′i denotes every strategy of Pi (i ∈ {1, 2}).
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
Collusion-free for Cloud Verification toward the View of Game Theory 33:7
Definition 2.6. Let <P,A,H , P , fc , (IPi
)i ∈{1,2},�i> be an extensive game with perfect call and
imperfect information. The assessment (β, μ ) is consistent, if there is a sequence ((βn , μn ))∞n=1
of assessments converging to (β, μ ) in Euclidian space. Furthermore, the profile βn is completely
mixed and the belief system μn is derived from βn according to Bayes’s rule.
The idea behind this requirement is that the probability of events conditional on zero-probability
events must approximate probabilities that are derived from strategies that assign positive proba-
bility to every action.
Definition 2.7. An assessment is a sequential equilibrium of a finite extensive game with perfect
recall if it is sequentially rational and consistent.
The basic idea of consistent is that the probability of events conditional on zero-probability
events must approximate probabilities that are derived from strategies that assign positive proba-
bility to every action. This consistency requirement, however, is too strong and thus not natural,
since it is stated in terms of limits. Kreps [21] show that “rather a lot of bodies are buried in this
definition.” Therefore, in this article, we introduce weak sequential equilibrium as a substitutes
equilibrium in extensive game with imperfect information.
Definition 2.8. An assessment (β, μ ) is a sequential equilibrium if it satisfies the following two
conditions:
• Given μ, β is sequentially rational.
• Given β , the probability of history h∗, where each information set Ii can be reached with
positive probability, is updated according to Bayes’s rule,
Pr (h∗ |Ii ) =
Pr (h ∗ accordinд to β )
∑
h∈Ii
Pr (h accordinд to β )
.
The following two propositions are established.
• Any weak sequential equilibrium is sub-game perfect equilibrium for any extensive game
with perfect information.
• Any strategy profile in weak sequential equilibrium is Nash equilibrium.
Therefore, in this article, we try to find weak sequential equilibrium instead of sequential equi-
librium for our games.
We demonstrate these definitions with regard to an extensive game with imperfect information
<P,A,H , P , fc , (IPi
)i ∈{1,2},�i> by Card Game [26]. The game tree is shown in Figure 2. P =
{P1, P2} participate in the game. Note that chance is an exterior entity in the game, who assigns
private type Hiдh or Low to P1 at the initial of game and does not obtain payoff from the game.
A1 = {See,Raise} and A2 = {Pass,Meet } are action sets for P1 and P2, respectively. (Raise, Pass ),
for example, is an action profile. History is composed by a sequence of actions profiles such as
h1 = (Hiдh), h′1 = (Low ), h2 = (Hiдh,Raise ), h′2 = (Low,Raise ), and h3 = (Hiдh,Raise, Pass ), and
so on. Note that ∅ denotes the empty history, where the game is initial. Function P assigns the
party who should take actions after the history h, like P (h1) = P1 and P (h2) = P2. fc (Hiдh |∅) =
fc (Low |∅) = 0.5. I1 = {Hiдh,Low } and I2 = {(Hiдh,Raise ), (Low,Raise )} are information sets for
P1 and P2, respectively. The tuples of the terminal nodes denote the payoffs for parties, where the
former part denotes the payoff for P1 and the latter one for P2. The preference relation depends on
the payoffs of the terminal nodes. ((Raise,Meet ) |h2) �1 ((Raise, Pass ) |h2) denotes that P1 prefer
Raise when follow the history of h2.
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
33:8 H. Yan et al.
Fig. 2. The game tree of Card Game.
A behavior strategy β = (β1, β2), where β1 (Raise ) = (β1 (h1) = PH , β1 (h′1) = PL ) and
β2 (Meet ) = (β2 (h2) = φ,β2 (h′2) = ψ ). β1 (Raise ) means that P1 chooses Raise with probability
PH (PL) when reaching information set I1 by following history h1 (h′1). β2 (Meet ) that P2 chooses
Meet with probability φ (ψ ) when reaching information set I2 by following history h2 (h′2). The be-
lief system with μ (I1) (h1) = 0.5 means that P1 assign the probability 0.5 to the information set I1 by
following history h1. Pr (h2 accordinд to β ) = PH denotes the probability for P2 reaching history
h2 by choosing Raise according to β . Pr (h′2 accordinд to β ) = PL denotes the probability for P2
reaching history h′2 by choosing Raise according to β . The probability for P2 reaching information
I2 is updated by following Bayes’s rule. That is, μ (I2) (h2) =
Pr (h2 accordinд to β )
∑
h′∈I2
Pr (h′ accordinд to β ) =
PH
PH+PL
. The
assessment (β, μ ) is a weak sequential equilibrium, where β = ((1, 1
3 ), ( 2
3 ,
2
3 )) and μ (I2) (h2) = 0.75.
More specifically, the strategy of P1 is as follows: (1) P1 always chooses Raise when he is assigned
Hiдh card, and (2) P1 chooses Raise with probability 1
3 when he is assigned Low card. The strategy
of P2 is: he will chooses Meet with probability 2
3 when reaching information set I2. Furthermore,
P2 updates his belief system by Bayes’s rule when information set I2 is reached.
3 BASELINE GAME FOR VERIFYING COMPUTATION
In this section, we present a basic version of verifying computation, where two clouds collude to
maximize their utilities. However, the collusion has no binding effect on rational clouds, since they
will not have to pay for deviation from it. The work flow of the baseline game is as follows.
(1) Two rational cloud serversC1 and C2 deposit d to the client if they are willing to earn some
rewards by completing specific jobs. The client outsources two jobs J1 and J2 toC1 andC2, re-
spectively. Each job consists ofn independent tasks J1 = {J 1
1 , J
2
1 , . . . , J
n
1 }, J2 = {J 1
2 , J
2
2 , . . . , J
n
2 }.
The client chooses k sentinels Sl = Sl1
, Sl2
, . . . , Slk
, which are identical in J1 and J2. Denote
J1 = J1 − Sl and J2 = J2 − Sl as the rest tasks in J1 and J2, respectively.
In this article, we assume that the job is to compute the determinate function f (·) with
respect to n inputs. The client sends X1 = {X 1
1 ,X
2
1 , . . . ,X
n
1 }, X2 = {X 1
2 ,X
2
2 , . . . ,X
n
2 } to C1
and C2, respectively. Let Xl = Xl1
,Xl2
, . . . ,Xlk
are k sentinels. Therefore, f (X1) and f (X2)
are distinct, since X1 = X1 − Xl and X2 = X2 − Xl are distinct for determinate function. Let
f (Xi ) = ( f ormeri , latteri ), where latteri denotes the results of k sentinels.
(2) Cloud servers C1 and C2 locally complete the jobs. As rational clouds, they have three
strategies.
(a) Honest (denoted as f (·)): Two clouds honestly compute all tasks. Generally, C1 computes
f (X1) = { f (X1), f (Xl )} and C2 computes f (X2) = { f (X2), f (Xl )}. The computation cost
for the clouds is denoted as c .
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
Collusion-free for Cloud Verification toward the View of Game Theory 33:9
(b) Collusion (denoted as r ): Two clouds identify all sentinel tasks and agree on a random value
as the result for each of them. That is, two clouds agree on f (Xl )′ = {rl1
, rl2
, . . . , rlk
} �
f (Xl ). Then they choose other random values for f (X1)′ � f (X1) and f (X2)′ = f (X2)
independently such that f (Xl )′ � f (X1)′ � f (X2)′. Let f (X1) = ({ f (X1)′, f (Xl )′}) and
f (X2) = ({ f (X2)′, f (Xl )′}). Note that the cost of this strategy is 0, since no clouds need to
compute f (·).
(c) Other : Other strategy that is neither f (·) nor r . In case Ci does not follow the collusion
strategy and tries to cheat, its cost is αi · c where αi ∈ [0, 1]. For example, C1 and C2
choose random values for f (X1) = { f (X1)′′, f (Xl )′′} and f (X2) = { f (X2)′′, f (Xl )′′′} inde-
pendently such that f (Xl )′′ � f (Xl )′′′ � f (Xl ), f (X1)′′ � f (X2)′′, f (X1)′′ � f (X1) and
f (X2)′′ � f (X2).
(3) C1 and C2 send f (X1) and f (X2) to the client, respectively.
(4) If latter1 and latter2 are identical, then the client returns the deposit d and rewards w to
each cloud server.
(5) Otherwise, the client audits TTP to verify that server provides the correct results. The client
retains d if the clouds server (say, C1) provides random results. However, the client refunds
the deposit d , rewards w and pays additional d as a bonus to the one (say, C2) who provides
correct results. However,C2 should pay ch for auditing TTP, sinceC1 has no money to deduct.
The rewards and deposits between client and clouds are enforced through smart contract
Depositi (refer Algorithm 1).
Probability for cheating detection
Rewards are paid according to the equivalence of latter1 and latter2 as shown in Algorithm 1.
The clouds have incentives to cheat by sending random values, since client will not verify the
correctness of the results if latter1 = latter2. Unfortunately, the collusion has no binding between
them and rational clouds still have incentives to deviate from collusion for the sake of bonus.
Therefore, the probability when cheating is detected is defined as follows (see Table 1).
• If both parties are honest, then the probability when client detects cheating is 0, since there
is no cheating behavior at all.
• If parties follow strategy Collusion, then the probability is 0, since latter1 and latter2 are
identical. Meanwhile, TTP is not called and client regards them as correct results.
• IfCi (i = 1, 2) does not follow the collusion strategy and tries to cheat, then the probability of
at least one sentinel is not computed correctly is pi . It is clear that pi ≥ k/n. The probability
that the client can detect cheating behavior is the following.
— If C3−i (i = 1, 2) is honest, then the detection probability is pi .
— If C3−i follows collusion strategy, then the detection probability is 1. (Ci does not follow
the collusion strategy means the result of at least one sentinel is not identical to the agreed
the random value).
— If C3−i does not follow the collusion strategy and tries to cheat, then the detection proba-
bility is q = 1 − (1 − p1) (1 − p2) = p1 + p2 − p1 · p2.
Strategies and utility for rational clouds
The baseline game is denoted asGame1 and the utilities with regard to rational clouds are listed
in Figure 3. The rectangular nodes, called terminal node, denote the terminal states of the game and
the round circles denote non-terminal nodes.C1 (C2) takes an action on non-terminal nodes, which
leads to a new node. The actions constitute the histories of the game. For example, the history may
be hf (x ) = { f (x )} after C1 chooses the action f (x ) at node v0. hr = {r }, and hOther = {Other } are
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
33:10 H. Yan et al.
Table 1. The Probability of
Cheating Detection
������C1
C2
f (x ) r Other
f (x ) 0 1 p1
r 1 0 1
Other p2 1 q
ALGORITHM 1: Depositi : Deposit Contract between Ci and Client
Input: deposit d , input Xi (i = 1,2)
Output: Result f (Xi ) (i = 1, 2), Utility ui (i = 1,2)
Ci sends deposit d to Client;
Client sends Xi to Ci ;
Client returns f (Xi ) to Client. /* Ci has three strategies to choose. */;
if latter1 = latter2 then
Deposit d is refund to Ci ;
Reward w is paid to Ci ;
end
else
TTP is call with cost ch;
if latter1 = f (Xl ) then
Deposit d is refund to C1;
Reward w is paid to C1;
Client retains deposit d of C2 as a punishment and pays it to C1 as a bonus;
C1 pay ch for calling TTP
end
if latter2 = f (Xl ) then
Deposit d is refund to C2;
Reward w is paid to C2;
Client retains deposit d of C1 as a punishment and pays it to C2 as a bonus;
C2 pay ch for calling TTP
end
if latter1 � f (Xl ) and latter2 � f (Xl ) then
Client retains deposit d of both clouds and pays ch for calling TTP
end
end
defined analogously. These histories lead to an information set I2 = {hf (x ),hr ,hOther },1 which
is denoted by including non-terminal nodes v1, v2 and v3 in a dotted box. The information set
means that C2 is assigned by P (I2) to take actions when I2 is reached. C2, however, has no idea
which history leads to I2. Therefore, he may choose actions based on the belief system μ (I2) (h) =
(Pr (hf (x ) ), Pr (hr ), Pr (hOther )), where Pr (h) (h ∈ I2) is the probability that I2 is leading by h.
The actions chosen by C1 and C2 form the strategies for them. Pure strategy, in this arti-
cle, is denoted as βi (Ii ) = ai (i ∈ {C1,C2}, ai ∈ { f (x ), r ,Other }). Behavior strategy is de-
noted as βi (Ii ) = {Pr ( f (x )), Pr (r ), Pr (Other )},2 where Pr (ai ) is the probability on ai at I2 and
1C1 first take actions with empty history ∅.
2Note Pr (hf (x ) ) and Pr (f (x )) are distinct, where the former is the probability for history hf (x ) and the latter is the
probability for action f (x ).
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
Collusion-free for Cloud Verification toward the View of Game Theory 33:11
Fig. 3. Baseline game. Bold edges indicate the actions that parties will play in the unique sequential equilib-
rium. The reachable terminal node of the game is in grey. Denote z = w − c + d − ch for simplicity.
Pr ( f (x ))+Pr (r )+Pr (Other ) = 1. For example, β2 (I2) = f (x ) meansC2 choose pure strategy f (x )
at information set I2. β2 (I2) = (0.5, 0.2, 0.3) means C2 choose f (x ), r , Other with probabilities 0.5,
0.2, 0.3, respectively, at I2. Here we omit I2 in β2 (I2) = f (x ) when the information set is explicit.
Given strategies β and belief systems μ, the utility can be calculated consequently with regard to
each outcome, say, β = (β1, β2) = ( f (x ), f (x )), μ (I2) (hf (x ) ) = (1, 0, 0). That is, C1 adopts f (x ),
C2 adopts f (x ) at I2 and C2 has the belief that I2 is reached by following hf (x ) is 1. Therefore, the
outcome is O(β, μ |I2) and corresponding utility tuple is (w −c,w −c ), where the former part is for
C1 and the latter part is for C2. The formal definition of utilities above is tedious, since it related
to behavior strategies, belief systems, and information set.
We choose another succinct way to better illustrate the utility definition in Figure 3, which
corresponds to pure strategies with the assumption of perfect information. Note that the utility
definitions in game tree are independent of information set and belief systems. For example, the
outcome O(β, μ |I2) mentioned above can be simplified to be history ( f (x ), f (x )), which lead to a
terminal nodev4. Therefore, the utility can be denoted asu2 (O(β, μ |I2)) = u2 ( f (x ), f (x )) = u2 (v4),
which denotes the utility with respect to β , μ, and I2. The utilities for each cloud include the
deposit, reward and computation cost. The utility (say, at terminal node v4) can be calculated as
follows: Ci (i = 1, 2) gets reward w and refund deposit d at the expense of c to correctly compute
the result. Therefore, the total utility for Ci is w − c . Note that clouds get expected utilities at
terminal node v6, v10 and v12, which depend on probabilities for cheating detection. For example,
C1 honestly complete the job while C2 tries to deviate from the honest strategy at terminal node
v6. Recall that the client detects cheating with probability p2.C2 cannot get his refund d if cheating
is detected; otherwise, C2 gets rewards w with cost α2 · c . Therefore, the expected utility for C2 is
p2 · (−d ) + (1 − p2) (w − α2 · c ). Similarly, the expected utility for C1 is p2 · z + (1 − p2) (w − c ). The
client can bias two clouds to honestly complete the jobs by setting proper d .
Theorem 3.1. Givend > max ( nc
k
−w, c+ch), assessment (β , μ ), where β = (β1, β2) = ( f (x ), f (x )),
μ (I2) (hf (x ) ) = (1, 0, 0) is weak sequential equilibrium for baseline game.
Proof. (β, μ ) is weak sequential equilibrium should satisfy two conditions: (1) given μ, β is
sequentially rational and (2) given β , belief system μ updates according to Bayes’s rule. Condition
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
33:12 H. Yan et al.
(2) is the basic rule for baseline game (and the games in Section 4 and 5), so it is always established.
We will, if not specified, omit the proof of this part in following sections. The main task is to prove
the establishment of condition (1).
We prove condition (1) with the method of backward induction, a common method in game
theory [27]. The proof should also consider two cases: pure strategy and behavior strategy.
Case 1: pure strategy.
C2 chooses actions at I2. Given d > max ( nċ
k
− w, c + ch), we get Equation (1). That is, any
deviation from β2 = f (x ) is not a dominate strategy for C2. Therefore, C2 may choose f (x ) when
I2 is reached, which leads to terminal node v4, v7 and v10. We mark the corresponding edge with
thick lines in Figure 3,
u2 (v4) > u2 (v5),u2 (v4) > u2 (v6)
u2 (v7) > u2 (v8),u2 (v7) > u2 (v9)
u2 (v10) > u2 (v11),u2 (v10) > u2 (v12).
(1)
It isC1’s turn to choose among f (x ), r andOther . Given d > max ( nċ
k
−w, c+ch), it satisfied that
u1 (v4) > u1 (v7) and u1 (v4) > u1 (v10). That is, any deviation from β1 = f (x ) is not a dominating
strategy for C1. Therefore, C1 may choose f (x ) at the beginning of the game.
Case 2: Behavior strategy.
In this case, we manage to find any behavior strategy, which is better than pure strategy. Suppose
there exists a behavior strategy βb
= (βb
1 , β
b
2 ) = ((φ1,φ2,φ3), (ψ1,ψ2,ψ3)), which satisfies βb �i β .
C2 updates the belief system μ ′ according to βb such that, the probabilities reaching I2 through
histories hf (x ) , hr , and hOther are φ1, φ2, and φ3, respectively. Then we have Equation (2),
u2 (βb , μ ′|I2) = φ1 · (ψ1 · u2 (v4) +ψ2 · u2 (v5) +ψ3 · u2 (v6))
+φ2 · (ψ1 · u2 (v7) +ψ2 · u2 (v8) +ψ3 · u2 (v9))
+φ3 · (ψ1 · u2 (v10 +ψ2 · u2 (v11) +ψ3 · u2 (v12)).
(2)
Recall that u2 (β, μ |I2) = u2 (v4) and, given d > max ( nċ
k
− w, c + ch), Equation (1) establishes.
For Equation (2), u2 (βb , μ ′|I2) gets the maximum u2 (v4) when φ1 = ψ1 = 1, which is in line with
the pure strategy β . That is, there is no such behavior strategy that can lead better utility than the
pure strategy.
In a word, given d > max ( nċ
k
−w, c + ch) and μ, pure strategy β is sequentially rational. Conse-
quently, (β , μ ) is weak sequential equilibrium for baseline game. �
4 COLLUSION CONTRACTS BETWEEN TWO CLOUDS
Two clouds fail to collude when client sets proper parameters according to Theorem 1. The reason
for collusion failure is ascribed to lack of strong incentives. In other words, there is no binding effect
on the collusion, since it is free to deviate from collusion. In this section, we discuss the scenario
where the cloud, who deviate from collusion, will be punished by his opponent. A new game
Game2 is extended based on Game1. Game2 consists of three smart contracts: Deposit1, Deposit2
and a collusion contract Collusion. Two clouds deposit t to each other and agree on k random
values such that latter1 = latter2. Deposit t is refund if Ci returns latteri to the client. Moreover,
one cloud (say,C1) strengthens the collusion by providing a bribery b < c toC2 if the latter abides
by contract Collusion. Note that C1 and C2 adopt their strategies by turns sometimes in Game2,
since C1 should wait for the reply of his opponent before taking next strategy. The work flow of
the extended game is as follows.
(1) Two rational cloud servers C1 and C2 deposit d to the client if they are willing to earn some
rewards by completing specific jobs. It is the same as step 1 in Game1.
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
Collusion-free for Cloud Verification toward the View of Game Theory 33:13
ALGORITHM 2: Collusion: Collusion Contract between C1 and C2
Input: deposit t , input latteri (i = 1, 2)
Output: Utility ui (i = 1, 2)
C1 sends deposit t to C2 and vice versa;
C1 and C2 agree on k random values r = {rl1
, rl2
, . . . rlk
} such that Ci may let latteri = r if he wants;
if latter1 = latter2 then
Deposit t is refund to Ci ;
if latter2 = r then
C1 pays b to C2 as bribery;
end
end
else
if latter1 = r then
Deposit t is refund to C1;
C1 retains deposit t of C2 as a punishment
end
if latter2 = r then
Deposit t is refund to C2;
C2 retains deposit t of C1 as a punishment. Furthermore, C1 pays b to C2 as bribery
end
end
(2) In this section the strategies are more complex than those of Game1. C1 first decides to
request collusion (denoted as init ) or not (denoted as¬init ). If he chooses strategy¬init , then
the game enters into Game1, which means C1 and C2 play Game1. Otherwise, C1 initiates
smart contract Collusion and discuss it with C2. The contract indicates the mutual deposit t
and promises an additional bribery b if C2 abide by the contract.
(3) It is C2’s turn to choose one strategy between accepting collusion (denoted as Collude) or
not (denoted as ¬Collude). IfC2 chooses ¬Collude), then the game entersGame1. Otherwise,
C1 andC2 deposit t to each other and agree on k random values such that latter1 = latter2 =
r = {rl1
, rl2
, . . . rlk
} (i = 1, 2).
(4) Both clouds begin to locally complete the jobs onceC2 chooses strategyCollude . They have
three strategies, which are similar to those steps 2 (a)(b)(c) in Game1. Note that clouds may
adopt f (x ) or Other even they reach a contract Collusion.
(5) C1 and C2 send f (X1) and f (X2) to the client, respectively.
(6) Client receives the returned results, then he rewards or calls TTP, which are the same as
step (4) or (5) in Game1.
(7) C1 refunds t and give bribery b toC2 ifC2 returns r to the client. Meanwhile,C2 refunds t if
C1 returns r to the client.
The rewards and deposits in contract Depositi (i = 1, 2) are paid according to Algorithm 1.
Deposit and bribery in contract Collusion are paid according to Algorithm 2.
Utility for rational clouds
The extended game is denoted asGame2 and the utilities for rational clouds are listed in Figure 4.
The cheating detection probabilities ofGame2 are the same withGame1. Two clouds choose proper
t to facilitate contract Collusion under the parameter configuration of Theorem 1. Note that the
rationale behind the work flow of the extended game in Figure 4 is as follow. We cannot guarantee
that all tasks are completed simultaneously. Furthermore, malicious users may deliberately delay
the submission even if they complete. Therefore, we should consider the extensive games instead
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
33:14 H. Yan et al.
Fig. 4. Collusion game. Bold edges indicate the actions that parties will play in the unique sequential equi-
librium. The reachable terminal node of the game is in grey.
of static games. The former game allows parties to act alternatively and the latter game requires
that all parties should act simultaneously.
Theorem 4.1. Given t > z + d − b, d > max ( nċ
k
− w, c + ch) and b < c , (βc , μc ), where βc
=
(β1, β2) = ((init , r ), (Collude, r )), μc (I2) (r )) = (0, 1, 0)) is weak sequential equilibrium for collusion
game.
Proof. We follow the proof line of Theorem 1. Given t > z + d − b, d > max ( nċ
k
−w, c + ch)
and b < c , we get Equation (3),
u2 (v7) > u2 (v6),u2 (v7) > u2 (v8)
u2 (v10) > u2 (v9),u2 (v10) > u2 (v11)
u2 (v13) > u2 (v12),u2 (v13) > u2 (v14).
(3)
Therefore, C2 will not deviate from β2 at I2, since it is dominated strategy for C2.
Now it is turn forC1 to choose.C1 may choose r according to β1, since it satisfies that u1 (v10) >
u1 (v7) andu1 (v10) > u1 (v13). Then the game backward to nodev1 andv0. Given proper parameters
listed in Theorem 2, we have u2 (v10) > u2 (дame1) and u1 (v10) > u1 (дame1). For the same reason,
C1 andC2 have no incentives to deviate from βc . That is,C2 choosesCollude at v1 andC1 chooses
init at v0. We can also prove that there is no behavior strategies, which is better than βc .
In a word, given t > z + d − b, d > max ( nċ
k
−w, c + ch) and b < c , (βc , μc ), is weak sequential
equilibrium for collusion game. �
5 COLLUSION-FREE CONTRACT
Two clouds can successfully collude under the assumption in Theorem 2. C2 agrees on collusion,
since he can get refunds d and t , reward w without cost c , and a bribery b. Therefore, the client
should provide stronger incentives such that collusion is not a dominant strategy for C2. In this
article, we propose a signal scheme between C2 and the client, which is a collusion-free smart
contract. The signal scheme is as follows: (1) C2 sends a signal and a tuple of (r , f (X2)) to the
client. (2) The client calls TTP once C2 sends a signal even latter1 = latter2 holds.
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
Collusion-free for Cloud Verification toward the View of Game Theory 33:15
ALGORITHM 3: Collusion − f ree: Collusion-free Contract between the Client and C2
Input: f (X1), Siдnal (r , f (X2))
Output: Utility ui (i = 1, 2)
Client calls TTP and deduct ch from C2;
if latter1 = r then
The client retains deposit d of C1 and gives it to C2;
The client refunds d and rewards w to C2;
end
else
if latter1 = f (Xl ) then
Deposit d is refund and reward w is given to C1;
end
if latter2 = r then
Deposit t is refund to C2;
C2 retains deposit t of C1 as a punishment. Furthermore, C1 pays b to C2 as bribery
end
end
Notes for the signal scheme.
• The signal indicates that C1 try to collude with him and C2 discloses the collusion behavior
to the client. The function of r in (r , f (X2)) is to verify the existence of Collusion and gets
refund t . That is,C1 regards thatC2 sends r to the client. The function of f (X2) in (r , f (X2))
is to get refund d .
• The distinction from previous two games is who pays ch. Recall that the cloud who correctly
completes the job bears the cost ch, since the deposit of the dishonest cloud is paid as a bonus
to the honest one. In this section, cost ch is always deducted fromC2 once he sends the signal,
since TTP verifies whether latter1 = latter2 all the time. It is unfair forC1 to afford the cost
if latter1 = f (Xl ) � r . However, C1 has no money to deduct if latter1 � f (Xl ) = r .
The work flow of the collusion-free game is as follows.
(1) The strategies int , ¬int , Collude and ¬Collude are the same as those in Game2.
(2) The client and C2 sign a secret collusion-free smart contract Collusion − f ree , which imple-
ments the signal scheme.
(3) Both clouds begin to locally complete the jobs once C2 chooses strategy Collude . Here C1
still has three strategies, which are similar to those steps 2 (a)(b)(c) in Game1. However, C2
has an addition strategy Siдnal (r , f (Xl )) except for f (x ), r andOther . Siдnal (r , f (X2)) indi-
cates that C2 signals the client for the collusion, where C2 pretends to return r by following
contract Collusion to get refund t and bribery b. Meanwhile, C2 returns f (X2) by following
contract Collusion − f ree such that he can at least get refund d , reward w . Note here f (X2)
in Siдnal (r , f (X2)) is correctly computed, otherwise it is not dominant strategy for C2.
(4) C1 sends f (X1) and C2 sends f (X2)3 or Siдnal (r , f (X2)) to the client.
(5) Client receives the returned results. Refunds and deposits are calculated according toGame2
if there is no signals.
(6) Otherwise, the client calls TTP no matter whether latter1 = latter2. Rewards and deposits
in contract Collusion − f ree are paid according to Algorithm 3.
3It defined according to three strategies as Game1.
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
33:16 H. Yan et al.
Fig. 5. Collusion-free game. Bold edges indicate the actions that parties will play in the unique sequential
equilibrium. The reachable terminal node of the game is in grey. The grid boxes denote the newly added
terminal nodes compared with Game2.
Recall that the rewards and deposits in contract Depositi (i = 1, 2) are paid according to Algo-
rithm 1. Deposit and bribery in contract Collusion are paid according to Algorithm 2.
Utility for rational clouds
The collusion-free game is denoted as Game3 and the utilities for rational clouds are listed in
Figure 5. The cheating detection probabilities of Game3 are the same with Game1.
Theorem 5.1. Given d > c + ch, the assessment (βcf , μcf ), where βcf
= (β1, β2) = ((¬init , r ),
(Collude, siдnal (r , f (x )))), μcf (I2) = (ξ1, ξ2, ξ3), (ξ1, ξ2, ξ3, ∈ [0, 1], ξ1+ξ2+ξ3 = 1) is weak sequential
equilibrium for collusion-free game.
Proof. We follow the proof line of Theorem 1 and 2. Note here μcf (I2) = (ξ1, ξ2, ξ3) can be
assigned any positive value once it satisfied that ξ1, ξ2, ξ3 ∈ [0, 1] and ξ1 + ξ2 + ξ3 = 1. The reason
is that I2 is not reachable according to βcf . Therefore, any belief on I2 is reasonable. Anyway, the
belief systems here still are updated according to Bayes’s rule.
Recall that u2 (v7), u2 (v10), and u2 (v13) are optimal compared with other terminal nodes in
Theorem 2. However, given d > c + ch, it satisfies that u2 (v15) > u2 (v7), u2 (v16) > u2 (v10), and
u2 (v17) > u2 (v13) in Game3. That is, C2 is certain to choose the strategy Collude at node v1 and
siдnal (r , f (x )) at I2, since it brings optimal utility no matter what strategy C1 takes. Knowing
this,C1 would not initiate a collusion contract withC2 at node v0. Therefore, the game enters into
Game1 in grey (Figure 5).
In a word, given d > c+ch, the assessment (βcf , μcf ) for collusion-free game is weak sequential
equilibrium for collusion-free game. That is, the contract collusion-f ree can efficiently prevents
collusion. �
The client need not set specifically parameters to prevent the potential contract Collusion be-
tween two clouds. We can prove that collusion between two clouds is impossible if proper param-
eters are set.
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
Collusion-free for Cloud Verification toward the View of Game Theory 33:17
Fig. 6. The codes of Algorithm 1 (Depositi ).
5.1 Implementation
We implement the contracts in Solidity 0.5.1 and deploy them on the Ethereum network with
Rinkeby. The addresses of the parties like the client ,Cloud1, andCloud2 are listed in Table 2, which
can be found in Rinkeby. Some codes are listed in Figures 6, 7, and 8, which corresponding to
Algorithms 1, 2, and 3.
The transaction fees of each function in the smart contracts are shown in Table 3. The cost for
the smart contract are rather low compare to the reward paid for the clouds. Therefore, we do not
consider the cost of the smart contract when we present the theoretical analysis.
6 CONCLUSION
Dong et al. [14] solve the problem of verifying computation by outsourcing two rational clouds.
They discuss single task for each cloud and they ignore the scenario where one cloud may bribe
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
33:18 H. Yan et al.
Fig. 7. The codes of Algorithm 2 (Collusion).
Table 2. The Addresses of the Parties Involved in the Smart Contracts
Parties Address
Client 0x3dd6f268d8FC12977DFFa4D8C0Fb801E947C2994
Cloud1 0x297fe8c0babC5C5a369DD65EBFb1734b228106fb
Cloud2 0x79502DEe0701010f15Ba64A2F64bB466B2Ad7a63
TTP 0xcceBD0d3C78edD35D3b787100b4B9A6aC1882749
Smart Contract 0xb09AfCa814973c0A495942bcBE9FDB83d2fec27E
Table 3. The Cost of Smart Contracts
Caller Smart contract Function Transaction Cost in gas Cost in $
Client
Smartcontr act Deployment 0x480c480c6d7123c501918d04dc91d8a4f561279e4d9ba7c1b6ed5742f0cc4f90 1531526 0.31
set Reward 0x6e202c516b9a4beebcc64c2f7d2d2326cfea26ea7bc56857557e2d138feed35b 62596 0.01289
sendReward 0xcac5a3c432cda7ad32068993f3ce0655001000845478123232056f79f1466153 36646 0.00755
дiveBonus 0xf77aba9beba2a2f0a733e82271d1d218b856d68ac631480837ffc50af6a03c09 43156 0.00899
дivePunishment 0xfc4ba11348bf550ad56b2dacf3065ea34437003e24ca83dc5d2a90bc0227571d 43266 0.00891
Cloud1
makeDepositd 0x056be948c32335016afc5efaa0e5d5658c1ead176bb30df12714f68e8c890b36 32535 0.00670
makeDepositt 0x1aad2dd490ebe7d9d2af9e92c7068556fca4119d7fbe047ea46feb3fdf9f81c7 32579 0.00671
r ef undDepositd 0xa138b7ea992192aa9d2658828810dd7e9d909092112a6723799a2a7ddecb4ce6 36366 0.00749
r ef undDepositt 0x1be4eabed0818cceec083b3307020708c3dcc7c32e63d223d52d0db2dea3d113 36322 0.00748
set Br ibery 0xb50ee6ea973433335eb30a042c38c192cc867551fbab7b2553508d2aff45c76c 47508 0.00978
sendBr ibery 0x17c2601860d08fda8e5a47e89440b3c729aa908fb8fd4372f5aa8dab893603fc 21382 0.00440
Cloud2
makeDepositd 0x23f300f34d7df2aa9ea262c2914c4b6ad0cf231520b967824d1acd7fa4fd3a60 32535 0.00670
makeDepositt 0x1f2a2cd94a128f2d8c574a210cd9720452d3c83d3a9c9cf7bf50a3c61efa9f55 32579 0.00671
r ef undDepositd 0x990609369e690a9958d7b26bc35cfc784617ed175c225ecc85159b001717236e 21366 0.00440
r ef undDepositt 0xcc47e149cbc51a31b743cf3aac6c6b77ffaecd400b2feb8f808e17060eb3dc63 51322 0.10572
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
Collusion-free for Cloud Verification toward the View of Game Theory 33:19
Fig. 8. The codes of Algorithm 3 (Collusion − f ree).
the other one to strengthening the collusion. In this article, we extend the single task to
multi-task and allow bribery between them. At first, the collusion is an empty threat for the
client, since no enforcement between two clouds. Then we consider the possibility of collusion
when there exists a deposit between two clouds. We prove that collusion is established given
proper parameters. Finally, we construct a collusion-free contract between the client and one
cloud to impede the collusion. We prove that our signal scheme is collusion-free with proper
parameters. That is, honest computation without collusion is dominant strategy for both clouds.
Future works include involve scenario such as incomplete information, where clouds are allowed
to have private types. The dominant strategies are more complex, since private types have strong
influence on strategy chosen.
REFERENCES
[1] David P. Anderson, Jeff Cobb, Eric Korpela, Matt Lebofsky, and Dan Werthimer. 2002. SETI@ home: An experiment
in public-resource computing. Commun. ACM 45, 11 (2002), 56–61.
[2] László Babai, Lance Fortnow, Leonid A. Levin, and Mario Szegedy. 1991. Checking computations in polylogarithmic
time. In Proceedings of the 23rd Annual ACM Symposium on Theory of Computing. ACM, 21–32.
[3] Michael Backes, Dario Fiore, and Raphael M. Reischuk. 2013. Verifiable delegation of computation on outsourced data.
In Proceedings of the ACM SIGSAC Conference on Computer & Communications Security. ACM, 863–874.
[4] Iddo Bentov and Ranjit Kumaresan. 2014. How to use bitcoin to design fair protocols. In Proceedings of the International
Cryptology Conference. Springer, 421–439.
[5] Giulio Binetti, Ali Davoudi, David Naso, Biagio Turchiano, and Frank L. Lewis. 2013. A distributed auction-based
algorithm for the nonconvex economic dispatch problem. IEEE Trans. Industr. Inf. 10, 2 (2013), 1124–1132.
[6] Vitalik Buterin. 2014. A Next-generation Smart Contract and Decentralized Application Platform. White Paper (2014).
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
33:20 H. Yan et al.
[7] Ran Canetti, Yilei Chen, Justin Holmgren, and Mariana Raykova. 2016. Adaptive succinct garbled RAM or: How to
delegate your database. In Theory of Cryptography Conference. Springer, 61–90.
[8] Ran Canetti, Ben Riva, and Guy N. Rothblum. 2011. Practical delegation of computation using multiple servers. In
Proceedings of the 18th ACM Conference on Computer and Communications Security. ACM, 445–454.
[9] Bogdan Carbunar and Mahesh V. Tripunitara. 2012. Payments for outsourced computations. IEEE Trans. Parallel Dis-
trib. Syst. 23, 2 (2012), 313–320.
[10] Lien-Wu Chen and Yu-Fan Ho. 2019. Centimeter-grade metropolitan positioning for lane-level intelligent transporta-
tion systems based on the internet of vehicles. IEEE Trans. Industr. Inf. 15, 3 (2019), 1474–1485.
[11] Li Da Xu, Wu He, and Shancang Li. 2014. Internet of things in industries: A survey. IEEE Trans. Industr. Inf. 10, 4 (2014),
2233–2243.
[12] Kevin Delmolino, Mitchell Arnett, Ahmed E. Kosba, Andrew Miller, and Elaine Shi. 2015. Step by step toward cre-
ating a safe smart contract: Lessons and insights from a cryptocurrency lab. IACR Cryptol. ePrint Arch. 2015 (2015),
460.
[13] Xue-Feng Ding and Hu-Chen Liu. 2019. A new approach for emergency decision-making based on zero-sum game
with Pythagorean fuzzy uncertain linguistic variables. Int. J. Intell. Syst. 34, 7 (2019), 1667–1684. https://doi.org/10.
1002/int.22113
[14] Changyu Dong, Yilei Wang, Amjad Aldweesh, Patrick McCorry, and Aad van Moorsel. 2017. Betrayal, distrust, and
rationality: Smart counter-collusion contracts for verifiable cloud computing. In Proceedings of the ACM SIGSAC Con-
ference on Computer and Communications Security. ACM, 211–227.
[15] Rosario Gennaro, Craig Gentry, and Bryan Parno. 2010. Non-interactive verifiable computing: Outsourcing computa-
tion to untrusted workers. In Annual Cryptology Conference. Springer, 465–482.
[16] Rosario Gennaro and Daniel Wichs. 2013. Fully homomorphic message authenticators. In Proceedings of the Interna-
tional Conference on the Theory and Application of Cryptology and Information Security. Springer, 301–320.
[17] Shafi Goldwasser, Yael Tauman Kalai, and Guy N. Rothblum. 2008. Delegating computation: Interactive proofs for
muggles. In Proceedings of the 40th Annual ACM Symposium on Theory of Computing. ACM, 113–122.
[18] Yuzhen Han and Yong Deng. 2019. A novel matrix game with payoffs of Maxitive Belief Structure. Int. J. Intell. Syst.
34, 4 (2019), 690–706. https://doi.org/10.1002/int.22072
[19] Seny Kamara and Mariana Raykova. 2011. Secure outsourced computation in a multi-tenant cloud. In Proceedings of
the IBM Workshop on Cryptography and Security in Clouds. 15–16.
[20] M. H. R. Khouzani, Viet Pham, and Carlos Cid. 2014. Incentive engineering for outsourced computation in the face of
collusion. In Proceedings of the Annual Workshop on the Economics of Information Security (WEIS’14).
[21] David M. Kreps. 1990. A Course in Microeconomic Theory. Princeton University Press.
[22] Ranjit Kumaresan and Iddo Bentov. 2014. How to use bitcoin to incentivize correct computations. In Proceedings of
the ACM SIGSAC Conference on Computer and Communications Security. ACM, 30–41.
[23] Silvio Micali. 2000. Computationally sound proofs. SIAM J. Comput. 30, 4 (2000), 1253–1298.
[24] Satoshi Nakamoto. 2008. Bitcoin: A peer-to-peer electronic cash system. https://courses.cs.washington.edu/courses/
csep552/18wi/papers/nakamoto-bitcoin.pdf.
[25] Robert Nix and Murat Kantarcioglu. 2012. Contractual agreement design for enforcing honesty in cloud outsourcing.
In Proceedings of the International Conference on Decision and Game Theory for Security. Springer, 296–308.
[26] M. Osborne and A. Rubinstein. 2004. A Course in Game Theory. MIT Press, Cambridge, MA.
[27] Martin J. Osborne and Ariel Rubinstein. 1994. A Course in Game Theory. MIT Press, Cambridge, MA.
[28] Bryan Parno, Jon Howell, Craig Gentry, and Mariana Raykova. 2013. Pinocchio: Nearly practical verifiable computa-
tion. In Proceedings of the IEEE Symposium on Security and Privacy (SP’13). IEEE, 238–252.
[29] Viet Pham, M. H. R. Khouzani, and Carlos Cid. 2014. Optimal contracts for outsourced computation. In Proceedings of
the International Conference on Decision and Game Theory for Security. Springer, 79–98.
[30] The Folding@home project. [n.d.]. Stanford University. Retrieved from http://www.stanford.edu/group/pandegroup/
cosm/.
[31] Srinath Setty, Victor Vu, Nikhil Panpalia, Benjamin Braun, Andrew J. Blumberg, and Michael Walfish. 2012. Taking
proof-based verified computation a few steps closer to practicality. In Presented as Part of the 21st USENIX Security
Symposium (USENIX Security’12). 253–268.
[32] Srinath T. V. Setty, Richard McPherson, Andrew J. Blumberg, and Michael Walfish. 2012. Making argument systems
for outsourced computation practical (sometimes). In Proceedings of the Network and Distributed System Security Sym-
posium (NDSS’12), Vol. 1. 17.
[33] Fei Tao, Ying Cheng, Li Da Xu, Lin Zhang, and Bo Hu Li. 2014. CCIoT-CMfg: Cloud computing and internet of things-
based cloud manufacturing service system. IEEE Trans. Industr. Inf. 10, 2 (2014), 1435–1442.
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.
https://doi.org/10.1002/int.22113
https://doi.org/10.1002/int.22072
https://courses.cs.washington.edu/courses/csep552/18wi/papers/nakamoto-bitcoin.pdf
http://www.stanford.edu/group/pandegroup/cosm/
Collusion-free for Cloud Verification toward the View of Game Theory 33:21
[34] Fei Tao, Ying Zuo, Li Da Xu, and Lin Zhang. 2014. IoT-based intelligent perception and access of manufacturing
resource toward cloud manufacturing. IEEE Trans. Industr. Inf. 10, 2 (2014), 1547–1557.
[35] Li Tao, Brij Bhooshan Gupta, and Roberto Metere. 2018. Socially-conforming cooperative computation in cloud net-
works. J. Parallel Distrib. Comput. 117 (2018), 274–280.
[36] Wang Yilei, Bracciali Andrea, Li Tao, Li Fengyin, Cui Xinchun, and Zhao Minghao. 2019. Randomness invalidates
criminal smart contracts. Inf. Sci. 477 (2019), 291–301.
[37] Qi Zhao, Chuan Zhao, Shujie Cui, Shan Jing, and Zhenxiang Chen. 2020. PrivateDL: Privacy-preserving collaborative
deep learning against leakage from gradient sharing. Int. J. Intell. Syst. (2020).
[38] Yu Zheng, Yue Song, David J. Hill, and Ke Meng. 2019. Online distributed MPC-based optimal scheduling for EV
charging stations in distribution systems. IEEE Trans. Industr. Inf. 15, 2 (2019), 638–649.
Received June 2020; revised July 2020; accepted September 2020
ACM Transactions on Internet Technology, Vol. 22, No. 2, Article 33. Publication date: November 2021.