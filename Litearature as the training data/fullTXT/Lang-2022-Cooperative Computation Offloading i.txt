Cooperative Computation Offloading in Blockchain-Based Vehicular Edge Computing Networks
IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 7, NO. 3, SEPTEMBER 2022 783
Cooperative Computation Offloading in
Blockchain-Based Vehicular Edge
Computing Networks
Ping Lang , Daxin Tian , Senior Member, IEEE, Xuting Duan , Jianshan Zhou ,
Zhengguo Sheng , Senior Member, IEEE, and Victor C. M. Leung , Life Fellow, IEEE
Abstract—As a novel computing paradigm, multiaccess edge
computing (MEC) migrates computing and storage capabilities to
edge nodes of the network to meet the requirements of executing
computationally intensive or delay-sensitive tasks on intelligent
vehicles. In addition, MEC fills the gap between cloud computing
and terminals in vehicular networks. In the MEC system, to reduce
the load on MEC servers with large-scale vehicle deployment and
promote the efficient use of network resources, vehicles can also
transfer tasks to neighboring resource-rich vehicles using cooper-
ative computation offloading. However, cooperative computation
offloading between vehicles faces the challenges of security and
insufficient information about the server vehicle. Therefore, this
paper proposes using blockchain technology to achieve efficient
data sharing between vehicles and service providers (i.e., server
vehicles) and ensure the security of computation offloading between
vehicles. First, we design a secure data sharing architecture in
blockchain-based vehicular edge computing networks. Then, a new
consensus mechanism in this architecture is proposed to improve
the efficiency of data sharing and prevent malicious attacks. Fur-
thermore, we present a cooperative offloading decision-making
method using an offloading game, and the Nash equilibrium of
the offloading strategy is achieved using this method. The results
of numerical experiments demonstrate the superior performance
of the proposed method.
Index Terms—Vehicular edge computing, cooperative computa-
tion offloading, data sharing, blockchain, game theory.
Manuscript received 24 June 2022; revised 6 July 2022; accepted 8 July 2022.
Date of publication 12 July 2022; date of current version 24 October 2022. This
research was supported in part by the National Natural Science Foundation of
China under Grants U20A20155, 62061130221, and 62173012, in part by the
Beijing Municipal Natural Science Foundation under Grant L191001, in part by
the Zhuoyue Program of Beihang University (Postdoctoral Fellowship), and in
part by the China Postdoctoral Science Foundation under Grant 2020M680299.
(Corresponding author: Daxin Tian.)
Ping Lang, Daxin Tian, Xuting Duan, and Jianshan Zhou are with the Beijing
Advanced Innovation Center for Big Data and Brain Computing, Beijing Key
Laboratory for Cooperative Vehicle Infrastructure Systems and Safety Control,
School of Transportation Science and Engineering, Beihang University, Beijing
100191, China (e-mail: langping@buaa.edu.cn; dtian@buaa.edu.cn; duanxut-
ing@buaa.edu.cn; jianshanzhou@foxmail.com).
Zhengguo Sheng is with the Department of Engineering and Design, Univer-
sity of Sussex, Richmond 3A09, U.K. (e-mail: z.sheng@sussex.ac.uk).
Victor C. M. Leung is with the Department of Electrical and Computer
Engineering, The University of British Columbia, Vancouver, BC V6T 1Z4,
Canada (e-mail: vleung@ieee.org).
Color versions of one or more figures in this article are available at
https://doi.org/10.1109/TIV.2022.3190308.
Digital Object Identifier 10.1109/TIV.2022.3190308
I. INTRODUCTION
ADVANCEMENTS in automated driving technology and
intelligent transportation systems have led to a prolifer-
ation of applications for safety assurance, efficiency enhance-
ment, and entertainment [1]–[6]. In contrast to traditional ve-
hicles, in which people observe the environment and perform
dynamic driving tasks with manual control, intelligent vehicles
achieve intelligent environment perception by deploying various
sensors such as cameras and LiDARs, and assist in driving or
even achieve autonomous driving by performing computation-
ally intensive and delay-sensitive tasks. To meet the require-
ments of these computationally intensive and delay-sensitive
applications, more computing and storage resources must be
deployed on vehicles, which increases the cost of deploying
autonomous vehicles [7]. In addition, it is difficult to provide
sufficient onboard resources due to the limited physical space
on vehicles.
To facilitate the efficient and stable execution of onboard
applications, researchers have developed a new architecture and
corresponding technology called multiaccess edge computing
(MEC) [8], [9], formerly known as mobile edge computing [10].
MEC helps vehicles achieve real-time data processing by em-
ploying the computing capabilities of the edge of the network.
Therefore, a vehicle can offload difficult computing tasks to the
MEC server to meet the delay demands of advanced onboard
applications [11]. Compared with cloud computing, MEC can
significantly reduce the transmission delay of data and ensure
real-time processing of the data in vehicles or other terminals.
However, constrained by limited computing resources, the
local capabilities of MEC servers may also be insufficient with
the large-scale deployment of intelligent vehicles [12], [13]. A
motivating example is as follows. During high traffic volumes
(e.g., traffic jams or rush hours), many intelligent vehicles of-
fload their computation tasks to a single roadside MEC server
covering this area, which will cause the computation require-
ments to exceed the computation capacity of that server. As
a result of competition between multiple vehicles for limited
resources, the quality of service for applications will not be
guaranteed [14]. That is, the computing tasks of vehicles will
be completed beyond the maximum time they can tolerate,
causing a large number of delay-sensitive applications to not be
executed properly. A case in point is augmented reality or virtual
2379-8858 © 2022 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
https://orcid.org/0000-0001-7369-3563
https://orcid.org/0000-0001-7796-5650
https://orcid.org/0000-0001-5931-8310
https://orcid.org/0000-0001-5331-6162
https://orcid.org/0000-0003-2143-4003
https://orcid.org/0000-0003-3529-2640
mailto:langping@buaa.edu.cn
mailto:dtian@buaa.edu.cn
mailto:duanxuting@buaa.edu.cn
mailto:duanxuting@buaa.edu.cn
mailto:jianshanzhou@foxmail.com
mailto:z.sheng@sussex.ac.uk
mailto:vleung@ieee.org
https://doi.org/10.1109/TIV.2022.3190308
784 IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 7, NO. 3, SEPTEMBER 2022
Fig. 1. Cooperative computation offloading in vehicular edge computing
networks.
reality applications, such as cloud gaming in vehicles, which
have critical delay requirements and involve heavy computation
when the resolution and frame rate increase. These cloud gaming
applications require extensive processing for rendering, which
can be performed on the network or device side. The 3 rd Gen-
eration Partnership Project (3GPP) has specified performance
requirements for cloud gaming (e.g., bandwidth and latency)
and introduced split rendering architecture that allows rendering
tasks to be performed flexibly on different entities [15], [16]. For
example, some rendering tasks can be performed on the host
vehicle, while other tasks can be performed on edge servers or
on other vehicles when the edge servers are overloaded.
Therefore, in addition to offloading computing tasks to the
MEC server, vehicles can also offload them to neighboring ve-
hicles, which have redundant computing and storage resources,
to reduce the burden on the MEC server [17], [18]. As illustrated
in Fig. 1, in this scenario, the user vehicle can offload its onboard
computing tasks to the MEC server or to neighboring vehicles ac-
cording to the resource usage of the edge server and the number
of neighboring service providers. This cooperative computation
offloading effectively reduces the load on the MEC server, which
helps to promote the efficient use of resources in the network
and reduce waste caused by idle computing resources.
However, no methods have been developed for vehicles to
accurately determine the computing capacity and trajectory
of service providers for cooperative computation offloading.
Transmission security and vehicle privacy are also difficult to
guarantee in computation offloading between vehicles [19], [20].
Since computation offloading of vehicles often involves private
data such as their trajectory, driving status, and surrounding envi-
ronment, vehicles need to be sure that their offloading destination
is a trusted service provider before computation offloading. In
cooperative computation offloading, the server vehicle provides
computation services for the surrounding vehicles as a service
provider autonomously, which makes it difficult to guarantee the
trustworthiness of its information. Once malicious nodes appear
in the server vehicles, the privacy of user vehicles will be dis-
closed, which jeopardizes the information security and even the
driving safety of vehicles and drivers. Therefore, it is necessary
to construct a secure and tamper-proof sharing architecture of
service provider information to ensure the trustworthiness of
server vehicles.
Recently, blockchain technology has attracted a great deal
of attention in vehicular networks in both academia and in-
dustry [21]–[23]. As a decentralized data storage technology,
blockchain is characterized by distributed processing, multiparty
consensus, and tamper-proof features [24], [25]. It can achieve
secure synchronization and sharing of data between multiple
parties and guarantee the credibility of information [26]–[28].
By integrating blockchain technology into vehicular edge com-
puting networks, an efficient and secure data sharing mech-
anism can be established among MEC servers to supply in-
formation on neighboring service providers to user vehicles,
which can significantly improve the cooperation and security
of the system. Specifically, facing the previously mentioned
security challenges, the blockchain-based secure information
sharing mechanism can verify the identity of the server ve-
hicle and ensure the trustworthiness of its service capabilities
through the blockchain nodes. Moreover, attacks by malicious
nodes can be identified and prevented by the consensus mecha-
nism in the blockchain. In addition, the immutability of data
in blockchain ensures the traceability of service information
and thus the attacker can be traced after a malicious attack
occurs.
To avoid the competition for the roadside server resources,
vehicles can offload tasks to neighboring resource-rich vehi-
cles (i.e., server vehicles or service providers) with redundant
computing resources for execution, thereby reducing the use
of roadside resources. Note that both user vehicles and server
vehicles in this paper are intelligent vehicles, in which user ve-
hicles are low-cost intelligent vehicles that deploy limited com-
puting resources, and server vehicles are advanced autonomous
vehicles with redundant computing resources. Therefore, the
server vehicle can provide computing services to the user ve-
hicle by cooperative computation offloading. With the addition
of resource-rich vehicles as edge servers, this study faces the
challenges of both trusted information sharing of server vehicles
and policy evaluation for task offloading to server vehicles and
roadside servers. In the existing studies of the cooperative com-
putation offloading, the server vehicles are assumed to be trusted
nodes and their service capabilities and trajectories have been
accessed by the user vehicles. However, in practice, there is a
lack of a trusted sharing mechanism for the information of server
vehicles. In addition, the existing studies of blockchain-based
data sharing in vehicular edge computing networks have not
addressed the sharing mechanism for the information of service
providers. Therefore, different from the existing studies, we
propose a novel blockchain-based data sharing architecture for
vehicular MEC networks to provide accurate information on
server vehicles for cooperative computation offloading. Note
that in terms of blockchain-based sharing methods and consen-
sus mechanisms, this paper focuses on novel applications of
blockchain technology in cooperative computation offloading,
rather than proposing new algorithms in the blockchain field.
In addition, we model the offloading decision process of each
user vehicle using game theory to achieve an equilibrium of
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
LANG et al.: COOPERATIVE COMPUTATION OFFLOADING IN BLOCKCHAIN-BASED VEHICULAR EDGE COMPUTING NETWORKS 785
offloading strategies in the region. The major contributions of
this paper are summarized as follows:
� We propose a secure information sharing mechanism be-
tween user vehicles and service providers and a coopera-
tive computing method for vehicles based on blockchain
technology to ensure security and access to accurate infor-
mation.
� In the blockchain-based data sharing architecture, we
propose a consensus mechanism that combines Proof
of Service [29] and Practical Byzantine Fault Tolerance
(PBFT) [30] to achieve data synchronization between MEC
networks and prevent malicious attacks.
� To help user vehicles make correct computation offload-
ing decisions, we propose an offloading game model for
cooperative computation offloading scenarios, in which
user vehicles can select roadside MEC servers or neigh-
boring resource-rich vehicles with different probabilities
to execute applications and achieve Nash equilibrium. The
performance of the proposed game method is evaluated by
experimental comparison.
The remainder of this paper is organized as follows. Section II
discusses related studies, while Section III presents the secure
information sharing mechanism between user vehicles and ser-
vice providers with a consensus mechanism in blockchain-based
vehicular edge computing networks. Section IV presents the de-
sign of the offloading game method in cooperative computation
offloading scenarios and describes the Nash equilibrium with a
distributed solution. Section V provides the performance anal-
ysis of the proposed algorithm and the comparison with other
computation offloading methods. Finally, Section VI concludes
the paper.
II. RELATED WORK
Computation offloading is a key research topic in MEC and
mobile cloud computing, and there is a large amount of liter-
ature on computation offloading problems for vehicular MEC
networks. Zhao et al. [31] researched the problem of com-
putation offloading and resource allocation for cloud-assisted
vehicular MEC, where the offloaded tasks could be executed on
roadside MEC servers or migrated to cloud computing servers
using roadside units. They proposed a collaborative optimization
scheme for this problem and developed a distributed method
to obtain the best optimization results. Ke et al. [32] modeled
task computation offloading in an unstable environment with
a varying channel state and available bandwidth to minimize
the energy consumption, allocated bandwidth, and transmission
delay. They then proposed a deep-reinforcement-learning-based
adaptive computation offloading method to solve this prob-
lem and achieve the optimal offloading action. To reduce the
overhead of MEC servers and improve the performance of
computation offloading, Dai et al. [33] jointly modeled the
offloading of vehicles and load balancing of roadside MEC
servers and proposed a joint algorithm for server selection and
offloading. Similarly, in our previous study [14], we proposed
a computation offloading game for a large number of vehicles
to reduce the computational burden on roadside MEC servers.
We also designed a distributed best-response algorithm to guar-
antee the uniqueness of the Nash equilibrium converged by the
offloading strategies of vehicles, thus achieving efficient and
stable computation offloading.
As reported by the 5G Automotive Association (5GAA) [17],
vehicles can migrate tasks to neighboring resource-rich vehicles
for execution as well as offload them to roadside servers. Sun
et al. [34] considered vehicle-to-vehicle (V2V) task offloading
in a dynamic and uncertain vehicular wireless environment
and proposed a distributed adaptive learning-based offloading
method to optimize the delay in computation offloading. To
relieve the workload of cloudlet nodes and improve resource
utilization of vehicular fog computing, Yadav et al. [35] pro-
posed a dynamic computation offloading solution to achieve
energy-latency tradeoff and effective resource allocation in V2V
offloading. They provided a heuristic method as the resource
allocation solution and minimized the energy consumption and
offloading latency. However, existing studies on V2V offloading
assume that information on the service provider can be obtained
by simple communication, which exposes vehicles to security
and privacy risks while preventing them from effectively obtain-
ing the service provider data.
As a decentralized and trusted storage approach, blockchain
can facilitate data sharing and ensure the security and im-
mutability of information. Thus, its applications in MEC and
vehicular networks have been widely studied in the literature.
Yang et al. [24] summarized various studies on integrated
blockchain and MEC systems and provided a clear description
of the complementarity of blockchain and MEC. They provided
typical architectures of the integrated system and discussed the
functions of computation, storage, and network in this system.
To ensure the security and privacy of data storage and sharing
in an integrated platform of MEC and vehicular networks, Kang
et al. [26] established an efficient data storage and sharing
mechanism using blockchain and its smart contracts. In the infor-
mation sharing scheme, they developed a logic-based evaluation
mechanism to select secure information providers and ensure the
credibility of the shared information. In another study, Zhang
et al. [36] designed a hierarchical software-defined vehicular
network with blockchain and used a dueling deep reinforce-
ment learning (DRL) method to improve the throughput of
this integrated system. Fu et al. [37] investigated efficient and
secure machine learning methods for connected autonomous
vehicles and designed a collective learning framework with
blockchain to achieve the distributed training and sharing of
machine learning models for connected autonomous vehicles.
In this architecture, blockchain was used to protect the integrity
of the shared models and to prevent malicious node attacks.
To enhance the capability of onboard positioning and support
autonomous driving, Li et al. [38] proposed a positioning error
evolution sharing architecture using blockchain. They also pro-
posed a deep-learning-based positioning correction method as a
shared model to improve the applicability of the framework.
Some studies have also combined blockchain with compu-
tation offloading to improve the security of the latter. Guo
et al. [39] designed a computation offloading architecture
in blockchain-based MEC networks to verify and audit the
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
786 IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 7, NO. 3, SEPTEMBER 2022
execution results of tasks using smart contracts in blockchain
systems. In this architecture, the authors considered the vari-
ables of resource allocation, block size, and block number and
presented a DRL-based method to optimize the latency and
throughput of the joint system. Qiu et al. [40] also provided
a computation offloading solution using DRL to offload the
mining and data processing applications of mobile terminals
to the MEC server in blockchain-empowered MEC networks.
To ensure the security and privacy of relay-based computation
offloading, Feng et al. [41] designed a relay-based offloading
framework in blockchain-enabled MEC networks and optimized
the throughput and computation rate of this integrated system
using the asynchronous advantage actor-critic (A3C) algorithm.
For a vehicular network, Zheng et al. [42] reused the hierarchical
distributed software-defined architecture in [36] and proposed a
secure access method with smart contracts to construct a trusted
computation offloading framework in integrated edge-cloud net-
works. They also designed a DRL-based offloading solution to
achieve a tradeoff between latency and energy consumption in
computation offloading.
Blockchain can thus ensure secure sharing of information in
computation offloading to prevent attacks by malicious nodes.
However, to the best of our knowledge, existing studies have
focused on the sharing of sensing data, autonomous driving
learning models, positioning errors, and computation offloading
applications on audit, mining, and access control in a combined
blockchain-based MEC system while ignoring the information
sharing requirements of service providers in cooperative compu-
tation offloading. In this paper, we propose an information shar-
ing architecture and consensus mechanism for service providers
based on blockchain in cooperative computation offloading to
provide secure and accurate offloading service information for
user vehicles. The proposed blockchain-based data sharing is
a new application of blockchain in cooperative computation
offloading to ensure the shared information of server vehicles is
consistency and tamper-proof. Based on the shared information,
we propose a cooperative offloading game model that allows user
vehicles to make optimal offloading decisions.
III. BLOCKCHAIN-BASED DATA SHARING
A. Scenario Overview
In this study, we assume that user vehicles drive within the
coverage area of the roadside MEC server (also called the edge
node), and that there are server vehicles around the user vehicles
that can provide computing services, which are also called
resource-rich vehicles or service providers. A blockchain system
is deployed on each roadside MEC server, and the MEC servers
can achieve data sharing and synchronization using blockchain.
When a user vehicle vi is faced with a computing task that
cannot be completed in the required time, the vehicle must
decide whether to send the task to the roadside server or service
provider. To make an accurate decision regarding computation
offloading, the user vehicle must obtain the service capacity
information of the neighboring server vehicles. In this scenario,
to expand the transmission range of service capacities on server
vehicles and prevent attacks by malicious nodes, we adopt
Fig. 2. Data sharing between user vehicles and service providers in
blockchain-based vehicular edge computing networks.
blockchain to share the information of idle server vehicles to
user vehicles to provide a basis for their decision to computation
offloading.
B. Secure Data Sharing Scheme for Cooperative Computation
Offloading
As mentioned above, in vehicular edge computing networks,
each roadside MEC server shares the information of the server
vehicle with the blockchain and broadcasts this information to
vehicles within its coverage area. Note that user vehicles do not
store all the received data, but filter the server vehicles with
matching trajectories as potential service providers during data
receiving to avoid excessive data storage. Then, the user vehicle
that requires computation offloading makes a game decision
according to the received information of the neighboring server
vehicles and roadside MEC servers. Finally, the task can be
migrated to the roadside MEC server or a server vehicle to ensure
the secure and stable execution of the onboard application. The
service provider data sharing scheme is designed as illustrated
in Fig. 2 and described below.
Step 1: The server vehicle uploads its service capacity to the
roadside MEC server. Within the range of the area covered by the
MEC serverMECm, the server vehicle vj , which has redundant
computing resources, determines its service capacity, such as
the computing resources resourcej , service period periodj ,
planned trajectory trajectoryj , and initial price priceinitj .
Then, vj establishes a communication link with MECm and
sends data regarding the service capacity to MECm after en-
cryption, attaching the certificate of the vehicle and the signature
of the message as
vj → MECm : EKpu
MECm
(
timestamp||DataPseus
j
||CertPseus
j
||SignPseus
j
(
DataPseus
j
))
,
where Kpu
MECm
is the public key of MECm, Pseus
j is the cur-
rent pseudonym used by vehicle j, CertPseus
j
and SignPseus
j
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
LANG et al.: COOPERATIVE COMPUTATION OFFLOADING IN BLOCKCHAIN-BASED VEHICULAR EDGE COMPUTING NETWORKS 787
are the corresponding certificate and signature, respectively, and
DataPseus
j
= EKpr
Pseus
j
(timestamp||resourcej
||trajectoryj ||priceinitj ||periodj
)
(1)
is the data of the service capacity of vj encrypted by its private
key. Specifically, the form of the service capability data uploaded
by the server vehicle vj in (1) consists of the time of data
generation, the computing resources, the travel trajectory, the
desired initial service price, and the service price of vj . These
contents are further encrypted by the private key Kpr
Pseus
j
of vj
to form the service capability data uploaded by vj . Note that
since the vehicle periodically broadcasts its status containing
the certificate and public key via vehicle-to-everything (V2X)
communication [43], [44] in vehicular networks, we assume that
both the vehicle and the roadside MEC server have obtained each
other’s public keys before data sharing.
Step 2: The roadside MEC server collects the vehicle service
capacity information. After receiving the encrypted message
sent by vj , MECm decrypts the message with its private key
to obtain the service capacity provided by vj , and verifies the
signature of vj . Then, MECm identifies the service capacity
information and stores it as a service capacity record in the form
of a transaction record as
record = (timestamp||recordID||provider||resource
||trajectory||price||period||quality) , (2)
where recordID is the index of the service capacity record,
provider is the service provider, and resource, trajectory,
and period are the computing resources, trajectory, and service
duration, respectively, that the server vehicle can provide for
the service. In addition, quality ∈ [0, 1] is the evaluation of
the service quality provided by the user vehicle: the higher the
value, the higher the evaluation. In (2), we represent the service
capability of the server vehicle in the form of a transaction
record stored in the blockchain. Specifically, the previously
mentioned data generation time, the index of the record, and the
serial number, the computing resources, the travel trajectory, the
service price, the service period and the service quality of the
service vehicle together form the service capability record. The
MEC server uses the smart contract feature [45] of blockchain
to dynamically price the computing services with the quality of
service as
price = priceinit · quality. (3)
Step 3: The MEC server adds the service capacity record of
the server vehicle to the blockchain. As illustrated in Fig. 3,
the MEC server (i.e., blockchain node for data sharing) uses a
consensus mechanism combining Proof of Service and PBFT to
share the records of the service capacity within a certain time
period and ensure the security of the data to prevent malicious
attacks. It is worth to noting that we use a limited number of MEC
servers instead of vehicles as blockchain nodes to improve the
efficiency of consensus to avoid the inefficiency of the consensus
mechanism caused by excessive blockchain nodes. The specific
processes are as follows.
Fig. 3. Consensus mechanism for data sharing between user vehicles and
service providers.
1) Broadcast: The MEC server (e.g., MECm) broadcasts
the service capacity information obtained in Step 2 in the
blockchain network (i.e., network composed of all edge
computing nodes). Then, each node collects the service
capacity records sent by other nodes and stores them.
2) Select: After a certain time t, a primary node (leader) is
selected in the blockchain system to organize the recently
generated service capacity records into a block and add this
block to the current chain through a consensus mechanism
between all MEC servers. Then, the latest block can be
shared in the system. Here the leader is selected with the
Proof of Service mechanism; that is, based on the current
computing capacity of each node, the node with more
redundant computing resources is selected as the primary
node to generate the block. To avoid the server with strong
computing power being the only leader, the p nodes with
redundant computing resources are selected as the primary
node in turn to generate new blocks. When all p nodes have
become proposers, the server with redundant computing
resources will be reselected and proceed to the next round.
3) Pre-prepare: Each node determines whether it is the pri-
mary node. If it is the selected leader, it broadcasts its
generated block and its verification results as a pre-prepare
message to other MEC servers in the blockchain network.
4) Prepare: After receiving the pre-prepare message, all
MEC servers verify the authenticity of the leader and the
validity of the content in the block. Then, they broadcast
the verification results in the network as prepare messages.
5) Commit: After receiving the prepare messages sent by
other nodes, each MEC server uses the messages along
with its own verification result to make a decision and vote
on whether the block is generated successfully. If the total
number of valid results exceeds 2f (f can be interpreted
as the maximum number of virulent servers that can be
tolerated), the MEC server broadcasts the commit message
to all other nodes in the blockchain network to indicate its
voting result.
6) Reply: After receiving the commit messages sent by other
nodes, each MEC server uses the messages along with
its own voting result to make a decision. If the number
of votes in favor of the generated block exceeds 2f + 1
(including the vote of the node itself), it is considered
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
788 IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 7, NO. 3, SEPTEMBER 2022
that the blockchain system has reached a consensus on the
generation of the block, and the consensus result is sent to
the leader.
7) Store: The primary node receives the consensus result of
each MEC server and sends the latest block to all MEC
servers in the system for data sharing and storage.
Step 4: The roadside MEC server sends the service capacity
information of the block to the vehicle within its coverage area.
After completing data sharing with the blockchain, the roadside
MEC server (e.g., MECl) parses the latest service capacity
record in the block and sends the parsed record to user vehicles
in its communication coverage (e.g., vehicle vi) with encrypted
transmission, namely
MECl → vi : EKpu
Pseus
i
(timestamp||DataMECl
||CertMECl
||SignMECl
(DataMECl
)) ,
where
DataMECl
= EKpr
MECl
(timestamp||record1
||record2|| · · · ||recordz) . (4)
After receiving the record sent by MECl, user vehicle vi
decrypts the data with its private key and verifies the signature of
MECl. Then, vi uses the parsed data of the latest neighboring
server vehicles and the data of service chain introduced in Step
6 to verify whether there is a server vehicle that can complete
the V2V computation offloading; this help to make subsequent
computation offloading decisions.
Step 5: The user vehicle makes an offloading decision based
on the service capacity of the MEC server and the neighboring
server vehicles. The user vehicle vi that requires offloading
determines the code codei, the input data datai of the task to
be computed, and the deadline deadlinei for the task. If there is
no server vehicle that can provide computing resources around
vi, the vehicle sends its task directly to the MEC server. If
there is more than one server vehicle around it, vi selects the
server vehicle vj that is closest to its trajectory and performs
the computation offloading decision process proposed in the
Section IV. To more clearly describe the secure data sharing
mechanism for cooperative computation offloading, we assume
that vi decides to send its task to vehicle vj as
vi → vj : EKpu
Pseus
j
(
timestamp||RequestPseus
i
||CertPseus
i
||SignPseus
i
(
RequestPseus
i
))
,
where
RequestPseus
i
= EKpr
Pseus
i
(timestamp||codei||datai||deadlinei) . (5)
Step 6: The server vehicle uploads the information of ongoing
service, and the MEC server updates the service chain. Since
the computing resources of the server vehicles are significantly
less than those of the roadside servers, we consider that each
server vehicle can only provide computing services to one user
vehicle simultaneously. With the proposed service capability
chain, roadside edge servers share the service capability infor-
mation of server vehicles and provide it to user vehicles, but
the dynamically changing service status of offloading cannot be
captured in the chain. Therefore, we add a service chain to share
the service information of occupied server vehicles so that user
vehicles can determine the available server vehicles for offload-
ing decisions. If user vehicle vi has selected a server vehicle to
which to offload the computation task, the server vehicle also
generates the current service information and uploads it to the
nearby MEC server when it starts to execute the computation
task. Similar to the operation in Steps 1–4, the MEC server
packages different service information to form a block. Through
the consensus mechanism, this service block is added to the
service chain parallel to the service capacity chain mentioned
above, and the service information of the current service provider
is shared through the service chain to assist user vehicles in the
computation offloading decision. Since the specific consensus
processes of ongoing service information sharing are the same
as those of the service capacity sharing, this step only provides
the format of the service record as follows:
service = (timestamp||serviceID||provider
||requester||duration) , (6)
where serviceID is the index of the service record, requester
is the specific requester of the service, and duration is the
estimated duration of the service.
Step 7: The user vehicle evaluates the quality of the service,
and the MEC server dynamically prices the service based on the
evaluation. After obtaining the execution results from vehicle vj ,
user vehicle vi evaluates its quality of service using a subjective
logic framework. Specifically, the user vehicle uses three trust
variables (i.e. the belief, distrust, and uncertainty of vi to vj)
to evaluate the quality of service. Then, the user vehicle sends
the evaluation results to the roadside MEC server to complete
the entire offloading process of the task. To avoid malicious
evaluations, user vehicles need to provide the corresponding
basis while uploading evaluations. The edge server verifies data
such as computing results, trajectory consistency, and connec-
tion stability against suspicious evaluations in the evaluation
management. After confirming the evaluations are reasonable,
the MEC server updates the corresponding service capacity
record of provider vj and uploads the data when the next block
is generated so that the computing service is dynamically priced
by the smart contract on the chain. In addition, the edge server
maintains the reputation of user vehicles within its service area.
If users frequently submit malicious evaluations, their reputation
value will be reduced, resulting in a lower weight of their
evaluations.
C. Security Analysis
1) Service Information Spoofing of Malicious Vehicles: In
cooperative computation offloading, malicious service vehicles
may provide false service information to trick user vehicles
into offloading data to them and thus obtain the privacy of user
vehicles. In the proposed blockchain-based sharing architecture,
the MEC server prevents access of unauthorized service vehicles
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
LANG et al.: COOPERATIVE COMPUTATION OFFLOADING IN BLOCKCHAIN-BASED VEHICULAR EDGE COMPUTING NETWORKS 789
by verifying the certificates. If the service vehicle does not
provide effective service and violates privacy, the user vehicle
can give a minimal service rating and thus prevent the ser-
vice vehicle from being selected as an offloading destination
by other user vehicles [46]. Meanwhile, the immutability and
traceability of the service information in the blockchain-based
system ensure the accurate identification of malicious service
vehicles [26].
2) Malicious Evaluation of User Vehicles: In the proposed
sharing scheme of service vehicle information, the evaluation
of the service quality by user vehicles affects the pricing of
the service, so user vehicles have an incentive to give ma-
licious evaluations intentionally. To avoid malicious evalua-
tions, user vehicles need to provide the corresponding evi-
dence while uploading evaluations. The MEC server verifies
data such as computing results, trajectory consistency, and
connection stability for suspicious evaluations, and updates
the service quality after confirming that the evaluations are
reasonable. In addition, the MEC servers can maintain the
reputation of user vehicles within their service area, and if
users frequently submit malicious evaluations, their reputation
value will be reduced, resulting in a lower weight of their
evaluations.
3) Fake Block Generation and Majority Attack of MEC
Servers: In the proposed data sharing scheme, the roadside MEC
servers are responsible for generating blocks and sharing them
within the region. If a malicious MEC server generates a fake
block, the PBFT-based consensus mechanism can identify the
error in the block and avoid adding it to the blockchain in case the
number of malicious servers does not exceed one-third. Mean-
while, the proposed shared architecture can prevent the majority
attack or 51% attack because mining-based consensus is not
used [47]. In addition, the cyclic selection of block generators
avoids the manipulation of the blockchain system by nodes with
high computational power.
4) Data Tampering of MEC Servers: The proposed sharing
scheme of service vehicle information uses blockchain to share
data among different MEC servers. Each block on the blockchain
contains a hash digest of the previous block, so blockchain nodes
can only read existing blocks or add new blocks, and cannot
modify the contents of blocks on the chain, which ensures data
immutability and prevents data tampering [46]–[48].
IV. COOPERATIVE COMPUTATION OFFLOADING USING
GAME THEORY
Based on the trusted sharing scheme designed in the previous
section, user vehicles can obtain information about the surround-
ing service vehicles. In this way, each user vehicle can choose to
offload its tasks to the roadside MEC server or the surrounding
service vehicles for execution. To ensure efficient computation
offloading of user vehicles, the main problem in this paper
is how to achieve the distributed optimal offloading decision
in the blockchain-based vehicular edge computing network.
Therefore, we propose a game-based cooperative computation
offloading decision method and prove the existence of equilib-
rium in this section.
A. Cooperative Computation Offloading Model
As mentioned in the last section, when user vehicle vi matches
with a nearby server vehicle according to the trajectory of the
server vehicle from the received shared data, it must decide
whether to execute its task on the MEC server or the server
vehicle based on the utility and overhead of the service, such
as the price, task execution latency, and quality of service. To
better characterize the utility and cost of cooperative compu-
tation offloading, we present specific models of application,
communication, and computation. Based on these models, we
propose a game model for cooperative computation offloading
and design a payoff function for user vehicles.
In cooperative computation offloading, the user vehicle sends
the code, input data, and deadline of the task to the MEC
server or server vehicle. Therefore, the application model of
the user vehicle vi that requires computation offloading can be
expressed as a triple (Li, αi, ti,max), where Li is the input data
size of the application to be offloaded, αi is the computational
complexity, and ti,max is the maximum tolerable execution time.
The computational complexity refers to the required central pro-
cessing unit (CPU) cycles to handle 1-bit data in the application,
which is related to the code of that task. ti,max is the maximum
execution time of the offloaded computation that is useful for
user vehicle vi. If the task is completed within ti,max, vi attains
the expected utility; conversely, it is penalized accordingly. A
quantitative expression of the expected utility is provided in
the next subsection. In practical systems, the values of these
parameters vary with different tasks. For example, in the task of
point cloud based object detection, Li is the input data size of
LiDAR point clouds per frame,αi is the complexity of the object
detection algorithm (i.e., the number of CPU cycles required to
process each bit of data), and ti,max is the processing interval of
the adjacent frames.
For simplicity and without loss of generality, we consider
that the communication model for computation offloading is a
block flat Rayleigh fading channel with path loss exponent θ and
fading coefficient hi of user vehicle vi. For all user vehicles, the
length of the block is greater than ti,max. Therefore, the uplink
and downlink data rates between vi and the MEC server can be
expressed as
RU
i,E = Wi log2
(
1 +
Pid
−θ
i,E |hi|2
N0
)
, (7)
RD
i,E = Wi log2
(
1 +
PEd
−θ
i,E |hi|2
N0
)
, (8)
where Wi and di,E are the bandwidth and distance between
the user vehicle and MEC server, respectively, N0 is the white
Gaussian noise power, andPi andPE are the transmission power
of the user vehicle and MEC server, respectively. It is worth
noting that the noise power N0 is dependent of the bandwidth,
but since the bandwidth of V2V and vehicle-to-infrastructure
(V2I) communication is fixed (10 MHz in China), we determine
the noise power here with a fixed bandwidth [34], [49]. It is
worth noting that we consider V2V and V2I communication
implemented with LTE-V2X [43], [44], which achieves data
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
790 IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 7, NO. 3, SEPTEMBER 2022
transmission through the multiple access approach of orthogonal
frequency-division multiplexing (OFDM). Referring to [11],
[34], [50], we use the same bandwidth and channel gain to evalu-
ate the computation offloading delay, which also fits the practical
application of LTE-V2X (fixed bandwidth for V2I and V2V
communication). In addition, the offloading decision method
proposed in this paper evaluates the utility of computation
offloading based on the relative delay, which is also applicable
to the environment with different bandwidths and channel gains
in the uplink and downlink. Similar to [11] and [34], in the
downlink transmission we consider roadside units transmitting
data with fixed power, which is also consistent with the practi-
cal application of LTE-V2X communication. Meanwhile, since
the power allocation does not affect the game-based decision
methodology, the offloading decision method proposed in this
paper is also applicable to the transmission environment with
dynamic power.
Similarly, the data transmission rates of the offloading request
and returned result between the user vehicle vi and server vehicle
vj can be expressed as
Rreq
i,V = Wi log2
(
1 +
Pid
−θ
i,V |hi|2
N0
)
, (9)
Rres
i,V = Wi log2
(
1 +
Pjd
−θ
i,V |hi|2
N0
)
, (10)
where di,V is the distance between vi and vj , andPj is the trans-
mission power of the server vehicle. As mentioned earlier, the
bandwidth and channel gain of the links for offloading requests
and returned results in V2V communication are also the same,
and the decision method proposed in this paper is applicable
to communication environments with different bandwidths and
channel gains.
In the computation model, we use the CPU frequency to
represent the computational capability of the server vehicle and
MEC server. Combining this with the computational complexity
and the data size of the task being offloaded, we can obtain the
expected time for the task to execute at the node and evaluate
the utility of computation offloading with this latency. Therefore,
the processing time of the task on the MEC server is
τi,E =
αiLi
fE
, (11)
where fE is the CPU frequency of the MEC server. Similarly,
with the CPU frequency fj of server vehicle vj , the execution
time on vj can be expressed as
τi,V =
αiLi
fj
. (12)
In this way, the total latency of computation offloading on the
MEC server and server vehicle sides can be expressed as
ti,E = tUi,E + τi,E + tDi,E
=
βU
i Li
Wi log2
(
1 +
Pid
−θ
i,E |hi|2
N0
) +
αiLi
fE
+
βD
i Li
Wi log2
(
1 +
PEd
−θ
i,E |hi|2
N0
) , (13)
ti,V = treqi,V + τi,V + tresi,V
=
βreq
i Li
Wi log2
(
1 +
Pid
−θ
i,V |hi|2
N0
) +
αiLi
fj
+
βres
i Li
Wi log2
(
1 +
Pjd
−θ
i,V |hi|2
N0
) , (14)
where βU
i and βreq
i are the uplink-cost in vehicle-to-MEC
(V2M) offloading and request-cost in V2V offloading, respec-
tively, βD
i is the joint factor for the downlink-cost and the
output-input data ratio on in V2M offloading, and βres
i is the
joint factor for result return-cost and the output-input data ratio
in V2V offloading.
Based on these offloading latencies, the user vehicle can
quantify the utility of both V2M and V2V offloading, and decide
whether to migrate the task to the MEC server or server vehicle.
Next, we use the latencies to construct a game of cooperative
computation offloading to guide the decision of user vehicles.
B. Cooperative Computation Offloading Game
We obtain the latencies incurred by offloading tasks from
the user vehicle to different destinations with the application,
communication, and computation models of cooperative compu-
tation offloading. Combining these latencies with the maximum
execution time of the tasks, the utility of offloading computation
to different destinations can be evaluated. In this section, we
establish the interaction of user vehicles using game theory in
cooperative computation offloading, and derive the utility and
overhead of offloading to construct a distributed solution with
the goal of optimizing the latencies of all user vehicles.
The game model of cooperative computation offloading can
be expressed as G = {N , (pi)i∈N , (ui)i∈N } [5], where N =
{1, 2, . . . , N} denotes the set of all user vehicles in the coverage
area of MEC servers, and pi ∈ [0, 1] is the mixed offloading
strategy of user vehicle vi that combines the two pure strategies
of V2M and V2V offloading. If pi is close to 1, vi migrates
the task to the MEC server with a high probability. ui is the
payoff that vi can obtain from this game with the payoff function
ui(p). The payoff function consists of both the utility and the
cost of computation offloading, thus evaluating the benefit and
overhead of strategy pi in cooperative computation offloading.
In this game model, we derive a specific payoff function based
on the latency of computation offloading and the competition of
multiple user vehicles for the MEC server.
First, we use the latency of task execution to characterize
the utility of the user vehicle in cooperative computation of-
floading. To unify the wide range of fluctuations in latency,
we design a value function to map the task execution time to
a fixed value interval. Intuitively, the lower the latency of the
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
LANG et al.: COOPERATIVE COMPUTATION OFFLOADING IN BLOCKCHAIN-BASED VEHICULAR EDGE COMPUTING NETWORKS 791
Fig. 4. Value function for different value factors.
task execution, the higher the utility to the user vehicle, but
in practice, the user vehicle can benefit from the successful
execution of the task as long as the latency of the task does not
exceed its maximum tolerable execution time. Moreover, the
blind pursuit of minimizing the execution latency can also make
user vehicles compete fiercely for edge server resources, leading
to overtime of some tasks with the long waiting time. Therefore,
considering the reciprocity among user vehicles, we construct
this value function in the form of a quadratic function and use a
parameter to dynamically adjust the value versus latency curve.
The specific value function can be expressed as
ri(ti) = 2ti,max (ti + δti,max)− (ti + δti,max)
2 , (15)
where ti ∈ {ti,E , ti,V } is the total latency of V2M offloading
in (13) or V2V offloading in (14), and δ ∈ [0, 1] is defined as
the value factor to regulate the latency of the maximum value
(i.e., the distance between the latency of the apex of the curve
and ti,max). As illustrated in Fig. 4, when δ is large, the task
reaches its maximum value at a lower latency, and, conversely,
the maximum value corresponds to a longer task execution time.
If the task takes longer than ti,max to execute, the vehicle will
not obtain any value from computation offloading.
With the value function, we can use the latencies to express the
expected utility of different computation offloading strategies as
Ui(p) = pi
ri(ti,E)
ri,max
+ (1− pi)
qjri(ti,V )
ri,max
, (16)
where ri,max = ri((1− δ)ti,max) is the maximum value of the
task, and qj is the quality of service of vj evaluated by other
user vehicles. The expected utility is composed of the utility
resulting from V2M and V2V offloading together. The utility of
each computation offloading is expressed as the ratio of the value
corresponding to its execution latency to the maximum value,
and the quality of service is also considered in the utility of V2V
offloading. If the quality of service of the corresponding server
vehicle is low, the utility obtained from computation offloading
will be reduced.
Due to the limited MEC servers resources, multiple user ve-
hicles in V2M computation offloading will compete for limited
resources. Thus, the expected cost of cooperative computation
offloading can be computed by considering the competition for
V2M offloading and the price of V2V offloading, which can be
expressed as
Ci(p) = p2i
⎡
⎣1−∏
k �=i
(1− λkpk)
⎤
⎦+ (1− pi)ρj , (17)
where λk denotes the average arrival rate of task in user vehicle
vk, and ρj =
pricej
priceE
denotes the ratio of the price of V2V
offloading to that of V2M offloading. In (17), as the number
of user vehicles and the price increase, the cost of computation
offloading also increases; thus, vehicles must consider both
utility and overhead to make better decisions.
Finally, by integrating (16) and (17), the payoff function for
cooperative computation offloading is given by
ui(p) = Ui(p)− Ci(p)
= pi
ri(ti,E)
ri,max
+ (1− pi)
qjri(ti,V )
ri,max
− p2i
⎡
⎣1−∏
k �=i
(1− λkpk)
⎤
⎦+ (1− pi)ρj . (18)
In this way, user vehicles can fully account for the effects of
latency, competition, and price in the cooperative computation
offloading game and adjust their computation offloading prob-
abilities (i.e., mixed strategies) to obtain a higher payoff. We
consider the current strategy to be a Nash equilibrium p∗ if no
user vehicle can achieve more payoff by changing its current
strategy, that is, for all pi
ui(p
∗
i ,p
∗
−i) ≥ ui(pi,p
∗
−i), (19)
wherep−i = (p1, . . ., pi−1, pi+1, . . ., pN ) is the vector of mixed
strategies of all user vehicles except vehicle vi [51].
Next, we construct a distributed solution for user vehicles
based on the cooperative computation offloading game and
guarantee the uniqueness of the converged Nash equilibrium
from the strategies of all user vehicles.
C. Distributed Computation Offloading Solution
With blockchain-based data sharing of resource-rich vehi-
cles, we propose a cooperative offloading game to describe
the influence of the capacity of MEC servers and server ve-
hicles on the computation offloading decision of user vehicle
vi. Following [52], there is definitely a Nash equilibrium of
mixed strategies in the cooperative computation offloading game
proposed in this paper; thus, we must construct an efficient
algorithm to guarantee the convergence of the Nash equilibrium
from the strategies of user vehicles. For the static game proposed
in this paper, we use the best-response mechanism to perform the
offloading decision of user vehicles and construct a distributed
cooperative computation offloading algorithm for them. To en-
sure the convergence and uniqueness of the user vehicle strate-
gies, we also prove that this distributed computation offloading
algorithm allows the strategy of each vehicle to converge to the
unique Nash equilibrium. Since the user vehicles in the proposed
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
792 IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 7, NO. 3, SEPTEMBER 2022
Algorithm 1: Distributed Cooperative Computation Of-
floading Algorithm For User Vehicles.
1: Initialization
2: Initialize the offloading requirements (L,α, ti,max) of
tasks of all user vehicles.
3: Initialize the vector p, ρ, and λ of all user vehicles.
4: for all i ∈ {1, . . ., N} do
5: Parse the information of server vehicles.
6: if no server vehicles are around vi then
7: vi takes the roadside MEC as the offloading
destination and sends its task.
8: else
9: if the number of server vehicles > 1 then
10: Select the server vehicle vj that is closest to its
trajectory.
11: end if
12: Estimate the data transmission rate with the
roadside MEC server and server vehicle vj based
on (7)–(10).
13: Estimate the latencies when the task is offloaded to
the MEC server and vj with (13) and (14),
respectively.
14: Generate a random number randi ∈ [0, 1] and
obtain the offloading probability pi with the
best-response updated in (20).
15: if randi > pi then
16: vi offloads its task to server vehicle vj for
execution.
17: Upload the service evaluation to the MEC server
after the offloading task is completed.
18: else
19: vi offloads its task to the roadside MEC for
execution.
20: end if
21: end if
22: end for
game cannot obtain the strategies of other vehicles in real time,
we express the best response of user vehicle vi based on the
previous strategies of other vehicles as
pi = argmax
pi
ui(p)
=
⎡
⎣ri (ti,E) /ri,max − qjri (ti,V ) /ri,max + ρj
2
(
1−∏k �=i (1− λkpk)
)
⎤
⎦
1
0
, (20)
where the operator [·]10 limits the result to [0,1]. Based on
this best-response mechanism in the cooperative computation
offloading game, we can construct the distributed cooperative
computation offloading solution as given in Algorithm 1.
In Algorithm 1, each user vehicle vi makes the computation
offloading decision in parallel, so its computational complexity
is mainly reflected in parsing and screening the information of
server vehicles. If each user vehicle can obtain information ofM
server vehicles, the computational complexity of data parsing for
vi isO(M). In addition, for each user vehicle, the computational
complexity of both latency estimation and strategy update is
O(1). Thus, for each task, the computational complexity of
Algorithm 1 is O(M). Considering that each user vehicle needs
to perform K independent tasks, the total complexity of its
computation offloading is O(KM).
In this way, within the framework of game theory, user vehicle
vi determines the utility and cost that can be obtained from its
mixed strategy and then calculates the payoff function of the
game. Based on this payoff function, vi adopts the strategy pi
using the best-response method to obtain the maximum payoff.
It can be proved using the contraction mapping theorem [53] that
pi uniquely converges to the Nash equilibrium p∗i under certain
conditions.
Theorem 1: Starting from any initial strategy, the best-
response mechanism in the distributed cooperative computation
offloading algorithm converges to the unique equilibrium p∗i if
∀i ∈ {1, . . ., N},∣∣∣∣ri(ti,E)ri,max
− qjri(ti,V )
ri,max
+ ρj
∣∣∣∣
<
2
[
1−∏k′ �=i (1− λk′pk′)
]2
∑
k �=i λk
∏
l �=i,k(1− λlpl)
. (21)
Proof: Following [14], [54], the convergence and uniqueness
of the Nash equilibrium in best-response updating can be guaran-
teed by proving that (20) is a contraction mapping. In addition,
according to the contraction mapping theorem [53], we only
need to prove that a certain norm (here, we use ‖ · ‖∞) of the
Jacobian matrix of (20) is less than 1.
Therefore, we first derive the norm of best-response updating.
The Jacobian matrix J of best-response updating in (20) is
defined as
Ji,k =
∂psi
∂ps−1
k
, (22)
where ps−1
k denotes the strategy adopted in the previous stage
for each user vehicle except vi. Therefore, the Jacobian matrix
can be derived as
Ji,k =
⎧⎪⎪⎨
⎪⎪⎩
0, i = k
−λk (ri,E − ri,V + ρj)
∏
l �=i,k(1− λlpl)
2
[
1−∏k′ �=i (1− λ′
kp
′
k)
]2 , i �= k ,
(23)
where ri,E =
ri(ti,E)
ri,max
and ri,V =
qjri(ti,V )
ri,max
are defined to sim-
plify the expression of Ji,k. Therefore,
‖J ‖∞ = max
i∈N
∑
k �=i |ri,E − ri,V + ρj |λk
∏
l �=i,k(1− λlpl)
2
[
1−∏k′ �=i (1− λk′pk′)
]2 .
(24)
According to the contraction mapping theorem, if
‖J ‖∞ < 1, then the strategy updating in (20) can converge
to the unique Nash equilibrium. Therefore, if ∀i ∈
N ,
∑
k �=i |ri,E − ri,V + ρj |λk
∏
l �=i,k(1− λlpl)
2[1−∏k′ �=i(1− λk′pk′)]2
< 1, that
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
LANG et al.: COOPERATIVE COMPUTATION OFFLOADING IN BLOCKCHAIN-BASED VEHICULAR EDGE COMPUTING NETWORKS 793
is, | ri(ti,E)
ri,max
− qjri(ti,V )
ri,max
+ ρj | <
2[1−∏k′ �=i(1− λk′pk′)]2∑
k �=i λk
∏
l �=i,k(1− λlpl)
,
then the best-response strategy in the distributed cooperative
computation offloading algorithm can converge to the unique
Nash equilibrium. �
The distributed computation offloading method thus achieves
strategy equilibrium to help user vehicles make better offloading
decisions. In this way, user vehicle vi obtains a computation
offloading strategy p∗i that can achieve Nash equilibrium in
most cases. Based on p∗i , vi can decide whether to transfer
the onboard application task to the roadside MEC server or
neighboring server vehicles to improve the execution efficiency
of the application.
V. NUMERICAL RESULTS AND DISCUSSION
In this section, we present a series of experiments run in
MATLAB to evaluate the performance of the method proposed
in this paper. Specifically, we demonstrate the convergence of
Algorithm 1 and estimate the effect of different parameters on
the offloading strategy and expected time (latency) consumed
to complete the task of user vehicles. In addition, we compare
the expected latency and payoff of cooperative computation
offloading in different offloading schemes and demonstrate the
performance of the proposed offloading method.
For simplicity and without loss of generality, we assume that
all user vehicles do not have sufficient local resources to execute
their tasks and need to offload these tasks to MEC servers or
resource-rich vehicles for execution. These tasks share the same
application model (L,α, tmax) and other parameters for user
vehicle vi, such as Li = L, αi = α, ti,max = tmax, Pi = PE =
Pj = P , λi = λ, and ρj = ρ. Furthermore, we assume that each
user vehicle in the scenario is near a resource-rich vehicle that
can provide computing services to meet the requirements of
cooperative computation offloading. The main parameters in the
experiments are listed in Table I.
The convergence of the offloading probability (i.e., strat-
egy) for six user vehicles is presented in Fig. 5. We can
see that the strategies of the user vehicles quickly con-
verge to a stable value, which demonstrates the convergence
and uniqueness of the Nash equilibrium under the condition
of Theorem 1, that is, ∀i ∈ N , | ri(ti,E)
ri,max
− qjri(ti,V )
ri,max
+ ρj | <
2[1−∏k′ �=i(1− λk′pk′)]2∑
k �=i λk
∏
l �=i,k(1− λlpl)
. In addition, due to the different
channel environments and communication distances around
each user vehicle, each strategy converge to a different equi-
librium.
Fig. 6 displays the variation of the average probability of
cooperative computation offloading with the number of vehicles
for all user vehicles. Initially, as the number of user vehicles
grows, the offloading probabilities decrease sharply. Once the
number of vehicles is greater than 20, the average offloading
probabilities saturate and remain low; that is, user vehicles prefer
to offload tasks to neighboring server vehicles rather than to the
MEC server. This is because overloaded user vehicles intensify
the competition for the MEC server resources between user
TABLE I
EXPERIMENTAL PARAMETERS [7], [14], [34], [55]
Fig. 5. Convergence of computation offloading probability for user vehicles.
vehicles, and vehicles find it difficult to achieve higher utility
from V2M offloading; therefore, they turn to V2V offloading
without competition for resources. In addition, different task
arrival rates λ have no effect on the saturation value of the
average offloading probability for the same price ratios. This is
because an increased number of user vehicles saturates the MEC
server utilization, and a lower λ only slows down the process of
resource saturation without affecting the saturation strategy.
Figs. 7 and 8 display the variation in the average offloading
probability and the expected latency of 10 user vehicles with
the value factor δ. As expressed in (15) and Fig. 4, δ can
adjust the mapping of the latency to the maximum value. If
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
794 IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 7, NO. 3, SEPTEMBER 2022
Fig. 6. Comparison of the average probability of cooperative computation
offloading for different λ and ρ.
Fig. 7. Average offloading probability versus value factor δ for different λ
and ρ.
Fig. 8. Expected latency versus value factor δ for different λ and ρ.
Fig. 9. Offloading probability versus quality of service qj of the server vehicle
for different λ and ρ.
Fig. 10. Expected latency versus quality of service qj of the server vehicle for
different λ and ρ.
δ is large, the user vehicle is more inclined to minimize its own
latency to improve utility. In Fig. 7, as δ alters the value curve,
the average offloading probability gradually increases, thereby
reducing the task execution time through V2M offloading. As
demonstrated in Fig. 8, the increase in offloading probability
leads to a decreasing trend in the expected latency, and each
user vehicle can thus achieve higher utility in the game.
Figs. 9 and 10 depict the change in the offloading proba-
bility and expected latency of a single user vehicle with the
quality of service qj of its server vehicle while the quality
of service of other vehicles remains constant. In Fig. 9, the
offloading probability of the user vehicle gradually decreases as
qj increases, indicating its preference to perform tasks through
V2V offloading. The change in offloading probability is more
significant at a lower price ratio ρ, which indicates that low
ρ values are more sensitive to changes in qj because the user
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
LANG et al.: COOPERATIVE COMPUTATION OFFLOADING IN BLOCKCHAIN-BASED VEHICULAR EDGE COMPUTING NETWORKS 795
Fig. 11. Influence of ratio of di,E to di,V on offloading probability for
different λ and ρ.
Fig. 12. Influence of ratio of di,E to di,V on expected latency for different λ
and ρ.
vehicle can achieve higher utility in this case. Similarly, a
reduced offloading probability causes a slight increase in the
expected latency in Fig. 10, and the increase is more significant
at lower ρ values. This is because the increase in latency is
accompanied by a decrease in computation offloading overhead,
and the user vehicle can balance its payoff by sacrificing some
of its latency to reduce its V2M offloading cost as long as the
task is completed on time.
Figs. 11 and 12 display the variation in the offloading proba-
bility and expected latency of a single user vehicle with a ratio of
di,E to di,V while the communication distance of other vehicles
remains constant. In this experiment, we set the distance di,V
between user vehicle vi and server vehicle vj to 10 m and adjust
the distance di,E between vi and the MEC server to change the
ratio of di,E to di,V . As illustrated in Fig. 11, an increase in the
distance of V2M offloading prolongs the transmission time of the
application data and thus reduces the offloading probability of
Fig. 13. Comparison of different solutions in terms of expected latency.
Fig. 14. Comparison of different solutions in terms of expected payoff.
the user vehicle. As the increase in distance leads to a decrease
in the quality of V2M communication, the expected delay in
Fig. 12 gradually increases. In addition, as the distance of V2M
communication increases, the user vehicle is more willing to
execute tasks via V2V offloading, which reverses the effect of λ
and ρ on the expected latency.
Fig. 13 depicts the expected latency of user vehicles for dif-
ferent numbers of vehicles using different offloading solutions.
In this experiment, the completion deadline tmax is set to 1 s. We
can observe that the expected delay of the proposed method is
stable below the completion deadline and is significantly lower
than that of other offloading schemes. It can be seen that the
expected latency of the proposed game method is the same as the
result of the global optimization solved with global information
for large numbers of vehicles. However, due to changes in path
loss and channel fading caused by different communication
distances, the expected latency of the three non-game solutions
is difficult to maintain at a stable level. Therefore, the proposed
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
796 IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 7, NO. 3, SEPTEMBER 2022
game method can promote efficient computation offloading and
ensure the real-time execution of tasks.
The expected payoffs of different offloading solutions are
compared in Fig. 14. We can see that the game method proposed
in this paper achieves almost the same maximum payoff as the
global optimization method, whereas the other solutions fail to
maintain the obtained payoff at a high level. This is because
the proposed method efficiently obtains the server vehicle in-
formation using blockchain-based data sharing and evaluates
the competition of multiple vehicles for MEC server resources
using a distributed approach. In Fig. 14, the proposed distributed
algorithm achieves an equilibrium close to the global optimum,
demonstrating its performance advantage.
VI. CONCLUSION
In this paper, we proposed a data sharing architecture between
user vehicles and service providers for cooperative computa-
tion offloading in blockchain-based vehicular MEC networks.
A consensus mechanism used in blockchain, which combines
Proof of Service and PBFT, is designed in this architecture to
improve the security and efficiency of data sharing. Furthermore,
we proposed a game of cooperative computation offloading
and constructed a method to obtain offloading strategy equi-
librium using the best-response mechanism. The performance
evaluation reveals the advantage of the proposed method in
terms of latency. Using the computation offloading strategy, a
user vehicle can determine whether to transfer its task to the
roadside MEC server or a nearby server vehicle. The proposed
method can thus help increase the security and efficiency of
cooperative computation offloading in blockchain-based vehic-
ular edge computing networks. In future work, we will also
investigate cooperative computation offloading problem in pres-
ence of multiple MEC servers and server vehicles in a region
to provide a more accurate decision method in vehicular MEC
networks.
REFERENCES
[1] S. Santini, A. Salvi, A. S. Valente, A. Pescapé, M. Segata, and
R. L. Cigno, “Platooning maneuvers in vehicular networks: A distributed
and consensus-based approach,” IEEE Trans. Intell. Veh., vol. 4, no. 1,
pp. 59–72, Mar. 2019.
[2] J. A. Guerrero-Ibanez, S. Zeadally, and J. Contreras-Castillo, “Integration
challenges of intelligent transportation systems with connected vehicle,
cloud computing, and Internet of Things technologies,” IEEE Wireless
Commun., vol. 22, no. 6, pp. 122–128, Dec. 2015.
[3] S. A. Fayazi and A. Vahidi, “Mixed-integer linear programming for optimal
scheduling of autonomous vehicle intersection crossing,” IEEE Trans.
Intell. Veh., vol. 3, no. 3, pp. 287–299, Sep. 2018.
[4] L. Cheng et al., “SCTSC: A semicentralized traffic signal control mode
with attribute-based blockchain in IOVs,” IEEE Trans. Comput. Social
Syst., vol. 6, no. 6, pp. 1373–1385, Dec. 2019.
[5] H. Zhang, B. Xin, L.-H. Dou, J. Chen, and K. Hirota, “A review
of cooperative path planning of an unmanned aerial vehicle group,”
Front. Inf. Technol. Electron. Eng., vol. 21, no. 12, pp. 1671–1694,
2020.
[6] C. Lin, D. Tian, X. Duan, and J. Zhou, “3D environmental perception
modeling in the simulated autonomous-driving systems,” Complex Syst.
Model. Simul., vol. 1, no. 1, pp. 45–54, 2021.
[7] J. Wang, D. Feng, S. Zhang, J. Tang, and T. Q. Quek, “Computation
offloading for mobile edge computing enabled vehicular networks,” IEEE
Access, vol. 7, pp. 62624–62632, 2019.
[8] T. Taleb, K. Samdanis, B. Mada, H. Flinck, S. Dutta, and D. Sabella,
“On multi-access edge computing: A survey of the emerging 5G network
edge cloud architecture and orchestration,” IEEE Commun. Surveys Tuts.,
vol. 19, no. 3, pp. 1657–1681, Jul.–Sep. 2017.
[9] W. Yang et al., “Edgekeeper: A trusted edge computing framework for
ubiquitous power Internet of Things,” Front. Inf. Technol. Electron. Eng.,
vol. 22, no. 3, pp. 374–399, 2021.
[10] P.-Q. Huang, Y. Wang, and K.-Z. Wang, “Energy-efficient trajectory plan-
ning for a multi-UAV-assisted mobile edge computing system,” Front. Inf.
Technol. Electron. Eng., vol. 21, no. 12, pp. 1713–1725, 2020.
[11] S. Wang, J. Li, G. Wu, H. Chen, and S. Sun, “Joint optimization of
task offloading and resource allocation based on differential privacy in
vehicular edge computing,” IEEE Trans. Comput. Social Syst., vol. 9, no. 1,
pp. 109–119, Feb. 2022.
[12] H. Yu, C. Chang, S. Li, and L. Li, “CD-DB: A data storage model
for cooperative driving,” IEEE Trans. Intell. Veh., to be published,
doi: 10.1109/TIV.2022.3150509.
[13] S. S. Shinde, A. Bozorgchenani, D. Tarchi, and Q. Ni, “On the design
of federated learning in latency and energy constrained computation
offloading operations in vehicular edge computing systems,” IEEE Trans.
Veh. Technol., vol. 71, no. 2, pp. 2041–2057, Feb. 2022.
[14] Y. Wang et al., “A game-based computation offloading method in vehicular
multiaccess edge computing networks,” IEEE Internet Things J., vol. 7,
no. 6, pp. 4987–4996, Jun. 2020.
[15] 3GPP, “Study on network controlled interactive service (NCIS) in the 5G
system (5GS),” 3rd Gener. Partnership Project (3GPP), Tech. Rep. (TR)
22.842, Dec. 2019.
[16] 3GPP, “Service requirements for the 5G system,” 3rd Generation Partner-
ship Project (3GPP), Tech. Specification (TS) 22.261, Jul. 2020.
[17] 5GAA, “Toward fully connected vehicles: Edge computing for advanced
automotive communications,” 5G Automotive Association (5GAA), White
Paper, Dec. 2017. [Online]. Available: https://5gaa.org/news/toward-
fully-connected-vehicles-edge-computing-for-advanced-automotive-
communications/
[18] R. Chattopadhyay and C.-K. Tham, “Joint sensing and processing resource
allocation in vehicular Ad-Hoc networks,” IEEE Trans. Intell. Veh., to be
published, doi: 10.1109/TIV.2021.3124208.
[19] J. Xu, L. Chen, K. Liu, and C. Shen, “Designing security-aware incen-
tives for computation offloading via device-to-device communication,”
IEEE Trans. Wireless Commun., vol. 17, no. 9, pp. 6053–6066, Sep.
2018.
[20] M. Hasan, S. Mohan, T. Shimizu, and H. Lu, “Securing vehicle-to-
everything (v2x) communication platforms,” IEEE Trans. Intell. Veh.,
vol. 5, no. 4, pp. 693–713, Dec. 2020.
[21] T. Aste, P. Tasca, and T. Di Matteo, “Blockchain technologies: The
foreseeable impact on society and industry,” Computer, vol. 50, no. 9,
pp. 18–28, 2017.
[22] R. A. Memon, J. P. Li, J. Ahmed, M. I. Nazeer, M. Ismail, and K. Ali,
“Cloud-based vs. blockchain-based IoT: A comparative survey and way
forward,” Front. Inf. Technol. Electron. Eng., vol. 21, no. 4, pp. 563–586,
2020.
[23] X. Huang, D. Ye, R. Yu, and L. Shu, “Securing parked vehicle assisted fog
computing with blockchain and optimal smart contract design,” IEEE/CAA
J. Automatica Sinica, vol. 7, no. 2, pp. 426–441, Mar. 2020.
[24] R. Yang, F. R. Yu, P. Si, Z. Yang, and Y. Zhang, “Integrated blockchain and
edge computing systems: A survey, some research issues and challenges,”
IEEE Commun. Surveys Tuts., vol. 21, no. 2, pp. 1508–1532, Apr.–Jun.
2019.
[25] D. Xu, W. Shi, W. Zhai, and Z. Tian, “Multi-candidate voting model based
on blockchain,” IEEE/CAA J. Automatica Sinica, vol. 8, no. 12, pp. 1891–
1900, Dec. 2021.
[26] J. Kang et al., “Blockchain for secure and efficient data sharing in vehicular
edge computing and networks,” IEEE Internet Things J., vol. 6, no. 3,
pp. 4660–4670, Jun. 2019.
[27] X. Xu, Q. Liu, X. Zhang, J. Zhang, L. Qi, and W. Dou, “A blockchain-
powered crowdsourcing method with privacy preservation in mobile envi-
ronment,” IEEE Trans. Comput. Social Syst., vol. 6, no. 6, pp. 1407–1419,
Dec. 2019.
[28] S. K. Dwivedi, R. Amin, and S. Vollala, “Blockchain-based secured IPFS-
enable event storage technique with authentication protocol in VANET,”
IEEE/CAA J. Automatica Sinica, vol. 8, no. 12, pp. 1913–1922, Dec.
2021.
[29] P. K. Sharma, M.-Y. Chen, and J. H. Park, “A software defined fog node
based distributed blockchain cloud architecture for IoT,” IEEE Access,
vol. 6, pp. 115–124, 2017.
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
https://dx.doi.org/10.1109/TIV.2022.3150509
https://5gaa.org/news/toward-fully-connected-vehicles-edge-computing-for-advanced-automotive-communications/
https://5gaa.org/news/toward-fully-connected-vehicles-edge-computing-for-advanced-automotive-communications/
https://5gaa.org/news/toward-fully-connected-vehicles-edge-computing-for-advanced-automotive-communications/
https://dx.doi.org/10.1109/TIV.2021.3124208
LANG et al.: COOPERATIVE COMPUTATION OFFLOADING IN BLOCKCHAIN-BASED VEHICULAR EDGE COMPUTING NETWORKS 797
[30] M. Castro and B. Liskov, “Practical Byzantine fault tolerance and proactive
recovery,” ACM Trans. Comput. Syst., vol. 20, no. 4, pp. 398–461, 2002.
[31] J. Zhao, Q. Li, Y. Gong, and K. Zhang, “Computation offloading and
resource allocation for cloud assisted mobile edge computing in vehicular
networks,” IEEE Trans. Veh. Technol., vol. 68, no. 8, pp. 7944–7956,
Aug. 2019.
[32] H. Ke, J. Wang, L. Deng, Y. Ge, and H. Wang, “Deep reinforcement
learning-based adaptive computation offloading for MEC in heteroge-
neous vehicular networks,” IEEE Trans. Veh. Technol., vol. 69, no. 7,
pp. 7916–7929, Jul. 2020.
[33] Y. Dai, D. Xu, S. Maharjan, and Y. Zhang, “Joint load balancing and
offloading in vehicular edge computing and networks,” IEEE Internet
Things J., vol. 6, no. 3, pp. 4377–4387, Jun. 2019.
[34] Y. Sun et al., “Adaptive learning-based task offloading for vehicular
edge computing systems,” IEEE Trans. Veh. Technol., vol. 68, no. 4,
pp. 3061–3074, Apr. 2019.
[35] R. Yadav, W. Zhang, O. Kaiwartya, H. Song, and S. Yu, “Energy-latency
tradeoff for dynamic computation offloading in vehicular fog comput-
ing,” IEEE Trans. Veh. Technol., vol. 69, no. 12, pp. 14198–14211,
Dec. 2020.
[36] D. Zhang, F. R. Yu, and R. Yang, “Blockchain-based distributed software-
defined vehicular networks: A dueling deep Q-learning approach,”
IEEE Trans. Cogn. Commun. Netw., vol. 5, no. 4, pp. 1086–1100,
Dec. 2019.
[37] Y. Fu, F. R. Yu, C. Li, T. H. Luan, and Y. Zhang, “Vehicular blockchain-
based collective learning for connected and autonomous vehicles,” IEEE
Wireless Commun., vol. 27, no. 2, pp. 197–203, Apr. 2020.
[38] C. Li, Y. Fu, F. R. Yu, T. H. Luan, and Y. Zhang, “Vehicle position
correction: A vehicular blockchain networks-based GPS error sharing
framework,” IEEE Trans. Intell. Transp. Syst., vol. 22, no. 2, pp. 898–912,
Feb. 2021.
[39] F. Guo, F. R. Yu, H. Zhang, H. Ji, M. Liu, and V. C. Leung, “Adaptive
resource allocation in future wireless networks with blockchain and mobile
edge computing,” IEEE Trans. Wireless Commun., vol. 19, no. 3, pp. 1689–
1703, Mar. 2020.
[40] X. Qiu, L. Liu, W. Chen, Z. Hong, and Z. Zheng, “Online deep rein-
forcement learning for computation offloading in blockchain-empowered
mobile edge computing,” IEEE Trans. Veh. Technol., vol. 68, no. 8,
pp. 8050–8062, Aug. 2019.
[41] J. Feng, F. R. Yu, Q. Pei, X. Chu, J. Du, and L. Zhu, “Cooperative
computation offloading and resource allocation for blockchain-enabled
mobile-edge computing: A deep reinforcement learning approach,” IEEE
Internet Things J., vol. 7, no. 7, pp. 6214–6228, Jul. 2020.
[42] X. Zheng, M. Li, Y. Chen, J. Guo, M. Alam, and W. Hu, “Blockchain-based
secure computation offloading in vehicular networks,” IEEE Trans. Intell.
Transp. Syst., vol. 22, no. 7, pp. 4073–4087, Jul. 2021.
[43] S. Chen, J. Hu, Y. Shi, and L. Zhao, “LTE-V: A TD-LTE-based V2X
solution for future vehicular network,” IEEE Internet Things J., vol. 3,
no. 6, pp. 997–1005, Dec. 2016.
[44] S. Chen, J. Hu, Y. Shi, L. Zhao, and W. Li, “A vision of C-V2X: Tech-
nologies, field testing, and challenges with chinese development,” IEEE
Internet Things J., vol. 7, no. 5, pp. 3872–3881, May 2020.
[45] S. Dustdar, P. Fernández, J. M. García, and A. Ruiz-Cortés, “Elastic smart
contracts in blockchains,” IEEE/CAA J. Automatica Sinica, vol. 8, no. 12,
pp. 1901–1912, Dec. 2021.
[46] Z. Yang, K. Yang, L. Lei, K. Zheng, and V. C. Leung, “Blockchain-based
decentralized trust management in vehicular networks,” IEEE Internet
Things J., vol. 6, no. 2, pp. 1495–1505, Apr. 2019.
[47] W. Li, M. Nejad, and R. Zhang, “A blockchain-based architecture for traffic
signal control systems,” in Proc. IEEE Int. Congress Internet Things, 2019,
pp. 33–40.
[48] Z. Li, J. Kang, R. Yu, D. Ye, Q. Deng, and Y. Zhang, “Consor-
tium blockchain for secure energy trading in industrial Internet of
Things,” IEEE Trans. Ind. Informat., vol. 14, no. 8, pp. 3690–3700,
Aug. 2018.
[49] A. Bansal, N. Agrawal, and K. Singh, “Rate-splitting multiple ac-
cess for UAV-based RIS-enabled interference-limited vehicular com-
munication system,” IEEE Trans. Intell. Veh., to be published,
doi: 10.1109/TIV.2022.3168159.
[50] Y. Wang, M. Sheng, X. Wang, L. Wang, and J. Li, “Mobile-edge comput-
ing: Partial computation offloading using dynamic voltage scaling,” IEEE
Trans. Commun., vol. 64, no. 10, pp. 4268–4282, Oct. 2016.
[51] S. Tadelis, “Game theory : An introduction,” Econ. Books, vol. 1, 2012.
[52] D. Fudenberg and J. Tirole, Game Theory. Cambridge, MA,USA: MIT
Press, 1991.
[53] R. Abraham, J. E. Marsden, and T. S. Ratiu, Manifolds, Tensor Analysis,
and Applications. Berlin, Germany: Springer, 1988.
[54] J.-W. Lee, A. Tang, J. Huang, M. Chiang, and A. R. Calderbank, “Reverse-
engineering MAC: A non-cooperative game model,” IEEE J. Sel. Areas
Commun., vol. 25, no. 6, pp. 1135–1147, Aug. 2007.
[55] O. Munoz, A. Pascual-Iserte, and J. Vidal, “Optimization of radio and
computational resources for energy efficiency in latency-constrained
application offloading,” IEEE Trans. Veh. Technol., vol. 64, no. 10,
pp. 4738–4755, Oct. 2015.
Ping Lang received the B.Eng. and M.Sc. degrees in
computer science from Jilin University, Changchun,
China, in 2016 and 2019, respectively. He is currently
working toward the Ph.D. degree with the School
of Transportation Science and Engineering, Beihang
University, Beijing, China.
His research interests include vehicular networks,
edge computing, and intelligent transportation sys-
tems.
Daxin Tian (Senior Member, IEEE) received the
B.S., M.S., and Ph.D. degrees in computer science
from Jilin University, Changchun, China, in 2002,
2005, and 2007, respectively.
He is currently a Professor with the School of
Transportation Science and Engineering, Beihang
University, Beijing, China. His research interests in-
clude mobile computing, intelligent transportation
systems, vehicular ad hoc networks, and swarm in-
telligent. He is an IEEE Intelligent Transportation
Systems Society Member and an IEEE Vehicular
Technology Society Member.
Xuting Duan received the Ph.D. degree in traffic
information engineering and control from Beihang
University, Beijing, China.
He is currently an Assistant Professor with the
School of Transportation Science and Engineering,
Beihang University. His research interests include
vehicular ad hoc networks, cooperative vehicle in-
frastructure system, and Internet of Vehicles.
Jianshan Zhou received the B.Sc., M.Sc., and Ph.D.
degrees in traffic information engineering and control
from Beihang University, Beijing, China, in 2013,
2016, and 2020, respectively.
From 2017 to 2018, he was a Visiting Research Fel-
low with the School of Informatics and Engineering,
University of Sussex, Brighton, U.K. He has authored
or coauthored more than 20 international scientific
publications. His research interests include the mod-
eling and optimization of vehicular communication
networks and air–ground cooperative networks, the
analysis and control of connected autonomous vehicles, and intelligent trans-
portation systems. He is currently a Postdoctoral Research Fellow supported
by the Zhuoyue Program of Beihang University and the National Postdoctoral
Program for Innovative Talents, and is or was the Technical Program Session
Chair with the IEEE EDGE 2020, the TPC member with the IEEE VTC2021-Fall
track, the session organizer with ICAUS 2022, and IEEE ICUS 2022, and the
Youth Editorial Board Member of the Unmanned Systems Technology.
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
https://dx.doi.org/10.1109/TIV.2022.3168159
798 IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. 7, NO. 3, SEPTEMBER 2022
Zhengguo Sheng (Senior Member, IEEE) received
the B.Sc. degree from the University of Electronic
Science and Technology of China, Chengdu, China, in
2006, and the M.S. and Ph.D. degrees from Imperial
College London, London, U.K., in 2007 and 2011,
respectively.
He is currently a Reader with the University of Sus-
sex, Brighton, U.K. He was with UBC, Vancouver,
BC, Canada, as a Research Associate and with Orange
Labs as a Senior Researcher. He has authored or
coauthored more than 120 publications. His research
interests include IoT, vehicular communications, and cloud/edge computing.
Victor C. M. Leung (Life Fellow, IEEE) is a Dis-
tinguished Professor of computer science and soft-
ware engineering with Shenzhen University, Shen-
zhen, China. He is also an Emeritus Professor of
electrical and computer engineering and Director of
the Laboratory for Wireless Networks and Mobile
Systems with the University of British Columbia
(UBC), Vancouver, BC, Canada. His research focuses
on wireless networks and mobile systems, and he has
published widely in these areas.
Dr. Leung is serving on the editorial boards of the
IEEE TRANSACTIONS ON GREEN COMMUNICATIONS AND NETWORKING, IEEE
TRANSACTIONS ON CLOUD COMPUTING, IEEE TRANSACTIONS ON COMPUTA-
TIONAL SOCIAL SYSTEMS, IEEE ACCESS, IEEE NETWORK, and several other
journals. He was the recipient of the 1977 APEBC Gold Medal, 1977–1981
NSERC Postgraduate Scholarships, IEEE Vancouver Section Centennial Award,
2011 UBC Killam Research Prize, 2017 Canadian Award for Telecommuni-
cations Research, 2018 IEEE TCGCC Distinguished Technical Achievement
Recognition Award, and 2018 ACM MSWiM Reginald Fessenden Award. He
coauthored papers that won the 2017 IEEE ComSoc Fred W. Ellersick Prize,
2017 IEEE Systems Journal Best Paper Award, 2018 IEEE CSIM Best Journal
Paper Award, and 2019 IEEE TCGCC Best Journal Paper Award. He is a
Life Fellow of IEEE, and a Fellow of the Royal Society of Canada (Academy
of Science), Canadian Academy of Engineering, and Engineering Institute of
Canada. He is named in the current Clarivate Analytics list of Highly Cited
Researchers.
Authorized licensed use limited to: CITY UNIV OF HONG KONG. Downloaded on April 15,2023 at 09:06:40 UTC from IEEE Xplore.  Restrictions apply. 
<<
  /ASCII85EncodePages false
  /AllowTransparency false
  /AutoPositionEPSFiles true
  /AutoRotatePages /None
  /Binding /Left
  /CalGrayProfile (Gray Gamma 2.2)
  /CalRGBProfile (sRGB IEC61966-2.1)
  /CalCMYKProfile (U.S. Web Coated \050SWOP\051 v2)
  /sRGBProfile (sRGB IEC61966-2.1)
  /CannotEmbedFontPolicy /Warning
  /CompatibilityLevel 1.4
  /CompressObjects /Off
  /CompressPages true
  /ConvertImagesToIndexed true
  /PassThroughJPEGImages true
  /CreateJobTicket false
  /DefaultRenderingIntent /Default
  /DetectBlends true
  /DetectCurves 0.0000
  /ColorConversionStrategy /sRGB
  /DoThumbnails true
  /EmbedAllFonts true
  /EmbedOpenType false
  /ParseICCProfilesInComments true
  /EmbedJobOptions true
  /DSCReportingLevel 0
  /EmitDSCWarnings false
  /EndPage -1
  /ImageMemory 1048576
  /LockDistillerParams true
  /MaxSubsetPct 100
  /Optimize true
  /OPM 0
  /ParseDSCComments false
  /ParseDSCCommentsForDocInfo true
  /PreserveCopyPage true
  /PreserveDICMYKValues true
  /PreserveEPSInfo false
  /PreserveFlatness true
  /PreserveHalftoneInfo true
  /PreserveOPIComments false
  /PreserveOverprintSettings true
  /StartPage 1
  /SubsetFonts true
  /TransferFunctionInfo /Remove
  /UCRandBGInfo /Preserve
  /UsePrologue false
  /ColorSettingsFile ()
  /AlwaysEmbed [ true
    /Algerian
    /Arial-Black
    /Arial-BlackItalic
    /Arial-BoldItalicMT
    /Arial-BoldMT
    /Arial-ItalicMT
    /ArialMT
    /ArialNarrow
    /ArialNarrow-Bold
    /ArialNarrow-BoldItalic
    /ArialNarrow-Italic
    /ArialUnicodeMS
    /BaskOldFace
    /Batang
    /Bauhaus93
    /BellMT
    /BellMTBold
    /BellMTItalic
    /BerlinSansFB-Bold
    /BerlinSansFBDemi-Bold
    /BerlinSansFB-Reg
    /BernardMT-Condensed
    /BodoniMTPosterCompressed
    /BookAntiqua
    /BookAntiqua-Bold
    /BookAntiqua-BoldItalic
    /BookAntiqua-Italic
    /BookmanOldStyle
    /BookmanOldStyle-Bold
    /BookmanOldStyle-BoldItalic
    /BookmanOldStyle-Italic
    /BookshelfSymbolSeven
    /BritannicBold
    /Broadway
    /BrushScriptMT
    /CalifornianFB-Bold
    /CalifornianFB-Italic
    /CalifornianFB-Reg
    /Centaur
    /Century
    /CenturyGothic
    /CenturyGothic-Bold
    /CenturyGothic-BoldItalic
    /CenturyGothic-Italic
    /CenturySchoolbook
    /CenturySchoolbook-Bold
    /CenturySchoolbook-BoldItalic
    /CenturySchoolbook-Italic
    /Chiller-Regular
    /ColonnaMT
    /ComicSansMS
    /ComicSansMS-Bold
    /CooperBlack
    /CourierNewPS-BoldItalicMT
    /CourierNewPS-BoldMT
    /CourierNewPS-ItalicMT
    /CourierNewPSMT
    /EstrangeloEdessa
    /FootlightMTLight
    /FreestyleScript-Regular
    /Garamond
    /Garamond-Bold
    /Garamond-Italic
    /Georgia
    /Georgia-Bold
    /Georgia-BoldItalic
    /Georgia-Italic
    /Haettenschweiler
    /HarlowSolid
    /Harrington
    /HighTowerText-Italic
    /HighTowerText-Reg
    /Impact
    /InformalRoman-Regular
    /Jokerman-Regular
    /JuiceITC-Regular
    /KristenITC-Regular
    /KuenstlerScript-Black
    /KuenstlerScript-Medium
    /KuenstlerScript-TwoBold
    /KunstlerScript
    /LatinWide
    /LetterGothicMT
    /LetterGothicMT-Bold
    /LetterGothicMT-BoldOblique
    /LetterGothicMT-Oblique
    /LucidaBright
    /LucidaBright-Demi
    /LucidaBright-DemiItalic
    /LucidaBright-Italic
    /LucidaCalligraphy-Italic
    /LucidaConsole
    /LucidaFax
    /LucidaFax-Demi
    /LucidaFax-DemiItalic
    /LucidaFax-Italic
    /LucidaHandwriting-Italic
    /LucidaSansUnicode
    /Magneto-Bold
    /MaturaMTScriptCapitals
    /MediciScriptLTStd
    /MicrosoftSansSerif
    /Mistral
    /Modern-Regular
    /MonotypeCorsiva
    /MS-Mincho
    /MSReferenceSansSerif
    /MSReferenceSpecialty
    /NiagaraEngraved-Reg
    /NiagaraSolid-Reg
    /NuptialScript
    /OldEnglishTextMT
    /Onyx
    /PalatinoLinotype-Bold
    /PalatinoLinotype-BoldItalic
    /PalatinoLinotype-Italic
    /PalatinoLinotype-Roman
    /Parchment-Regular
    /Playbill
    /PMingLiU
    /PoorRichard-Regular
    /Ravie
    /ShowcardGothic-Reg
    /SimSun
    /SnapITC-Regular
    /Stencil
    /SymbolMT
    /Tahoma
    /Tahoma-Bold
    /TempusSansITC
    /TimesNewRomanMT-ExtraBold
    /TimesNewRomanMTStd
    /TimesNewRomanMTStd-Bold
    /TimesNewRomanMTStd-BoldCond
    /TimesNewRomanMTStd-BoldIt
    /TimesNewRomanMTStd-Cond
    /TimesNewRomanMTStd-CondIt
    /TimesNewRomanMTStd-Italic
    /TimesNewRomanPS-BoldItalicMT
    /TimesNewRomanPS-BoldMT
    /TimesNewRomanPS-ItalicMT
    /TimesNewRomanPSMT
    /Times-Roman
    /Trebuchet-BoldItalic
    /TrebuchetMS
    /TrebuchetMS-Bold
    /TrebuchetMS-Italic
    /Verdana
    /Verdana-Bold
    /Verdana-BoldItalic
    /Verdana-Italic
    /VinerHandITC
    /Vivaldii
    /VladimirScript
    /Webdings
    /Wingdings2
    /Wingdings3
    /Wingdings-Regular
    /ZapfChanceryStd-Demi
    /ZWAdobeF
  ]
  /NeverEmbed [ true
  ]
  /AntiAliasColorImages false
  /CropColorImages true
  /ColorImageMinResolution 150
  /ColorImageMinResolutionPolicy /OK
  /DownsampleColorImages false
  /ColorImageDownsampleType /Bicubic
  /ColorImageResolution 900
  /ColorImageDepth -1
  /ColorImageMinDownsampleDepth 1
  /ColorImageDownsampleThreshold 1.00111
  /EncodeColorImages true
  /ColorImageFilter /DCTEncode
  /AutoFilterColorImages true
  /ColorImageAutoFilterStrategy /JPEG
  /ColorACSImageDict <<
    /QFactor 0.76
    /HSamples [2 1 1 2] /VSamples [2 1 1 2]
  >>
  /ColorImageDict <<
    /QFactor 0.40
    /HSamples [1 1 1 1] /VSamples [1 1 1 1]
  >>
  /JPEG2000ColorACSImageDict <<
    /TileWidth 256
    /TileHeight 256
    /Quality 15
  >>
  /JPEG2000ColorImageDict <<
    /TileWidth 256
    /TileHeight 256
    /Quality 15
  >>
  /AntiAliasGrayImages false
  /CropGrayImages true
  /GrayImageMinResolution 150
  /GrayImageMinResolutionPolicy /OK
  /DownsampleGrayImages false
  /GrayImageDownsampleType /Bicubic
  /GrayImageResolution 1200
  /GrayImageDepth -1
  /GrayImageMinDownsampleDepth 2
  /GrayImageDownsampleThreshold 1.00083
  /EncodeGrayImages true
  /GrayImageFilter /DCTEncode
  /AutoFilterGrayImages true
  /GrayImageAutoFilterStrategy /JPEG
  /GrayACSImageDict <<
    /QFactor 0.76
    /HSamples [2 1 1 2] /VSamples [2 1 1 2]
  >>
  /GrayImageDict <<
    /QFactor 0.40
    /HSamples [1 1 1 1] /VSamples [1 1 1 1]
  >>
  /JPEG2000GrayACSImageDict <<
    /TileWidth 256
    /TileHeight 256
    /Quality 15
  >>
  /JPEG2000GrayImageDict <<
    /TileWidth 256
    /TileHeight 256
    /Quality 15
  >>
  /AntiAliasMonoImages false
  /CropMonoImages true
  /MonoImageMinResolution 1200
  /MonoImageMinResolutionPolicy /OK
  /DownsampleMonoImages false
  /MonoImageDownsampleType /Bicubic
  /MonoImageResolution 1600
  /MonoImageDepth -1
  /MonoImageDownsampleThreshold 1.00063
  /EncodeMonoImages true
  /MonoImageFilter /CCITTFaxEncode
  /MonoImageDict <<
    /K -1
  >>
  /AllowPSXObjects false
  /CheckCompliance [
    /None
  ]
  /PDFX1aCheck false
  /PDFX3Check false
  /PDFXCompliantPDFOnly false
  /PDFXNoTrimBoxError true
  /PDFXTrimBoxToMediaBoxOffset [
    0.00000
    0.00000
    0.00000
    0.00000
  ]
  /PDFXSetBleedBoxToMediaBox true
  /PDFXBleedBoxToTrimBoxOffset [
    0.00000
    0.00000
    0.00000
    0.00000
  ]
  /PDFXOutputIntentProfile (None)
  /PDFXOutputConditionIdentifier ()
  /PDFXOutputCondition ()
  /PDFXRegistryName ()
  /PDFXTrapped /False
  /CreateJDFFile false
  /Description <<
    /CHS <FEFF4f7f75288fd94e9b8bbe5b9a521b5efa7684002000410064006f006200650020005000440046002065876863900275284e8e55464e1a65876863768467e5770b548c62535370300260a853ef4ee54f7f75280020004100630072006f0062006100740020548c002000410064006f00620065002000520065006100640065007200200035002e003000204ee553ca66f49ad87248672c676562535f00521b5efa768400200050004400460020658768633002>
    /CHT <FEFF4f7f752890194e9b8a2d7f6e5efa7acb7684002000410064006f006200650020005000440046002065874ef69069752865bc666e901a554652d965874ef6768467e5770b548c52175370300260a853ef4ee54f7f75280020004100630072006f0062006100740020548c002000410064006f00620065002000520065006100640065007200200035002e003000204ee553ca66f49ad87248672c4f86958b555f5df25efa7acb76840020005000440046002065874ef63002>
    /DAN <FEFF004200720075006700200069006e0064007300740069006c006c0069006e006700650072006e0065002000740069006c0020006100740020006f007000720065007400740065002000410064006f006200650020005000440046002d0064006f006b0075006d0065006e007400650072002c0020006400650072002000650067006e006500720020007300690067002000740069006c00200064006500740061006c006a006500720065007400200073006b00e60072006d007600690073006e0069006e00670020006f00670020007500640073006b007200690076006e0069006e006700200061006600200066006f0072007200650074006e0069006e006700730064006f006b0075006d0065006e007400650072002e0020004400650020006f007000720065007400740065006400650020005000440046002d0064006f006b0075006d0065006e0074006500720020006b0061006e002000e50062006e00650073002000690020004100630072006f00620061007400200065006c006c006500720020004100630072006f006200610074002000520065006100640065007200200035002e00300020006f00670020006e0079006500720065002e>
    /DEU <FEFF00560065007200770065006e00640065006e0020005300690065002000640069006500730065002000450069006e007300740065006c006c0075006e00670065006e0020007a0075006d002000450072007300740065006c006c0065006e00200076006f006e002000410064006f006200650020005000440046002d0044006f006b0075006d0065006e00740065006e002c00200075006d002000650069006e00650020007a0075007600650072006c00e40073007300690067006500200041006e007a006500690067006500200075006e00640020004100750073006700610062006500200076006f006e00200047006500730063006800e40066007400730064006f006b0075006d0065006e00740065006e0020007a0075002000650072007a00690065006c0065006e002e00200044006900650020005000440046002d0044006f006b0075006d0065006e007400650020006b00f6006e006e0065006e0020006d006900740020004100630072006f00620061007400200075006e0064002000520065006100640065007200200035002e003000200075006e00640020006800f600680065007200200067006500f600660066006e00650074002000770065007200640065006e002e>
    /ESP <FEFF005500740069006c0069006300650020006500730074006100200063006f006e0066006900670075007200610063006900f3006e0020007000610072006100200063007200650061007200200064006f00630075006d0065006e0074006f0073002000640065002000410064006f00620065002000500044004600200061006400650063007500610064006f007300200070006100720061002000760069007300750061006c0069007a00610063006900f3006e0020006500200069006d0070007200650073006900f3006e00200064006500200063006f006e006600690061006e007a006100200064006500200064006f00630075006d0065006e0074006f007300200063006f006d00650072006300690061006c00650073002e002000530065002000700075006500640065006e00200061006200720069007200200064006f00630075006d0065006e0074006f00730020005000440046002000630072006500610064006f007300200063006f006e0020004100630072006f006200610074002c002000410064006f00620065002000520065006100640065007200200035002e003000200079002000760065007200730069006f006e0065007300200070006f00730074006500720069006f007200650073002e>
    /FRA <FEFF005500740069006c006900730065007a00200063006500730020006f007000740069006f006e00730020006100660069006e00200064006500200063007200e900650072002000640065007300200064006f00630075006d0065006e00740073002000410064006f006200650020005000440046002000700072006f00660065007300730069006f006e006e0065006c007300200066006900610062006c0065007300200070006f007500720020006c0061002000760069007300750061006c00690073006100740069006f006e0020006500740020006c00270069006d007000720065007300730069006f006e002e0020004c0065007300200064006f00630075006d0065006e00740073002000500044004600200063007200e900e90073002000700065007500760065006e0074002000ea0074007200650020006f007500760065007200740073002000640061006e00730020004100630072006f006200610074002c002000610069006e00730069002000710075002700410064006f00620065002000520065006100640065007200200035002e0030002000650074002000760065007200730069006f006e007300200075006c007400e90072006900650075007200650073002e>
    /ITA (Utilizzare queste impostazioni per creare documenti Adobe PDF adatti per visualizzare e stampare documenti aziendali in modo affidabile. I documenti PDF creati possono essere aperti con Acrobat e Adobe Reader 5.0 e versioni successive.)
    /JPN <FEFF30d330b830cd30b9658766f8306e8868793a304a3088307353705237306b90693057305f002000410064006f0062006500200050004400460020658766f8306e4f5c6210306b4f7f75283057307e305930023053306e8a2d5b9a30674f5c62103055308c305f0020005000440046002030d530a130a430eb306f3001004100630072006f0062006100740020304a30883073002000410064006f00620065002000520065006100640065007200200035002e003000204ee5964d3067958b304f30533068304c3067304d307e305930023053306e8a2d5b9a3067306f30d530a930f330c8306e57cb30818fbc307f3092884c3044307e30593002>
    /KOR <FEFFc7740020c124c815c7440020c0acc6a9d558c5ec0020be44c988b2c8c2a40020bb38c11cb97c0020c548c815c801c73cb85c0020bcf4ace00020c778c1c4d558b2940020b3700020ac00c7a50020c801d569d55c002000410064006f0062006500200050004400460020bb38c11cb97c0020c791c131d569b2c8b2e4002e0020c774b807ac8c0020c791c131b41c00200050004400460020bb38c11cb2940020004100630072006f0062006100740020bc0f002000410064006f00620065002000520065006100640065007200200035002e00300020c774c0c1c5d0c11c0020c5f40020c2180020c788c2b5b2c8b2e4002e>
    /NLD (Gebruik deze instellingen om Adobe PDF-documenten te maken waarmee zakelijke documenten betrouwbaar kunnen worden weergegeven en afgedrukt. De gemaakte PDF-documenten kunnen worden geopend met Acrobat en Adobe Reader 5.0 en hoger.)
    /NOR <FEFF004200720075006b00200064006900730073006500200069006e006e007300740069006c006c0069006e00670065006e0065002000740069006c002000e50020006f0070007000720065007400740065002000410064006f006200650020005000440046002d0064006f006b0075006d0065006e00740065007200200073006f006d002000650072002000650067006e0065007400200066006f00720020007000e5006c006900740065006c006900670020007600690073006e0069006e00670020006f00670020007500740073006b007200690066007400200061007600200066006f0072007200650074006e0069006e006700730064006f006b0075006d0065006e007400650072002e0020005000440046002d0064006f006b0075006d0065006e00740065006e00650020006b0061006e002000e50070006e00650073002000690020004100630072006f00620061007400200065006c006c00650072002000410064006f00620065002000520065006100640065007200200035002e003000200065006c006c00650072002e>
    /PTB <FEFF005500740069006c0069007a006500200065007300730061007300200063006f006e00660069006700750072006100e700f50065007300200064006500200066006f0072006d00610020006100200063007200690061007200200064006f00630075006d0065006e0074006f0073002000410064006f00620065002000500044004600200061006400650071007500610064006f00730020007000610072006100200061002000760069007300750061006c0069007a006100e700e3006f002000650020006100200069006d0070007200650073007300e3006f00200063006f006e0066006900e1007600650069007300200064006500200064006f00630075006d0065006e0074006f007300200063006f006d0065007200630069006100690073002e0020004f007300200064006f00630075006d0065006e0074006f00730020005000440046002000630072006900610064006f007300200070006f00640065006d0020007300650072002000610062006500720074006f007300200063006f006d0020006f0020004100630072006f006200610074002000650020006f002000410064006f00620065002000520065006100640065007200200035002e0030002000650020007600650072007300f50065007300200070006f00730074006500720069006f007200650073002e>
    /SUO <FEFF004b00e40079007400e40020006e00e40069007400e4002000610073006500740075006b007300690061002c0020006b0075006e0020006c0075006f0074002000410064006f0062006500200050004400460020002d0064006f006b0075006d0065006e007400740065006a0061002c0020006a006f0074006b006100200073006f0070006900760061007400200079007200690074007900730061007300690061006b00690072006a006f006a0065006e0020006c0075006f00740065007400740061007600610061006e0020006e00e400790074007400e4006d0069007300650065006e0020006a0061002000740075006c006f007300740061006d0069007300650065006e002e0020004c0075006f0064007500740020005000440046002d0064006f006b0075006d0065006e00740069007400200076006f0069006400610061006e0020006100760061007400610020004100630072006f0062006100740069006c006c00610020006a0061002000410064006f00620065002000520065006100640065007200200035002e0030003a006c006c00610020006a006100200075007500640065006d006d0069006c006c0061002e>
    /SVE <FEFF0041006e007600e4006e00640020006400650020006800e4007200200069006e0073007400e4006c006c006e0069006e006700610072006e00610020006f006d002000640075002000760069006c006c00200073006b006100700061002000410064006f006200650020005000440046002d0064006f006b0075006d0065006e007400200073006f006d00200070006100730073006100720020006600f60072002000740069006c006c006600f60072006c00690074006c006900670020007600690073006e0069006e00670020006f006300680020007500740073006b007200690066007400650072002000610076002000610066006600e4007200730064006f006b0075006d0065006e0074002e002000200053006b006100700061006400650020005000440046002d0064006f006b0075006d0065006e00740020006b0061006e002000f600700070006e00610073002000690020004100630072006f0062006100740020006f00630068002000410064006f00620065002000520065006100640065007200200035002e00300020006f00630068002000730065006e006100720065002e>
    /ENU (Use these settings to create PDFs that match the "Suggested"  settings for PDF Specification 4.0)
  >>
>> setdistillerparams
<<
  /HWResolution [600 600]
  /PageSize [612.000 792.000]
>> setpagedevice