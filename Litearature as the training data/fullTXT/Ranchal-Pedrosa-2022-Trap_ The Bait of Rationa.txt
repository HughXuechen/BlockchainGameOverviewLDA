Trap: The Bait of Rational Players to Solve Byzantine Consensus
Trap: The Bait of Rational Players to Solve Byzantine Consensus
Alejandro Ranchal-Pedrosa
University of Sydney
Sydney, Australia
alejandro.ranchalpedrosa@sydney.edu.au
Vincent Gramoli
University of Sydney and EPFL
Sydney, Australia
vincent.gramoli@sydney.edu.au
ABSTRACT
It is impossible to solve the Byzantine consensus problem in an
open network of 𝑛 participants if only 2𝑛/3 or less of them are
correct. As blockchains need to solve consensus, one might think
that blockchains need more than 2𝑛/3 correct participants. But
it is yet unknown whether consensus can be solved when less
than 2𝑛/3 participants are correct and 𝑘 participants are rational
players, which misbehave if they can gain the loot. Trading correct
participants for rational players may not seem helpful to solve
consensus since rational players can misbehave whereas correct
participants, by definition, cannot.
In this paper, we show that consensus is actually solvable in this
model, even with less than 2𝑛/3 correct participants. The key idea is
a baiting strategy that lets rational players pretend to misbehave in
joining a coalition but rewards them to betray this coalition before
the loot gets stolen. We propose Trap, a protocol that builds upon
recent advances in the theory of accountability to solve consensus
as soon as 𝑛 > max
( 3
2𝑘 +3𝑡, 2(𝑘 +𝑡)
)
: by assuming that private keys
cannot be forged, this protocol is an equilibrium where no coalition
of 𝑘 rational players can coordinate to increase their expected utility
regardless of the arbitrary behavior of up to 𝑡 Byzantine players.
Finally, we show that a baiting strategy is necessary and suffi-
cient to solve this, so-called rational agreement problem. First, we
show that it is impossible to solve this rational agreement problem
without implementing a baiting strategy. Second, the existence of
Trap demonstrates the sufficiency of the baiting strategy. Our Trap
protocol finds applications in blockchains to prevent players from
disagreeing, that could otherwise lead to “double spending”.
CCS CONCEPTS
• Theory of computation→ Algorithmic game theory; • Se-
curity and privacy → Distributed systems security; • Com-
puting methodologies→ Distributed algorithms.
KEYWORDS
Blockchain, consensus, game theory, robustness, fault tolerance
ACM Reference Format:
Alejandro Ranchal-Pedrosa and Vincent Gramoli. 2022. Trap: The Bait of
Rational Players to Solve Byzantine Consensus. In Proceedings of the 2022
ACM Asia Conference on Computer and Communications Security (ASIA
CCS ’22), May 30-June 3, 2022, Nagasaki, Japan. ACM, New York, NY, USA,
14 pages. https://doi.org/10.1145/3488932.3517386
Publication rights licensed to ACM. ACM acknowledges that this contribution was
authored or co-authored by an employee, contractor or affiliate of a national govern-
ment. As such, the Government retains a nonexclusive, royalty-free right to publish or
reproduce this article, or to allow others to do so, for Government purposes only.
ASIACCS ’22, May 30–June 3, 2022, Nagasaki, Japan
© 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-9140-5/22/05. . . $15.00
https://doi.org/10.1145/3488932.3517386
1 INTRODUCTION AND BACKGROUND
Consider 𝑛 players, each with some initial value. Solving the Byzan-
tine consensus problem consists of designing a protocol guarantee-
ing that the 𝑛 − 𝑡 non-Byzantine players agree by outputting the
same value and despite the presence of up to 𝑡 arbitrarily behaving
Byzantine players. Standard cryptography, which permits oblivious
signed transfers and assumes computationally bounded players,
has recently been used to build undeniable proofs identifying the
players that led the system to a disagreement [12, 13]. Although this
construction has not been used in the game theoretical context, one
can intuitively see its application to implement a baiting strategy
that incentivizes rational players to solve blockchain consensus: the
idea is to reward rational players to pretend to join a coalition in
order to deceit the coalition by exposing undeniable proofs-of-fraud
(PoFs).
Placed in the game theory context, one can see a consensus pro-
tocol among rational players as a Nash equilibrium, however, a
Nash equilibrium only prevents one rational player from increasing
its utility by deviating solely, but it fails at preventing multiple
rational players from increasing their utility by colluding and by all
deviating together. The resilience against this type of coalition, men-
tioned originally in the 50s [8], is needed to solve consensus despite
a coalition of 𝑘 players. Ben-Porath [10] shows that one can simu-
late a Nash equilibrium with a central trusted mediator provided
that there is a punishment strategy to threaten rational players in
case they deviate and Heller [29] strengthens Ben-Porath’s result
to allow coalitions. Abraham et al. [2] applied these results to se-
cret sharing in the fully distributed setting, by showing that one
can simulate a mediator with cheap talks and assuming the same
standard cryptography we assume. A (𝑘, 𝑡)-punishment strategy
guarantees that if up to 𝑘 rational players deviate, then more than
𝑡 non-deviating players, by playing the punishment strategy, can
lower the utility of these rational players.
Another challenge when making consensus Byzantine fault tol-
erant is for the equilibrium to be immune to 𝑡 Byzantine players
that act arbitrarily or whose utility functions are unknown. Abra-
ham et al. [2] were the first to formalize 𝑘-resilience, 𝑡-immunity
and 𝜖-(𝑘, 𝑡)-robustness. A protocol is a 𝑘-resilient equilibrium if no
rational coalition of size up to 𝑘 can increase their utility by deviat-
ing in a coordinated way. A protocol is 𝑡-immune if the expected
utility of the 𝑛 − 𝑡 non-faulty players is not decreased regardless of
the arbitrary behavior of up to 𝑡 Byzantine players. A protocol is
𝜖-(𝑘, 𝑡)-robust if no coalition of 𝑘 rational players can coordinate
to increase their expected utility by 𝜖 regardless of the arbitrary
behavior of up to 𝑡 Byzantine players, even if the Byzantine players
join their coalition, where 𝜖 accounts for the (small) probability of
breaking the cryptography.
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
168
https://doi.org/10.1145/3488932.3517386
https://doi.org/10.1145/3488932.3517386
http://crossmark.crossref.org/dialog/?doi=10.1145%2F3488932.3517386&domain=pdf&date_stamp=2022-05-30
Considering rational players alongside the well-known Byzan-
tine faults to ensure the agreement property of the consensus prob-
lem allows us to evaluate protocols against coalitions of players
that are incentivized to deviate for their own benefit or to break
the system, rather than just because of their faulty nature. This
rational agreement problem finds application in blockchains where
participants can be modeled as players incentivized to gain valuable
cryptocurrency assets. In 2020, these assets incentivized players to
deviate from their blockchain protocol by forcing a disagreement
to fork the blockchain, leading to a double spending of US$70, 000
in Bitcoin Gold1 and US$5.6 million in Ethereum Classic2. Solving
rational agreement is key to avoid these losses because it ensures
that players agree on a unique block at each index of the chain, thus
preventing these forks from being exploited to double spend. Inter-
estingly, some blockchains already require participants to deposit
cryptocurrency assets in the form of staking and these deposits
could be used by the consensus protocol to incentivize their owners
to behave. Unfortunately, these blockchains fork in the presence
of rational players and we are not aware of any solution to this
rational agreement problem.
1.1 Our result
In this paper, we show that a baiting strategy, that incentivize ratio-
nal players to bait deviating players into a trap, is necessary and
sufficient to solve this rational agreement problem by offering a
consensus protocol that is robust to a coalition of up to 𝑘 rational
players and 𝑡 Byzantine players. Our first contribution is thus to
formalize the notion of a baiting strategy and show that this baiting
strategy is necessary to solve the rational agreement problem. Mo-
tivated by open networks, where blockchains typically operate, and
where the synchrony assumption [19] in unrealistic, we then solve
the rational agreement problem without assuming a known bound
on the delay of every message. As solving the consensus problem
is impossible with complete asynchrony [21], we consider the par-
tially synchronous model where there is an unknown bound on
the delay of messages [19]. This solution bypasses the well-known
requirement of 2𝑛/3 correct participants [32], by solving consensus
when 𝑛 > max( 32𝑘 + 3𝑡, 2(𝑘 + 𝑡)). For example if 𝑛 = 7 players,
then our solution solves consensus with only 4 correct participants,
hence tolerating 𝑘 = 1 rational player and 𝑡 = 2 Byzantine players.
We implement this solution in a new protocol, called Trap
(Tackling RationalAgreement through Persuasion), that is 𝜖-(𝑘, 𝑡)-
robust when 𝑛 > max( 32𝑘 + 3𝑡, 2(𝑘 + 𝑡)). Trap rewards a single
player to expose its coalition by generating proofs-of-fraud with
the Polygraph accountable consensus protocol [13]. Making ini-
tially colluding players decide on whether to betray the coalition
regardless of the coalition behavior is analogous to reducing the
extensive-form game into a normal-form game for this particular
decision. In addition, if the reward for exposing the coalition is
greater than the individual payoff for causing a disagreement, ratio-
nal players find that the coalition strategy is strictly dominated by
1https://news.bitcoin.com/bitcoin-gold-51-attacked-network-loses-70000-in-double-
spends/
2https://news.bitcoin.com/5-6-million-stolen-as-etc-team-finally-acknowledge-the-
51-attack-on-network/
the baiting strategy in the extensive-form game. This shows simi-
larities with the prisoner’s dilemma, in which all rational players
prefer to betray the coalition than to collude.
𝑡 𝑘 −𝑚 𝑚 𝐴 𝐵
𝐴 ∩ 𝐵 = ∅, partition of correctByzantines
𝑘 rationals,
of which𝑚 bait
➀ predec(𝑣𝐴) ➀ predec(𝑣𝐵 )
➀ 𝑡 + 𝑘 players lead𝐴
and 𝐵 to disagree
on predecisions
➁ ➁
➁ 𝐴 and 𝐵 cannot
terminate without
hearing from at least
1 of the𝑚 baiters ce
rti
fic
at
e (
𝑣 𝐴
)
cer
tifi
cat
e (𝑣 𝐵
)
➂
➂𝑚 baiters wait to
receive certificates
to construct
proofs-of-fraud
share PoFs from{𝑣𝐴 , 𝑣𝐵 }
share PoFs from
{𝑣𝐴 , 𝑣𝐵 }
➃ ➃
➃ partitions of correct players 𝐴 and 𝐵 (𝑖) discover disagreement,
(𝑖𝑖) select a winner of the reward at random out of the𝑚 baiters,
(𝑖𝑖𝑖) punish the rest of 𝑡 + 𝑘 − 1 deviants, and
(𝑖𝑣) resolve the disagreement on predecisions to agree on decision
Figure 1: Example execution of the Trap protocol. First,➀ all
𝑡 Byzantine and 𝑘 rational players collude to cause a dis-
agreement on the output of the accountable consensus pro-
tocol, resulting in 𝐴 and 𝐵 predeciding different outputs.
Then, ➁𝑚 of the 𝑘 rational players commit to bait while ex-
ecuting the BFTCR protocol, preventing𝐴 and 𝐵 from decid-
ing their disagreeing predecisions. As such, ➂ the𝑚 baiters
wait until they receive proof of the disagreement on predeci-
sions, to then ➃ prove the disagreement committing to and
revealing the proofs-of-fraud in the BFTCR protocol. Hence,
neither 𝐴 nor 𝐵 decide their conflicting predecisions, but in-
stead reward one of the𝑚 baiters, punish the rest of 𝑡 + 𝑘 − 1
players responsible for the disagreement on predecisions,
and resolve the disagreement, deciding one of 𝑣𝐴 or 𝑣𝐵 , or,
depending on the application, merging both.
More specifically, our protocol “pre-decides” the decisions from
Polygraph [13] that it extends with the Byzantine Fault Tolerant
Commit-Reveal protocol (BFTCR), which consists of two reliable
broadcasts and one additional broadcast. As we show in Figure 1,
by offering a reward the Trap protocol can convince𝑚 rational
players to betray the coalition after they helped cause a disagree-
ment on predecisions. First, the coalition exposes itself causing a
disagreement on predecisions. Second, the𝑚 rational players from
the coalition that decide to betray are enough to pause termina-
tion of the BFTCR protocol. Third, these players can wait to gather
enough PoFs of the disagreement on predecisions, which they will
get by the property of accountability (since they caused a disagree-
ment on the output of the Polygraph protocol). Fourth and finally,
once they get PoFs to prove the disagreement to correct players
and get the reward, these𝑚 players commit and reveal the PoFs by
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
169
https://news.bitcoin.com/bitcoin-gold-51-attacked-network-loses-70000-in-double-spends/
https://news.bitcoin.com/bitcoin-gold-51-attacked-network-loses-70000-in-double-spends/
https://news.bitcoin.com/5-6-million-stolen-as-etc-team-finally-acknowledge-the-51-attack-on-network/
https://news.bitcoin.com/5-6-million-stolen-as-etc-team-finally-acknowledge-the-51-attack-on-network/
sharing them during the BFTCR protocol, after which one of them
will be selected at random to get the reward. We detail further this
example in Appendix A.
Adding this BFTCR phase ensures the existence of a baiting strat-
egy (baiting-dominance) and that the protocol still solves agreement
even after playing the baiting strategy (baiting-agreement). We also
add an additional property, lossfree-reward, which states that the
increase in utility for baiting rational players comes at no cost to
non-deviating players. For this purpose, we introduce a deposit per
player, so that the system can always pay the reward by taking
the deposits of the proven coalition at no cost for non-deviating
players.
1.2 Related work
Considering fault tolerant distributed protocols as games requires to
cope with a mixture of up to 𝑘 rational players and 𝑡 faulty players.
The idea of mixing rational players with faulty players has already
been extensively explored in the context of secret sharing and multi-
party computation [2, 16, 22, 33]. In particular, the central third-
party mediator that is typically relied upon was implemented with
synchronous cheap talks [2], that are communications of negligible
cost through private pairwise channels. This extension was indeed
illustrated with an 𝜖-(𝑘, 𝑡)-robust secret sharing protocol where𝑛 >
𝑘 + 2𝑡 . It was later shown [1] that mediators could be implemented
with asynchronous cheap talks in an 𝜖-(𝑘, 𝑡)-robust protocol when
𝑛 > 3(𝑘 + 𝑡). This adaptation makes it impossible to devise even a
1-immune protocol that would solve the consensus problem [32]
as the communication model becomes asynchronous [21]. In this
paper, we focus instead on the partially synchronous model, where
the bound on the delay of messages is unknown [19], to design a
protocol that solves consensus among 𝑛 players, where up to 𝑡 are
Byzantine players and 𝑘 are rational players.
Consensus has been explored in the context of game theory.
Some works focused on the conditions under which termination
and validity is obtained for a non-negligible cost of communication
and/or local computation [7, 38], without considering the incentives
for rational players to cause a disagreement. This incentive is quite
apparent in the blockchain context, where Bitcoin users hacked
the network to double spend by simply leading sets of players to
a disagreement (or fork) for long enough3. Some results consider
the problem of consensus in the presence of rational players but do
not consider failures [24]. Leader election [3], which can be used to
solve consensus indirectly, and consensus proposals [26] focus on
ensuring fairness defined as all players having an equal probability
of their proposal being decided. Some proposals study consensus
and mix faulty players with rational players [5, 9], however, they
consider the synchronous communication model.
Several research results focus more particularly on agreement,
with some deriving from the BAR (Byzantine-Altruistic-Rational)
model. However, these works considered either no Byzantine play-
ers [20, 25], no coalitions of rational players [6], synchrony [25,
27, 28, 39] or solution preference [27]. By assuming a larger payoff
for agreeing than for disagreeing, solution preference requires that
rational players never have an incentive to sabotage agreement. To
3https://www.cnet.com/news/hacker-swipes-83000-from-bitcoin-mining-pools/.
the best of our knowledge, we present the first work that consid-
ers bounds for the robustness of agreement against coalitions of
Byzantine and rational players in partial synchrony.
The baiting strategy that we introduced to reward traitors of a
coalition is very similar to the betrayal used in the context of veri-
fiable cloud-computing for counter-collusion contracts, assuming
that the third party hosting the contracts is trusted [18]. Our BFTCR
protocol presents a novel implementation to select the winner of
the baiting reward without a trusted third party.
There are a number of advantages of BFTCR compared to other
state-of-the-art protocols. One may think that a solution similar to
submarine commitments [11] would work as well by, for example,
hiding the proofs-of-fraud in a decision. However, such a solution
does not prevent Byzantine players from always hiding in a subma-
rine commitment their proofs-of-fraud, and revealing them only if
a rational player reveals their submarine commitment, which can
act as a deterrent for rational players to not betray the coalition.
Additionally, other protocols based on zero-knowledge proofs [31]
explicitly reveal the existence of an information to prove, which
gives an additional advantage to other players in the coalition to
also claim the same knowledge.
State-of-the-art verifiable secret-sharing (VSS) schemes [4, 17,
30, 37] are not a good fit either, since there are no secret-sharing
schemes in partial synchrony that tolerate coalitions of size greater
than a third of the participants. To the best of our knowledge,
BFTCR is the first protocol that implements baiting strategies for
consensus tolerating coalitions of up to 𝑘 rational and 𝑡 Byzantine
players as long as 𝑛 > max
(
3
2𝑘 + 3𝑡, 2(𝑘 + 𝑡)
)
.
1.3 Roadmap
The rest of the paper is structured as follows: Section 2 presents
our model and preliminary definitions, Section 3 introduces the
definition of a baiting strategy and shows that it is impossible to
solve the rational agreement problem without a baiting strategy, in
Section 4 we present the Trap protocol and its correctness, and we
finally conclude in Section 5.
2 PRELIMINARIES
We consider a partially synchronous communication network, in
which messages can be delayed by up to a bound that is unknown.
For this purpose, we adapt the synchronous and asynchronous
models of Abraham et al. [1, 2] to partial synchrony. We consider
a game played by a set 𝑁 of |𝑁 | = 𝑛 players, each of type in
T = {Byzantine, rational, correct}. The game is in extensive form,
described by a game tree whose leaves are labeled by the utilities
𝑢𝑖 of each player 𝑖 . We introduce the scheduler as an additional
player that will model the delay on messages derived from partial
synchrony. We assume that players alternate making moves with
the scheduler : first the scheduler moves, then a player moves, then
the scheduler moves and so on. The scheduler’s move consists of
choosing a player 𝑖 to move next and a set of messages in transit
to 𝑖 that will be delivered just before 𝑖 moves (so that 𝑖’s move
can depend on all the messages 𝑖 delivers). Every non-leaf node is
associated with either a player or the scheduler. The scheduler is
bound to two constraints. First, the scheduler can choose to delay
any message msg up to a bound, known only to the scheduler,
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
170
https://www.cnet.com/news/hacker-swipes-83000-from-bitcoin-mining-pools/
before which he must have chosen all recipients of msg to move
and provided them with this message, so that they deliver it before
making a move. Second, the scheduler must eventually choose all
players that are still playing. That is, if player 𝑖 is playing at time 𝑒 ,
then 𝑖 is chosen to play at time 𝑒 ′ ≥ 𝑒 .
Each player 𝑖 has some local state at each node, which translates
into the initial information known by 𝑖 , the messages 𝑖 sent and re-
ceived at the time that 𝑖 moves, and the moves that 𝑖 has made. The
nodes where a player 𝑖 moves are further partitioned into informa-
tion sets, which are sets of nodes in the game tree that contain the
same local state for the same player 𝑖 , in that 𝑖 cannot distinguish
them. We assume that the scheduler has complete information, so
that the scheduler’s information sets consist of the singletons.
Since we do not assume synchrony, we need our game to be able
to continue even if a faulty player decides not to reply. As such,
w.l.o.g. we assume that players that decide not to play will at least
play the default-move, which consists of notifying the scheduler
that this player will not move, so that the game continues with
the scheduler choosing the next player to move. Thus, in every
node where the scheduler is to play a move, the scheduler can play
any move that combines a player and a subset of messages that
such player can deliver before playing. Then, the selected player
moves, after which the scheduler selects again the next player
for the next node, and the messages it receives, and so on. The
scheduler alternates thus with one player at each node down a path
in the game tree until reaching a leaf. A run of the game is then a
downward path in the tree from the root to a leaf.
Strategies.We denote the set of actions of a player 𝑖 (or the sched-
uler) as𝐴𝑖 (or𝐴𝑠 ), and a strategy 𝜎𝑖 for that set of actions is denoted
as a function from 𝑖’s information sets to a distribution over the
actions. We denote the set of all possible strategies of player 𝑖 as
S𝑖 . Let S𝐼 = Π𝑖∈𝐼S𝑖 and 𝐴𝐼 = Π𝑖∈𝐼𝐴𝑖 for a subset 𝐼 ⊆ 𝑁 . Let
S = S𝑁 with 𝐴−𝐼 = Π𝑖∉𝐼𝐴𝑖 and S−𝐼 = Π𝑖∉𝐼S𝑖 . A joint strategy
#»𝜎 = (𝜎0, 𝜎1, ..., 𝜎𝑛−1) draws thus a distribution over paths in the
game tree (given the scheduler’s strategy 𝜎𝑠 ), where 𝑢𝑖 ( #»𝜎 , 𝜎𝑠 ) is
player’s 𝑖 expected utility if #»𝜎 is played along with a strategy
for the scheduler 𝜎𝑠 . A strategy \𝑖 strictly dominates 𝜏𝑖 for 𝑖 if
for all #»
𝜙 −𝑖 ∈ S−𝑖 and all strategies 𝜎𝑠 of the scheduler we have
𝑢𝑖 (\𝑖 ,
#»
𝜙 −𝑖 , 𝜎𝑠 ) > 𝑢𝑖 (𝜏𝑖 ,
#»
𝜙 −𝑖 , 𝜎𝑠 ).
Given some desired functionality F , a protocol is the recom-
mended joint strategy #»𝜎 whose outcome satisfies F for all strate-
gies 𝜎𝑠 of the scheduler, and an associated game Γ for that protocol is
defined as all possible deviations from the protocol [2]. In this case,
we say that the protocol #»𝜎 implements the functionality. Note that
both the scheduler and the players can use probabilistic strategies.
Failure model.We set 𝑡0 = ⌈𝑛3 ⌉ − 1 for the rest of this paper and 𝑘
players out of 𝑛 can be rational while 𝑡 ≤ 𝑡0 can be Byzantine; the
rest of the players are correct. Correct players follow the protocol:
the expected utility of correct player 𝑖 is greater than 0 for any
run in which the outcome satisfies consensus, and 0 for any other
run. Rational players can deviate to follow the strategy that yields
them the greatest expected utility at any time they are to move,
while Byzantine players can deviate in any way, even not replying
at all (apart from notifying the scheduler that they will not move).
Rational players have greater utility for outcomes in which they
caused a disagreement than from outcomes that satisfy consensus,
but have no interest in deviating from consensus for anything else,
in that they prefer to terminate and to guarantee validity. We will
detail further the utilities of rational players in Section 4.3.
We assume that if a coalition manages to cause a disagreement,
then it obtains a payoff of at most G, which we call the total gain.
Nevertheless, this total gain may be, for example, the entire market
value of the system. In a payment system application in which
players agree on a set of transactions to be decided, the total gain G
is exactly the sum of all the amounts spent in all transactions. We
also assume, w.l.o.g., that a coalition with 𝑘 rational players and 𝑡
Byzantine players split equally the total gain into 𝑘 parts, which we
call the gain 𝑔 = G/𝑘 , that is, Byzantine players are willing to give
all the total gain from causing a disagreement to the rational players
that collude (to incentivize the deviation for these rational players).
Note that a protocol that tolerates a maximum gain G equally
split into 𝑘 parts also tolerates any gain such that the maximum
share of the split is G/𝑘 , but we assume the equal split for ease of
exposition. We speak of the disagreeing strategy as the strategy in
which players collude to produce a disagreement, and of a coalition
disagreeing to refer to a coalition that plays the disagreeing strategy.
A disagreement of consensus can mean two or more disjoint groups
of non-deviating players deciding two or more separate, conflicting
decisions [36]. For ease of exposition, we consider in this work
only disagreements into two values. Nonetheless, if the size of the
coalition is less than half the total number of players 𝑘 + 𝑡 < 𝑛/2 (as
is the case for the work that we present) then the coalition can only
cause a disagreement into two values [36], whereas greater sizes of
a coalition can cause disagreements into multiple values [34].
We let rational players in a coalition and Byzantine players (in
or outside the coalition) know the types of all players, so that
they know which players are the other Byzantine players, rational
players and correct players, while the rest of the players only know
the upper bounds on the number of rational and Byzantine players,
i.e., 𝑘 and 𝑡 respectively, and their own individual type (that is,
whether they are rational, Byzantine or correct).
Cheap talks. As we are in a fully distributed system, without a
trusted central entity like a mediator, we assume cheap-talks, that
is, private pairwise communication channels. We also assume neg-
ligible communication cost through these channels. Non-Byzantine
players are also only interested in reaching consensus, and not in
the number of messages exchanged. Similarly, we assume the cost
of performing local computations (such as validating proposals, or
verifying signatures) to be negligible.
Cryptography.We require the use of standard cryptography, for
which we reuse the assumptions of Goldreich et al. [23]: polyno-
mially bounded players and the enhanced trapdoor permutations.
In practice, these two assumptions mean that players can sign un-
forgeable messages, and that they can perform oblivious transfer.
Each player has a public key and a private key, and public keys are
common knowledge.
Robustness. Given that a Nash equilibrium only protects against
single-player deviations, and our distributed system may be suscep-
tible of a coalition of 𝑘 rational and 𝑡 Byzantine players, it is impor-
tant to consider tolerating multi-player deviations. We thus restate
Abraham’s et al. [2] definitions of 𝑡-immunity, 𝜖-(𝑘, 𝑡)-robustness
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
171
and the most recent definition of 𝑘-resilient equilibrium [1]. The
notion of 𝑘-resilience is motivated in distributed computing by
the need to tolerate a coalition of 𝑘 rational players that can all
coordinate actions. A joint strategy is 𝑘-resilient if not all rational
members of a coalition of size at most 𝑘 can gain greater utility by
deviating in a coordinated way.
Definition 2.1 (𝑘-resilient equilibrium). A joint strategy #»𝜎 ∈ S
is a 𝑘-resilient equilibrium (resp. strongly k-resilient equilibrium) if,
for all 𝐾 ⊆ 𝑁 with |𝐾 | ≤ 𝑘 , all #»𝜏 𝐾 ∈ S𝐾 , all strategies 𝜎𝑠 of the
scheduler, and for some (resp. all) 𝑖 ∈ 𝐾 we have𝑢𝑖 ( #»𝜎 𝐾 ,
#»𝜎 −𝐾 , 𝜎𝑠 ) ≥
𝑢𝑖 ( #»𝜏 𝐾 ,
#»𝜎 −𝐾 , 𝜎𝑠 ).
The notion of 𝑡-immunity is motivated in distributed algorithms
by the need to tolerate 𝑡 Byzantine players. An equilibrium #»𝜎 is
𝑡-immune if non-Byzantine players still prefer to follow #»𝜎 despite
the deviations of up to 𝑡 Byzantine players.
Definition 2.2 (𝑡-immunity). A joint strategy #»𝜎 ∈ S is t-immune
if, for all𝑇 ⊆ 𝑁 with |𝑇 | ≤ 𝑡 , all #»𝜏 ∈ S𝑇 , all 𝑖 ∉ 𝑇 and all strategies
of the scheduler 𝜎𝑠 , we have 𝑢𝑖 ( #»𝜎 −𝑇 ,
#»𝜏 𝑇 , 𝜎𝑠 ) ≥ 𝑢𝑖 ( #»𝜎 , 𝜎𝑠 ).
A joint strategy is an 𝜖-(𝑘, 𝑡)-robust equilibrium if no coalition of
𝑘 rational players can coordinate to increase their expected utility
by 𝜖 regardless of the arbitrary behavior of up to 𝑡 Byzantine players,
even if the Byzantine players join their coalition. We illustrate it
however with 𝜖 because of the use of cryptography, that is, in order
to account for the (negligible) probability of the coalition breaking
cryptography, as was done previously [2]:
Definition 2.3 (𝜖-(𝑘, 𝑡)-robust equilibrium). A joint strategy #»𝜎 ∈
S is an 𝜖-(𝑘, 𝑡)-robust (resp. strongly 𝜖-(𝑘, 𝑡)-robust) equilibrium
if for all 𝐾,𝑇 ⊆ 𝑁 such that 𝐾 ∩ 𝑇 = ∅, |𝐾 | ≤ 𝑘, and |𝑇 | ≤ 𝑡 ,
for all #»𝜏 𝑇 ∈ S𝑇 , for all
#»
𝜙 𝐾 ∈ S𝐾 , for some (resp. all) 𝑖 ∈ 𝐾 ,
and all strategies of the scheduler 𝜎𝑠 , we have 𝑢𝑖 ( #»𝜎 −𝑇 ,
#»𝜏 𝑇 , 𝜎𝑠 ) ≥
𝑢𝑖 ( #»𝜎 𝑁−(𝐾∪𝑇 ) ,
#»
𝜙 𝐾 ,
#»𝜏 𝑇 , 𝜎𝑠 ) − 𝜖 . We speak instead of a (𝑘, 𝑡)-robust
equilibrium if 𝜖 = 0.
We use a recent definition of 𝑘-resilient equilibrium [1], which
slightly differs from the definition of an 𝜖-(𝑘, 𝑡)-robust equilibrium.
We define here strong resilience and strong robustness to refer
to the stronger versions of these properties [2]. Byzantine fault
tolerance in distributed computing is equivalent to our definition
of 𝑡-immunity in game theory.
Given some game Γ and desired functionality F , we say that
a protocol #»𝜎 is a 𝑘-resilient protocol for F if #»𝜎 implements F
and is a 𝑘-resilient equilibrium. For example, if #»𝜎 is a k-resilient
protocol for the consensus problem, then in all runs of #»𝜎 , every
non-deviating player terminates and agrees on the same valid value.
We extend this notation to 𝑡-immunity and 𝜖-(𝑘, 𝑡)-robustness. The
required functionality of this paper is thus reaching agreement.
Punishment strategy. We also restate the definition of a punish-
ment strategy [2] as a threat that correct and rational players can
play in order to prevent other rational players from deviating. The
punishment strategy guarantees that if 𝑘 rational players deviate,
then 𝑡 + 1 players can lower the utility of these rational players by
playing the punishment strategy.
Definition 2.4 ((𝑘, 𝑡)-punishment strategy). A joint strategy #»𝜌 is
a (𝑘, 𝑡)-punishment strategy with respect to #»𝜎 if for all 𝐾,𝑇 , 𝑃 ⊆ 𝑁
such that 𝐾,𝑇 , 𝑃 are disjoint, |𝐾 | ≤ 𝑘, |𝑇 | ≤ 𝑡, |𝑃 | > 𝑡 , for all #»𝜏 ∈
S𝑇 , for all
#»
𝜙 𝐾 ∈ S𝐾 , for all 𝑖 ∈ 𝐾 , and all strategies of the scheduler
𝜎𝑠 , we have 𝑢𝑖 ( #»𝜎 −𝑇 ,
#»𝜏 𝑇 , 𝜎𝑠 ) > 𝑢𝑖 ( #»𝜎 𝑁−(𝐾∪𝑇∪𝑃 ) ,
#»
𝜙 𝐾 ,
#»𝜏 𝑇 ,
#»𝜌 𝑃 , 𝜎𝑠 ).
Intuitively, a punishment strategy represents a threat to prevent
rational players from deviating, in that if they deviate, then players
in 𝑃 can play the punishment strategy #»𝜌 and the deviating rational
players decrease their utility with respect to following #»𝜎 . For exam-
ple, crime sentences are an effective punishment strategy against
committing crimes. Not terminating a protocol if just one player
deviates can also be a punishment strategy against deviating from
the protocol.
Accountability. Previous work introduced signatures in consensus
protocol messages, guaranteeing that for a disagreement to occur,
at least 𝑡0 + 1 players must sign conflicting messages, and once
these messages are discovered by a correct player, such player can
prove the fraudsters to the rest of correct players through Proofs-
of-Fraud (PoFs) [12, 34]. We also adapt to this model the property
of accountability, recently defined for consensus [12, 13]:
Definition 2.5 (accountability). Let #»𝜎 be a protocol that imple-
ments agreement. Suppose that a disagreement takes place, then #»𝜎
is accountable if all correct players will eventually gather enough
proof that at least 𝑡0 + 1 players deviated to cause the disagreement.
Rational agreement. In the remainder, we are interested in
proposing a consensus protocol that is immune to up to 𝑡0 Byzantine
failures and robust to a coalition of up to 𝑘 rational and 𝑡 Byzantine
players, so we restate the Byzantine consensus problem [32] in the
presence of rational players: The Byzantine consensus problem is,
given 𝑛 players, each with an initial value, to ensure (i) agreement in
that no two non-deviating players decide different values; (ii) valid-
ity in that the decided value has to be proposed; and (iii) termination
in that eventually every non-deviating player decides.
Definition 2.6 (Rational Agreement). Consider a system with 𝑛
players, a protocol #»𝜎 solves the rational agreement problem if it
implements consensus, and is 𝑡0-immune and 𝜖-(𝑘, 𝑡)-robust for
some 𝑘, 𝑡 > 0 such that 𝑛 ≤ 3(𝑘 + 𝑡).
3 RATIONAL AGREEMENT IMPOSSIBILITY
WITHOUT A BAITING STRATEGY
In this section, we introduce a baiting strategy as a particular case
of punishment strategy and show that it is necessary to devise a
consensus protocol robust to a coalition of 𝑘 rational players and 𝑡
Byzantine players.
Our solution to agreement in the presence of rational and Byzan-
tine players, presented in Section 4.3, consists of rewarding rational
players for betraying the coalition. One may wonder whether re-
warding rational players in a coalition is the only way to obtain
𝜖-(𝑘, 𝑡)-robustness that tolerates coalitions of size 𝑛 ≤ 3(𝑘 + 𝑡)
in partial synchrony. To demonstrate the need for a reward, we
first formalize a type of (𝑘, 𝑡)-punishment strategy, which we call a
(𝑘, 𝑡,𝑚)-baiting strategy. A (𝑘, 𝑡,𝑚)-baiting strategy is a (𝑘 −𝑚, 𝑡)-
punishment strategy such that 𝑘 ≥ 𝑚 > 0, and these𝑚 rational
players prefer to actually play the baiting strategy than to deviate
with the rest of the players in the coalition. That is,𝑚 players of
the coalition have to play the baiting strategy for it to succeed, and
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
172
at least𝑚 rational players in the coalition prefer to play the baiting
strategy than to deviate with the coalition. An example is offering
a crime reduction for a criminal to cooperate with law enforcement
into catching the criminal group to which it belongs.
Definition 3.1 ((𝑘, 𝑡,𝑚)-baiting strategy). A joint strategy #»[ is
a (𝑘, 𝑡,𝑚)-baiting strategy with respect to a strategy #»𝜎 if #»[ is a
(𝑘 −𝑚, 𝑡)-punishment strategy with respect to #»𝜎 , with 0 < 𝑚 ≤ 𝑘
and for all 𝐾,𝑇 , 𝑃 ⊆ 𝑁 such that 𝐾 ∩𝑇 = ∅, |𝑃 ∩𝐾 | ≥ 𝑚, 𝑃 ∩𝑇 = ∅,
|𝐾\𝑃 | ≤ 𝑘 − 𝑚, |𝑇 | ≤ 𝑡, |𝑃 | > 𝑡 , for all #»𝜏 ∈ S𝑇 , all
#»
𝜙 𝐾\𝑃 ∈
S𝐾\𝑃 − { #»𝜎 𝐾 }, all
#»
\ 𝑃 ∈ S𝑃 , all 𝑖 ∈ 𝑃 , and all strategies of the
scheduler 𝜎𝑠 , we have:
𝑢𝑖 ( #»𝜎 𝑁−(𝐾∪𝑇∪𝑃 ) ,
#»
𝜙 𝐾\𝑃 ,
#»𝜏 𝑇 ,
#»[ 𝑃 , 𝜎𝑠 ) ≥ 𝑢𝑖 ( #»𝜎 𝑁−(𝐾∪𝑇∪𝑃 ) ,
#»
𝜙 𝐾\𝑃 ,
#»𝜏 𝑇 ,
#»
\ 𝑃 , 𝜎𝑠 ) .
Additionally, we speak of a strong (𝑘, 𝑡,𝑚)-baiting strategy in the
particular case where for all rational coalitions 𝐾 ⊆ 𝑁 such
that |𝐾 | ≤ 𝑘 , |𝐾 ∩ 𝑃 | ≥ 𝑚 and all #»
𝜙 𝐾\𝑃 ∈ S𝐾\𝑃 we have:∑
𝑖∈𝐾 𝑢𝑖 ( #»𝜎 𝑁−(𝐾∪𝑃 ) ,
#»
𝜙 𝐾\𝑃 ,
#»[ 𝑃 , 𝜎𝑠 ) ≤
∑
𝑖∈𝐾 𝑢𝑖 ( #»𝜎 , 𝜎𝑠 ).
A baiting strategy illustrates a situation where at least𝑚 rational
players in the coalition may be interested in baiting other 𝑘 + 𝑡 −𝑚
rational and Byzantine players into a trap: the 𝑘 + 𝑡 of them collude
to deviate initially, just so that these 𝑚 players can prove such
deviation by playing the baiting strategy, and get a reward for
exposing this deviation. Such a strategy has a significant impact
in a protocol to implement agreement. A strong baiting strategy
defines a baiting strategy in which the fact that𝑚 deviating players
play the baiting strategy does not yield greater payoff to the entire
coalition as a whole (if such coalition was made only by rationals),
compared to following the protocol. This prevents a coalition of
rational players from colluding together so as to play the baiting
strategy on themselves only with the purpose of splitting the baiting
reward among the colluding members. Notwithstanding, neither a
baiting strategy nor a strong baiting strategy show that if these𝑚
players play the baiting strategy, then the protocol implements the
desired functionality. We illustrate the efficacy of baiting strategies
to influence the outcome of a protocol in the example of the rational
generals, shown in Figure 2.
Impossibility result. The reason why a (𝑘, 𝑡,𝑚)-baiting strategy
is relevant to the consensus problem is that without such a strategy
it is not possible to obtain a consensus protocol that is (𝑘, 𝑡)-robust
where 𝑘 > 0. We show this result in Theorem 3.2. The proof is
similar to that of the impossibility of 𝑡-immune consensus under
partial synchrony for 𝑡 > 𝑡0 [19], since a partition of rational and
Byzantine players can exploit two disjoint partitions of correct
players to lead them to different decisions. Let us recall that we
do not assume solution preference, and thus the payoffs from a
disagreement can be singificantly greater than those of agreeing
for rational players. For the proof of Theorem 3.2, we first show
the more general proof of Lemma 3.1.
Lemma 3.1. It is impossible to obtain a protocol #»𝜎 that implements
agreement, is 𝑡0-immune and (𝑘, 𝑡)-robust, 𝑘 ≥ 0 and 𝑡 = max(𝑡0 −
𝑘 + 1, 0) unless there is a (𝑘, 𝑡,𝑚)-baiting strategy with respect to #»𝜎 ,
for𝑚 > 𝑘+𝑡−𝑛
2 + 𝑡0.
Proof. We refer to Dwork et al.’s [19] work for the impossibility
of increasing 𝑡 > 𝑡0 and obtaining agreement (i.e., for 𝑘 = 0). For
Rational generals example.We illustrate the intuition behind
baiting strategies with an example inspired from the Byzantine
generals problem [32], that we refer to as the ‘rational generals’
problem: suppose 𝑛 = 7 Ottoman generals need to agree on
whether to attack or retreat. If all generals agree on attacking,
they will succeed, if they agree on retreat, they can succeed
another day. However, if only some of the generals attack, they
will lose. There are two Byzantine generals, i.e., 𝑡 = 2 , whose goal
is for the Ottomans to disagree on their decision for them to lose,
and another rational general, i.e., 𝑘 = 1, who has been offered a
bribe G in order to contribute to the disagreement, but who is
willing to betray the Byzantines for a greater income from the
Ottomans. Because of accountability, the generals will eventually
be able to track the disagreement to both the 𝑡 Byzantine and
𝑘 rational generals, but by then the 𝑘 rational generals will be
enjoying its reward G in Constantinople, out of reach.
The generals suspect that there might be a bribed rational
general (𝑘 = 1). In an attempt from them to make the rational
general talk, they offer a reward R > G as a bounty for proving
the fraud of every other Byzantine and rational general, that
is, if the rational general reveals its identity and that of the 𝑡
Byzantine with proofs, then this rational general is spared and
rewarded with R, while the 𝑡 Byzantine generals lose all of their
capital (i.e., properties and savings) that they own in the Ottoman
empire. In this case, the rational general sees a greater incentive
to expose both himself and the Byzantine generals. This is an
example of a baiting strategy. Additionally, the Ottoman generals
will pay R with the capital taken from the 𝑡 Byzantine generals,
so the Ottoman empire will not even pay for the reward.
Notice that Ottoman generals must guarantee to the rational
general that they will recognize him as the first to expose the
coalition (and the only rightful owner of the reward), so that the
rational general is not influenced by a threat from the Byzantine
generals to steal the reward if he betrays the coalition. That is,
the rational general will only bait the coalition if the protocol
ensures that the Byzantine generals will not be able to steal the
reward from the rational general after seeing that he betrayed
the coalition. This is in order to prevent the Byzantine generals
from rushing to bait as soon as they learn the rational general is
starting to bait, creating a situation in which both Byzantine and
rational generals seem to be legitimate baiters of the coalition.
In the extensive game, this means that the rational general
must first behave and make moves as if he would cause the
disagreement. Then, the rational general will only bait if he gets
both enough evidence of the fraud of the deviants and assurance
that the Byzantine generals will not outpace him and steal the
reward.
Figure 2: Rational generals example.
𝑘 > 0 with 𝑡 ≤ 𝑡0, assume the contrary: let #»𝜎 be a protocol such
that there is no (𝑘, 𝑡,𝑚)-baiting strategy with respect to #»𝜎 and
#»𝜎 is (𝑘, 𝑡)-robust, for 𝑡 = 𝑚𝑎𝑥 (𝑡0 − 𝑘 + 1, 0), 𝑘 > 0. Since the
protocol is 𝑡0-immune and it works under partial synchrony, the
protocol must not require more than 𝑛 − 𝑡0 players participating in
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
173
it in order to take a decision, or else the Byzantine players could
prevent termination. Consider a partition of the network between
4 disjoint subsets 𝑁 = 𝐾 ∪ 𝐴 ∪ 𝐵 ∪ 𝐹 , where 𝐾 are the rational
players (there is at least one), 𝐹 are the Byzantine players, i.e.,
|𝐹 | + |𝐾 | = 𝑡 + 𝑘 ≥ 𝑡0 + 1, and 𝐴 and 𝐵 are the rest of the players
such that |𝐴| + |𝐵 | ≤ 𝑛 − 𝑡0 − 1 and both |𝐴| + |𝐹 | + |𝐾 | ≥ 𝑛 − 𝑡0 and
|𝐵 |+ |𝐹 |+ |𝐾 | ≥ 𝑛−𝑡0 hold (recall 𝑡0 = ⌈𝑛3 ⌉−1). Let
#»
\ be the strategy
in which the rational players in 𝐾 deviate with Byzantine players
in 𝐹 and achieve a disagreement between players in 𝐴 and players
in 𝐵. If the players in 𝐹 and 𝐾 are all Byzantine and rational players,
then such a disagreement is always possible and the utility for each
rational player is, by definition of the model, greater than that of
reaching agreement. Notice also that since 𝑡 = max(𝑡0 − 𝑘 + 1, 0),
if 𝑚 > 𝑘+𝑡−𝑛
2 + 𝑡0 rational players do not deviate to cause such
disagreement, we have that at least one of |𝐴| + |𝐹 | + |𝐾 | −𝑚 < 𝑛−𝑡0
and |𝐵 | + |𝐹 | + |𝐾 | −𝑚 < 𝑛− 𝑡0 holds, or both: for this value of𝑚 the
deviants cannot cause a disagreement. However, this is not true if
instead𝑚 ≤ 𝑘+𝑡−𝑛
2 + 𝑡0. It follows that it is necessary to encourage
at least𝑚 > 𝑘+𝑡−𝑛
2 + 𝑡0 rational players to not deviate into causing
a disagreement, which means, by definition, that a (𝑘, 𝑡,𝑚)-baiting
strategy is necessary. □
Theorem3.2. It is impossible to obtain a protocol #»𝜎 that implements
rational agreement unless there is a (𝑘, 𝑡,𝑚)-baiting strategy with
respect to #»𝜎 , for𝑚 > 𝑘+𝑡−𝑛
2 + 𝑡0.
Proof. By definition, every (𝑘, 𝑡)-robust protocol for𝑛 ≤ 3(𝑘+𝑡)
must also be (𝑘, 𝑡)-robust, for some 𝑘 ≥ 0 and 𝑡 = max(𝑡0 −𝑘 + 1, 0).
Therefore it derives from Lemma 3.1. □
Theorem 3.2 shows the need for a baiting strategy to solve ra-
tional agreement. In Section 4.2 we show the implementation of
an additional phase to an accountable consensus protocol in order
to provide the functionality of a baiting strategy. In Section 4.3 we
illustrate the values of a reward and deposit per player to make a
strong baiting strategy that at least𝑚 rational players will play.
4 TRAP: REACHING RATIONAL AGREEMENT
In this section, we present the Trap (Tackling Rational Agreement
through Persuasion) protocol, the first protocol to solve the rational
agreement problem. The Trap protocol comprises three compo-
nents:
(1) A financial component, consisting of a deposit per player
L, taken at the start of the protocol from each participating
player, and a rewardR, which is given to a player in the event
that it provides PoFs for a disagreement on predecisions.
(2) An accountable consensus component, that pre-decides out-
puts from an accountable consensus protocol.
(3) A baiting component, embodied in a novel Byzantine Fault
Tolerant commit-reveal (BFTCR) protocol that executes af-
ter the accountable consensus protocol. This component
terminates either deciding one output (predecision) of the
accountable consensus protocol, or resolving a disagreement
on predecisions by rewarding one of the deviating players
that exposed the disagreement and punishing the rest of
deviating players.
We first provide an overview of the properties that we aim at for the
Trap protocol in Section 4.1, and the possible runs of the game that
derive from implementing a strong baiting strategy for the rational
agreement problem with the aforementioned components. We then
introduce and prove the correctness of the baiting component, the
BFTCR protocol, in Section 4.2. Finally, we analyze the financial
component, that is, the specific values of reward and deposits, in
Section 4.3. The accountable consensus component can be any
accountable consensus protocol [12–14, 35], and thus we treat this
component as a black box, for the sake of generality.
4.1 Overview: consensus with a baiting strategy
We proved in Section 3 that we need a baiting strategy for a protocol
to solve the rational agreement problem.
Before we present the implementation of such a baiting strat-
egy in Section 4.2, with additional configurations of the required
deposits and reward sizes in Section 4.3, we present in this section
the basics of our baiting strategy. For this purpose, we focus first
on the properties that we aim at for such a baiting strategy. Then,
we showcase all the possible runs of a protocol for consensus that
provides such a strong baiting strategy.
Given a protocol #»𝜎 that implements accountable consensus and
is 𝑡0-immune, we will extend it to implement the rational agreement
problem, in that we will prove the three following properties:
• Baiting-dominance: There is a (𝑘, 𝑡,𝑚)-baiting strategy #»[ with
respect to #»𝜎 , for𝑚 > 𝑘+𝑡−𝑛
2 + 𝑡0.
• Baiting-agreement: #»[ implements agreement.
• Lossfree-reward: #»[ is a strong baiting strategy.
Baiting-dominance states the necessary condition that a baiting
strategy exists, while baiting-agreement guarantees that playing
such a baiting strategy still leads to agreement. Lossfree-reward
guarantees that such a baiting strategy is a strong baiting strat-
egy. Coming back to the rational generals example of Figure 2,
baiting-dominance states the existence of the reward for the ratio-
nal general, baiting-agreement guarantees that generals will still
decide whether to attack or retreat after paying the reward to the ra-
tional general, and lossfree-reward guarantees that only the slashed
capital of the Byzantine generals will be used to pay the reward to
the rational general.
Reward for baiting. Since the protocol is accountable, we add
a baiting reward R for player 𝑖 if 𝑖 can prove to the rest of the
players that a coalition of at least 𝑡0 + 1 players are trying to cause a
disagreement, but before they succeed at causing the disagreement.
If multiple players are eligible for the baiting reward, then only one
is chosen at random to win the reward, and the rest are treated as
fraudsters that did not bait. We select the winner at random in an
additional winner consensus in which the winner is decided from
among the proposed candidates to win from correct replicas in this
winner consensus. We explain further the winner consensus later
in this section. Players can prove that a coalition is trying to cause a
disagreement through PoFs which undeniably show two conflicting
messages signed by the same set of players. The reward is only
given to 𝑖 if 𝑖 exposes this coalition before the coalition causes the
disagreement (i.e., before both partitions of correct players decide
different decisions).
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
174
Funding the reward with deposits. we require all players to
place a minimum deposit L. We also require such deposit to be
big enough so that the deposit taken from the exposed coalition
is enough to pay the reward, satisfying lossfree-reward. Our goal
is to set R and L so that we implement a baiting strategy for a
set𝑀 of rational players in the coalition, such that if others in the
coalition bait, then for all 𝑖 ∈ 𝑀 , player 𝑖 is better off also trying
to bait and getting the reward, while if the rest of the players in
the coalition do not bait, then if 𝑖 baits then 𝑖 gets the greatest
expected utility that it can in that information set. We analyze
in Theorem 4.4 the required values for such deposit and reward
necessary to incentivize at least |𝑀 | = 𝑚 > 𝑘+𝑡−𝑛
2 + 𝑡0 rational
players in a coalition to follow a baiting strategy, depending on
the size 𝑘 + 𝑡 of the coalition and on the maximum total gain from
disagreeing G. For now, however, let us ignore the values of L
and R and focus on the protocol that solves the rational agreement
problem, by assuming that these values of L and R are enough to
make𝑚 > 𝑘+𝑡−𝑛
2 + 𝑡0 rational players bait the coalition, instead of
terminating a disagreement. We will come back to specify proper
values for L and R in Section 4.3. If these PoFs expose at least 𝑡0 + 1
players including the winner of the baiting reward R, then the 𝑡0
(or more) remaining colluding players lose the deposit amount L.
Dominating disagreements.We explore here the possible runs,
assuming that we already have such a baiting strategy, and what
each of these runs means for the payoffs of a rational player 𝑖:
(1) Rational players including 𝑖 contribute to reaching agreement
and follow the protocol #»𝜎 , getting some utility 𝑢𝑖 ( #»𝜎 −𝑇 ,
#»𝜏 𝑇 ) ≥ 𝜖
where 𝜖 > 0.
(2) Some rational players collude with 𝑖 and deviate to disagree,
playing strategy #»
𝜙 with some Byzantine players 𝑇 and other ratio-
nal players 𝐾 such that |𝐾 ∪𝑇 | ≥ 𝑛/3, 𝐾 ∩𝑇 = ∅, obtaining utility
𝑢𝑖 ( #»𝜎 𝑁−𝐾−𝑇 ,
#»
𝜙 𝐾∪𝑇 ) = 𝑔.
(3) Player 𝑖 deviates to bait other rational players into colluding
with some Byzantine players such that |𝐾∪𝑇 | ≥ 𝑛/3,𝐾∩𝑇 = ∅, and
this deviation consists of playing strategy #»[ to expose the colluding
players via PoFs and obtain the baiting reward. As a result, player
𝑖 obtains utility 𝑢𝑖 ( #»𝜎 𝑁−𝐾−𝑇 ,
#»
𝜙 𝐾∪𝑇−𝑀 ,
#»[ 𝑀 ) = 𝑝 (𝑚)R − 𝑞(𝑚)L,
where 𝑀 is the set of players of the coalition that bait, i.e., 𝑖 ∈ 𝑀 ,
with |𝑀 | = 𝑚. 𝑝 (𝑚) = 1/𝑚 represents the probability of winning
the reward, while 𝑞(𝑚) = 1 − 𝑝 (𝑚) = (𝑚 − 1)/𝑚 the probability of
not winning it after baiting.
(4) Player 𝑖 deviates to disagree only to suffer a trap baited by
another rational (or group of rational players), obtaining utility
𝑢𝑖 ( #»𝜎 𝑁−𝐾−𝑇 ,
#»
𝜙 𝐾∪𝑇−𝑀 ,
#»[ 𝑀 ) ≤ −L.
(5) In any run where the protocol does not terminate, player 𝑖
obtains negative utility.
(6) Player 𝑖 contributes to reaching agreement but a coalition
causes a disagreement. In this case, 𝑖 is one of the victims of a
disagreement (for example, a double-spending). Hence, 𝑖 obtains
negative utility.
Notice that the runs 4, 5 and 6 are strictly dominated by run 1
(following the protocol). Our goal is to make runs represented by 3
runs that also implement agreement and that strictly dominate runs
represented by 2.
4.2 Baiting component: the BFTCR protocol
In this section, we present the first implementation of a baiting
strategy for rational agreement. As such, we extend an accountable
consensus protocol with a Byzantine Fault Tolerant commit-reveal
(BFTCR) phase in order to solve consensus even if there is a dis-
agreement at consensus level, if at least𝑚 rational players decide
to betray the coalition in exchange for trying to win a reward. We
show in Algorithm 1 the BFTCR phase. As such, we speak of a
predecision for a decision of the accountable consensus protocol,
whereas a decision now refers to the outcome of the BFTCR protocol.
The BFTCR phase consists of 5 main parts:
(1) A reliable broadcast, in which players share their encrypted
commitment (line 15),
(2) a second reliable broadcast, in which players share the first
(𝑛 − 𝑡0) encrypted commitments that they delivered in the
first reliable broadcast (line 19),
(3) a regular broadcast, in which players share the key to reveal
their commitment (line 23),
(4) an additional consensus to select the winner of the reward,
if some players reveal a list of PoFs (line 39), and
(5) a slashing of the deposits from the fraudsters, payment of
the reward to the winner and resolution of the disagreement
on predecisions (line 40).
Commit and reveal. The purpose of the first group of reliable
broadcasts is to reliably broadcast the encrypted PoFs, should a
player own them, or an encrypted hash of a predecision otherwise.
We say that the commitment is the encrypted content that each
player decides to broadcast in this first reliable broadcast. In line 19
each player 𝑖 then starts the second reliable broadcast by broadcast-
ing a list of the first (𝑛− 𝑡0) delivered commitments that 𝑖 delivered
in the first reliable broadcast. The purpose of the calls to broadcast
on lines 23 and 25 is to deliver the keys to decrypt the encrypted
messages. A player 𝑖 thus reveals his commitment by broadcasting
the key. A player 𝑖 decrypts the commitment of player 𝑗 in line 26.
Then, player 𝑖 adds this decrypted message to the list of decided
hashes in lines 28 to 31, or to the list of PoFs received in lines 33
to 35.
Termination. The BFTCR phase of the Trap protocol terminates
in one of two ways:
• either there is no disagreement on predecisions, and then the
protocol terminates when at least (𝑛 − 𝑡0) messages are decrypted
with the same hash of the predecisions in line 31;
• or some players reveal a disagreement on predecisions through
PoFs, and then the protocol terminates when at least 𝑡0+1messages
are decrypted (without counting players that are proven to be false
through a PoF) with a reward to a chosen baiter and a punishment
to the remaining players that are listed in the PoFs from lines 36
to 40.
Note that accountability does not guarantee that a baiter will
gather enough PoFs before a disagreement takes place. We prove
that baiters will gather enough PoFs before a disagreement takes
place as part of the proof of Theorem 4.2. The idea is that𝑚 rational
players will wait to receive enough PoFs to be able to commit to
bait, where𝑚 is big enough to prevent termination of either of the
partitions of correct players.
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
175
Valid candidates of the winner consensus. We define a valid
candidate to win the reward as a member of a deviating coalition
that committed to bait the coalition (by sending a commitment to
a list of PoFs of the coalition in line 15) independently of whether
other𝑚 players of the coalition also committed to bait, for𝑚 >
𝑘+𝑡−𝑛
2 + 𝑡0. The objective of the BFTCR protocol is to distinguish
valid candidates from players who try to win the reward only after
they learn that the disagreement will not succeed. A correct player 𝑖
considers a baiter 𝑗 as a valid candidate if 𝑖 can see 𝑗 ’s commitment
to bait in at least 𝑡0 + 1messages from the second reliable broadcast.
We refer to this 𝑡0 + 1 messages as a proof-of-baiting (PoB). The
BFTCR protocol selects the winner of the bait among the list of
valid candidates by executing an additional consensus, in the call to
select_winner in line 39, in which all participating players propose
the PoFs they know about and the valid candidates, along with the
PoBs. We detail further this call later in this section.
Note that a rational player 𝑖 that commits to bait a coalition may
deviate from Algorithm 1 in order to hinder other deviants from
becoming valid candidates after 𝑖 reveals its commitment. This is
because this way 𝑖 maximizes its chances of winning the reward
(by minimizing the number of valid candidates for the reward).
This is an expected deviation of a baiting rational player, which
consists on waiting to deliver as many messages from the second
reliable broadcast as possible from both partitions of correct players
that suffered the disagreement on predecisions, and we show the
correctness of this approach as part of the proof of Theorem 4.4.
Correctness and randomness of the winner consensus. We
show in Theorem 4.5 that no deviating player can win the reward
without being a valid candidate, i.e., no player can bait and win
the reward after learning that other 𝑚 (or more) players baited.
Additionally, note that the winner consensus solves consensus
for 𝑛 > 9/5(𝑘 + 𝑡) because at least 𝑡0 + 1 provably fraudulent
players of the coalition will not participate in it, as has already
been shown [34], and we consider 𝑛 > 2(𝑘 + 𝑡). That is, at most
𝑛′ = 𝑛− (𝑡0+1) < 2𝑛/3 players participate in the winner consensus.
Since the maximum coalition size is 𝑘 + 𝑡 < 𝑛/2, then the remain-
ing players of the coalition that could participate in the winner
consensus are 𝑡 ′ = 𝑛/2 − (𝑡0 + 1) < 𝑛/6, and thus 𝑡 ′ < 𝑛′/3 and
the winner consensus solves consensus. Furthermore, the winner
consensus only terminates once at least 𝑛 − 𝑡 ′ proposals have been
decided, which can be optimized through a democratic consensus
protocol [12, 13, 15, 34]. Finally, after 𝑛 − 𝑡 ′ proposals are decided
upon, the participants execute an iteration of a random beacon that
tolerates 𝑡 ′ < 𝑛′/3 Byzantine faults [17, 30, 37], in order to select
the winner of the baiting reward randomly from among any of the
valid candidates that were in any of the decided proposals.
Following the winner consensus, in line 40, fraudsters are pun-
ished and the baiter is rewarded, respectively. The call to resolve(...)
resolves the two disagreeing predecisions by deterministically
choosing one of them (i.e., lexicographical order) or, depending
on the application, merging both.
Resolving a disagreement on consensus predecisions with
BFTCR. It is clear that if there is no disagreement on the predeci-
sions, the BFTCR phase will terminate and satisfy consensus. We
consider here the output of the BFTCR phase in the case where there
Algorithm 1 BFT commit-reveal protocol for (correct) player 𝑖
1: State:
2: enc_msgs, list of delivered encrypted messages from the first group reliable
3: broadcasts, initially ∅
4: list_enc_msgs, list of delivered encrypted messages by other players from the
5: first group of reliable broadcasts, initially ∅
6: decrypted_msgs, list of delivered decrypted messages from the first group of
7: reliable broadcasts, initially ∅
8: {RB1𝑗 }𝑛𝑗=0 , the first group of reliable broadcasts where 𝑗 is the source
9: {RB2𝑗 }𝑛𝑗=0 , the second group of reliable broadcasts where 𝑗 is the source
10: hashes, a dictionary where keys are hashes and values are integers, initially it
11: does not contain any key or value
12: local_hash, local hash of the predecided value, according to this player
13: POF_received, boolean, initially False
14: 𝑖, 𝑖_msg, 𝑖_key, 𝑖_enc_msg, player’s id, message, key, and encrypted message
15: RB1𝑖 .start(i_enc_msg) � start first group of reliable broadcasts
16: Upon RB-delivering enc_msg from reliable broadcast RB1𝑗 :
17: enc_msgs [ 𝑗 ] ← enc_msg𝑠
18: if (size(enc_msgs) ≥ 𝑛 − 𝑡0) then
19: RB2𝑖 .start(enc_msgs)
20: Upon RB-delivering enc_msgsj from reliable broadcast 𝑅𝐵2
𝑗 :
21: list_enc_msgs [ 𝑗 ] ← enc_msgsj
22: if (size(list_enc_msgs) ≥ 𝑛 − 𝑡0 and size(enc_msgs) ≥ 𝑛 − 𝑡0) then
23: broadcast(i_key, i) � reveal 𝑖’s commitment by broadcasting decryption key
24: Upon delivering key from 𝑗 and RB-delivering from RB1𝑗 and RB2𝑗 :
25: broadcast(key, j)
26: decrypted_msgs [j ] ← decrypt(enc_msgs, key) � decrypt it
27: if (decrypted_msgs [j ] .type = HASH) then � if it is the hash of a predecision
28: hash← decrypted_msgs [j ] .get_hash()
29: hashes [hash] += 1 � add to count
30: if (hashes [hash] ≥ 𝑛 − 𝑡0 and local_hash = hashes [hash]) then
31: decide(hash) � if count for this hash reaches threshold, then decide it
32: else if (decrypted_msgs [j ] .type = POFS) then � if instead list of PoFs
33: PoFs← decrypted_msgs [j ] .get_PoFs()
34: if (verify(PoFs)) then list_PoFs [j ] ← PoFs � verify PoFs are valid
35: POF_received ← True
36: if (POF_received) then
37: msgs_filtered ← keys(decrypted_msgs) \ keys(PoFs)
38: if (size(msgs_filtered) ≥ 𝑡0 + 1) then � winner consensus
39: baiter, frauds, predec1 predec2 ← select_winner(list_enc_msgs, lPoFs)
40: punish(frauds) ; reward(baiter) ; resolve(predec1, predec2)
is a disagreement into two predecisions. We speak of a disagree-
ment on predecisions being finalized if it becomes a disagreement
on decisions (that is, on the output of the BFTCR phase). We will
show in Theorem 4.2 that if𝑚 > 𝑘+𝑡−𝑛
2 +𝑡0 rational players commit
to bait instead of finalizing the disagreement on predecisions, then
the Trap protocol still satisfies consensus. For this purpose, we
define𝑚(𝑘, 𝑡) = ⌊ 𝑘+𝑡−𝑛2 + 𝑡0⌋ + 1 (i.e., the smallest natural value
that satisfies𝑚 > 𝑘+𝑡−𝑛
2 + 𝑡0). Then, we first show in Lemma 4.1
that if𝑚(𝑘, 𝑡) rational players bait, then the only possible outcome
is to resolve a disagreement on predecisions.
Lemma 4.1. Let 𝑛 players play the associated game of the Trap
protocol #»𝜎 , out of which 𝑘 can be rational and 𝑡 Byzantine, with
𝑛 > 2(𝑘+𝑡). Suppose a run in which a coalition causes a disagreement
on predecisions, and consider the start of the BFTCR phase. Then, if
𝑚(𝑘, 𝑡) rational players of the coalition commit to bait then the only
possible outcome is to pay the reward and resolve the disagreement
on predecisions.
Proof. First, we show that𝑚(𝑘, 𝑡) deviating players committing
to bait suffices to prevent the disagreement on predecisions to be
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
176
finalized in a disagreement on decisions. This is analogous to the
proof of Lemma 3.1. Then, we show that if𝑚(𝑘, 𝑡) players commit to
bait, then the BFTCR phase safely terminates resolving predecisions,
with all correct players that start the winner consensus terminating
it and agreeing. Finally, we show that deviating players cannot
get the reward and also cause a disagreement, i.e., if one player
terminates the winner consensus then all correct players start it.
Suppose two predecisions 𝑣𝐴, 𝑣𝐵 that two partitions of players
not in the coalition 𝐴 and 𝐵 predecided, such that 𝐴 ∩ 𝐵 = ∅, and
|𝐴| + |𝐵 | +𝑘 +𝑡 ≤ 𝑛. For𝐴 to decide 𝑣𝐴 (resp. 𝐵 to decide 𝑣𝐵 ), players
in𝐴 (resp. 𝐵) must be able to decide without hearing from players in
𝐵 (resp.𝐴). Therefore, |𝐴| +𝑘 +𝑡 ≥ 𝑛−𝑡0 and also |𝐵 | +𝑘 +𝑡 ≥ 𝑛−𝑡0
to finalize the disagreement. We consider now howmany𝑚 rational
players out of 𝑘 must bait (i.e., must not contribute to finalizing
the disagreement) for a disagreement to necessarily fail. This value
must be such that |𝐴| + (𝑘−𝑚)+𝑡 < 𝑛−𝑡0 and same for 𝐵’s partition,
which solves to𝑚 > 𝑘+𝑡−𝑛
2 + 𝑡0 (analogously to Lemma 3.1).
Then, we recall that the BFTCR phase resolves predecisions,
rewards and punishes players if at least 𝑡0 + 1 players have been
exposed through PoFs. Thus, every non-deviating player can ignore
messages received from a set containing at least 𝑡0 + 1 players.
All non-deviating players eventually converge to the same set of
detected fraudsters [34], as all correct players broadcast the PoFs
they hear from and update their detected fraudsters accordingly.
As such, let 𝐹 represent the set of detected fraudsters, then for all
|𝐹 | ∈ [𝑡0 + 1, 𝑘 + 𝑡] it follows that 𝑛′/3 > 𝑘 + 𝑡 − |𝐹 | for 𝑛′ = 𝑛 − |𝐹 |,
and thus the winner consensus tolerates deviations from the rest
of rational and Byzantine players not yet detected.
Finally, we show that if the reward is paid, then it is not possible
to cause a disagreement at decision level. We have shown in the
previous paragraph that all non-deviating players that execute the
winner consensus terminate agreeing. We must thus prove that if a
correct player terminates the winner consensus, then no correct
player can terminate deciding a predecision without executing the
winner consensus. Since 𝑛′/3 > 𝑘 + 𝑡 − |𝐹 |, the winner consensus
terminates with the participation of just 2𝑛′/3 players, of which at
least 2𝑛′/3− (𝑘 +𝑡 − |𝐹 |) are correct. Since there are 𝑛−𝑘 −𝑡 correct
players in total, if the winner consensus terminates for some correct
player, then there are at most 𝑐 = 𝑛−𝑘 − 𝑡 − (2𝑛′/3− (𝑘 + 𝑡 − |𝐹 |)) =
(𝑛 − |𝐹 |)/3 correct players that have neither learned about the
disagreement nor executed the winner consensus yet. Thus, for
these remaining correct players to not be able to decide without
executing the winner consensus, it is necessary that 𝑐 + 𝑡 + 𝑘 <
𝑛 − 𝑡0 ⇐⇒ 𝑡 + 𝑘 < 𝑛/2.
Hence, as long as at least 𝑚(𝑘, 𝑡) = ⌊ 𝑘+𝑡−𝑛2 + 𝑡0⌋ + 1 rational
players play the baiting strategy, the only possible outcome is for
one of them to get the reward, and to resolve the disagreement on
predecisions.
□
Theorem 4.2 (baiting-agreement). Let 𝑛 players play the associ-
ated game of the Trap protocol #»𝜎 , of which 𝑘 can be rational and 𝑡
Byzantine, with 𝑛 > 2(𝑘 + 𝑡). Suppose that𝑚(𝑘, 𝑡) = ⌊ 𝑘+𝑡−𝑛2 + 𝑡0⌋ +1
rational players in the coalition play the baiting strategy committing
to bait if they participate in a disagreement on predecisions. Then the
Trap protocol solves rational agreement.
Proof. The proof of 𝑡0-immunity follows from the proof of Poly-
graph’s 𝑡0-immunity and the fact that the additional BFTCR phase
consists of two Byzantine fault tolerant reliable broadcasts and one
additional broadcast per player, terminating each of them if 𝑛 − 𝑡0
players follow the protocol.
For 𝜖-(𝑘, 𝑡)-robustness, it is clear that if there is no disagreement
on predecisions, then rational and correct players are more than
𝑛 − 𝑡0 and thus the protocol terminates and guarantees validity and
agreement. If there is instead a disagreement on predecisions then,
as long as𝑚(𝑘, 𝑡) players commit to bait, by Lemma 4.1 the only
outcome is to pay the reward and resolve the disagreement. □
We show in Theorem 4.2 that, provided𝑚(𝑘, 𝑡) rational players
commit to bait if there is a disagreement in the predecisions, the
Trap protocol solves the rational agreement problem. We only have
left to prove for which values of L and R we can guarantee that the
strategy to bait the coalition strictly dominates that of terminating
a disagreement for at least𝑚(𝑘, 𝑡) rational players in the coalition.
We do this in Section 4.3.
4.3 Financial component: deposits & reward
In this section, we focus on the key idea of this paper: what are the
values required for a deposit per player and a reward to players
for baiting the coalition that make a strong baiting strategy. In
particular, and derived from the BFTCR algorithm of Section 4.1,
we focus on a baiting strategy that at least𝑚(𝑘, 𝑡) rational players
will play in Theorem 4.4. Then, we prove that the proposed Trap
protocol implements rational agreement and is 𝜖-(𝑘, 𝑡)-robust for
𝑛 > 3
2𝑘 + 3𝑡 and 𝑛 > 2(𝑘 + 𝑡) in Theorem 4.5 and Corollary 4.1.
We show in Theorem 4.4 which values of L and R make the
disagreeing strategy a strictly dominated strategy by the baiting
strategy for at least𝑚(𝑘, 𝑡) rational players (i.e., a dominated strat-
egy even if player 𝑖 already knows that𝑚(𝑘, 𝑡) − 1 other players are
also baiting at the time that 𝑖 has to decide whether to bait or not).
In other words, we show in Theorem 4.4 under which values of R
and L such strategy #»[ is a strong (𝑘, 𝑡,𝑚(𝑘, 𝑡))-baiting strategy
that satisfies baiting-dominance and lossfree-reward.
The result of Theorem 4.4 is the key part of the Trap protocol for
two reasons. First, because it shows that the first𝑚−1 baiters do not
even prevent a disagremeent from taking place, and thus if the rest
of 𝑡 +𝑘−(𝑚−1) colluding players want to finalize the disagreement,
they can. Second, because it shows that if𝑚 − 1 players commit
to bait, then the remaining 𝑡 + 𝑘 − (𝑚 − 1) must take the decision
on whether to commit to bait or not independently of what the
rest of them are doing. Thus, this is analogous to a reduction from
the extensive-form game into a normal-form game for this case,
played by the 𝑡 + 𝑘 − (𝑚 − 1) remaining rational and Byzantine
players, in which all rational players’ dominating strategy is to
bait the coalition, regardless of what the rest are doing. Without
this proof, Byzantine players in the coalition could threat rational
players to also bait if they see them baiting, creating a deterrent
and changing the equilibrium of rational players into colluding to
finalize the disagreement.
We first show in Lemma 4.3 that the Trap protocol guarantees
that no player can decide to join the baiting strategy #»[ and become a
valid candidate for the winner consensus after learning that another
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
177
𝑚(𝑘, 𝑡) players played #»[ : they must take that decision before they
know whether𝑚(𝑘, 𝑡) other players will play #»[ or not.
Lemma 4.3. Let 𝑛 players play the associated game of the Trap
protocol #»𝜎 , out of which 𝑘 can be rational and 𝑡 Byzantine, with
𝑛 > 3
2𝑘 + 3𝑡 and 𝑛 > 2(𝑘 + 𝑡). Suppose a run in which a coalition
causes a disagreement on predecisions and players start the BFTCR
phase. Then, deviating player 𝑖 in the coalition cannot become a valid
candidate for the reward unless it commits to bait before it learns that
𝑚(𝑘, 𝑡) other players commit to bait.
Proof. We show that if𝑚(𝑘, 𝑡) rational players in the coalition
play the baiting strategy, becoming valid candidates to win the
reward, then the remaining 𝑘 + 𝑡 − 𝑚(𝑘, 𝑡) cannot obtain valid
PoBs to become candidates of the winner consensus after learning
that𝑚(𝑘, 𝑡) players become candidates. Given that the non-baiting
members of the coalition are trying to finalize a disagreement, they
will still split non-deviating players into two partitions 𝐴 and 𝐵 for
the BFTCR protocol. Hence, we look at how many rational players
must take part in both partitions of the BFTCR protocol. Notice that
|𝐴| + |𝐵 | + 𝑡 +𝑘 ≤ 𝑛, |𝐴| +𝑘 + 𝑡 ≥ 𝑛− 𝑡0 and |𝐵 | +𝑘 + 𝑡 ≥ 𝑛− 𝑡0. Thus,
analogous to how we calculate𝑚 in Lemma 3.1, we have that 𝑐 ≥
(𝑛−𝑡0)− 𝑛−𝑡−𝑘2 is the number of members of the coalition that must
participate in a partition for it to terminate deciding a predecision,
with 𝐴 ∩ 𝐵 = ∅, as their predecisions differ. We are interested in
calculating 𝑐 − 𝑡 , the minimum number of rational players out of
these 𝑐 members of the coalition, this is why we include as many
Byzantine players as possible. Notice also that we want to see how
many rational players must take part in both partitions, meaning
that we are interested in 𝑐 − 𝑡 − 𝑘
2 = (𝑛 − 𝑡0) − 𝑛+𝑡
2 ≥ 𝑚(𝑘, 𝑡) for
𝑛 > 3
2𝑘 + 3𝑡 .
Hence, both partitions will include at least𝑚(𝑘, 𝑡) repeated ra-
tional players. What is left to prove is that if these𝑚(𝑘, 𝑡) players
commit to bait, then by the time they reveal their commitment, the
remaining players cannot collude to try and obtain PoBs to become
valid candidates of the winner consensus too. Since |𝐴|+𝑘+𝑡 ≥ 𝑛−𝑡0
and |𝐵 | + 𝑘 + 𝑡 ≥ 𝑛 − 𝑡0, there are |𝐷 | ≥ 2(𝑛 − 𝑡0) − 2𝑘 − 2𝑡 cor-
rect players that delivered at least𝑚(𝑘, 𝑡) commitments to bait, for
|𝐷 | ≤ |𝐴| + |𝐵 |, if these𝑚(𝑘, 𝑡) repeated rational players commit
to bait. Notice that |𝐷 | ≥ 𝑡0 + 1 for 𝑛 > 2(𝑘 + 𝑡). Then, each of the
𝑚(𝑘, 𝑡) players can wait for 𝑛 − 𝑡0 deliveries of the second reliable
broadcast before revealing their commitment by broadcasting their
key without compromising termination. Thus, we must calculate
for which values of 𝑘 and 𝑡 the remaining players cannot obtain
PoBs to become valid candidates, that is, for which values of 𝑘
and 𝑡 other players that did not bait yet cannot include the new
commitment to bait in 𝑡0 + 1 valid second reliable broadcasts. Since
the remaining set of correct players𝐶 such that |𝐶 | = 𝑛− 𝑡 −𝑘 − |𝐷 |
are |𝐶 | ≥ 𝑛 − 𝑘 − 𝑡 − (2(𝑛 − 𝑡0) − 2𝑘 − 2𝑡), we calculate for which
values of 𝑘 and 𝑡 we have |𝐶 | + 𝑘 + 𝑡 − 𝑡0 ≤ 𝑡0, which results in
𝑛 > 2(𝑘 + 𝑡). This means that the𝑚(𝑘, 𝑡) baiters can be sure that
no deviating player can commit to bait and win the reward without
being a valid candidate for the winner consensus. □
We use the result from Lemma 4.3 to prove lossfree-reward and
baiting-dominance in Theorem 4.4.
Theorem 4.4 (lossfree-reward and baiting-dominance). Let #»𝜎
be the Trap protocol, executed by 𝑛 players of which exactly 𝑘
are rational and 𝑡 Byzantine, for some values of 𝑘, 𝑡 satisfying
𝑛 > max( 32𝑘 + 3𝑡, 2(𝑘 + 𝑡)). Let
#»[ be the strategy in which𝑚(𝑘, 𝑡)
rational players reveal PoFs of the coalition if there is a disagreement
on predecisions. Then, #»[ is a strong baiting strategy if:
(1) each player is required to deposit L = 𝑑 · G, with 𝑑 >
𝑚 (𝑘,𝑡 )
𝑘 (𝑡0−𝑚 (𝑘,𝑡 )+1) , and
(2) the baiting reward R is such that R = 𝑡0L.
Proof. Recall that the gain is split equally among all 𝑘 rational
players in the coalition 𝑔 = G/𝑘 . To guarantee lossfree-reward, the
sum of losses from the coalition must always be equal or greater
than the reward given for the coalition to always lose funds while
failing to disagree, that is 𝑡0L ≥ R ⇐⇒ L ≥ R𝑡0 .
As a result, the baiting strategy #»[ must strictly dominate the
strategy to disagree for rational players, even if a rational player
knows another 𝑚 − 1 other rational players also play the same
strategy #»[ committing to bait. Since the probability of winning the
bait between𝑚 players is uniformly distributed 𝑝 (𝑚) = 1
𝑚 we have
that the utility for a player to play the baiting strategy knowing
that another𝑚(𝑘, 𝑡) − 1 players are playing the same strategy is
𝑝 (𝑚(𝑘, 𝑡))R − 𝑞(𝑚(𝑘, 𝑡))L. If, instead, the player disagrees then
the player’s utility is G
𝑘
. As such, and since Lemma 4.3 shows
that no rational player can become a valid candidate to win the
reward after learning that 𝑚(𝑘, 𝑡) other players commit to bait,
we obtain that #»[ strictly dominates the disagreeing strategy if
𝑝 (𝑚(𝑘, 𝑡))R −𝑞(𝑚(𝑘, 𝑡))L >
G
𝑘
and replacing R by 𝑡0L, and L by
𝑑G we obtain:
𝑑 >
(
𝑘
(
𝑡0𝑝 (𝑚(𝑘, 𝑡)) − 𝑞(𝑚(𝑘, 𝑡))
) )−1
⇔ 𝑑 >
𝑚(𝑘, 𝑡)
𝑘 (𝑡0 −𝑚(𝑘, 𝑡) + 1)
.
As for the reward, 𝑡0L ≥ R for the slashed deposits to always
cover the reward, and thus we set 𝑡0L = 𝑑G𝑡0 = R.
Hence,𝑚(𝑘, 𝑡) will play the baiting strategy (baiting-dominance)
of which one will be rewarded, and the reward will be paid with
the deposits of the fraudsters (lossfree-reward). □
Notice that any two values L and R suffice if they satisfy
𝑝 (𝑚(𝑘, 𝑡))R − 𝑞(𝑚(𝑘, 𝑡))L >
G
𝑘
(1), so that rational players prefer
to bait than to disagree, and 𝑡0L ≥ R (2), so that the reward is
always less than the slashed deposits.
The key to these two equations lies in the trade-off between R
and L, that is: R must be sufficiently big compared to L so that
players prefer to bait than to disagree (Equation 1), but R must be
sufficiently small compared to L so that the slashed deposits can
always pay for the reward (Equation 2).
It is already possible to derive from Theorem 4.4 results for the
number of Byzantine players tolerated for (𝑘 − 𝑡, 𝑡)-robustness,
given a deposit. That is, suppose that #»[ only requires𝑚(𝑘, 𝑡) = 1
rational player to satisfy agreement, and let L = 𝑑 ·𝐺 , then every
coalition of size at least 𝑡0 + 1 players has at least 𝑘 ≥ 𝑡0 + 1 −
𝑡 rational players, and thus the maximum amount of Byzantine
players tolerated for 𝜖-(𝑘 − 𝑡, 𝑡)-robustness is 𝑡 < 𝑡0 + 1 − 1
𝑡0𝑑
. For
example, let us set the deposit L = 𝑑G to 𝑑 = 1
𝑛 , i.e., the total
deposit is D = L · 𝑛 = G, and 𝑛 = 100, it follows that the Trap
protocol is 𝜖-(𝑘 − 𝑡, 𝑡)-robust and 𝑡 ≤ 30. If instead 𝑑 = 1
3𝑛 , then
𝑡 ≤ 24.
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
178
Finally, we gather all results together in Theorem 4.5, and Corol-
lary 4.1.
Theorem 4.5. Let #»𝜎 be the Trap protocol, executed by 𝑛 players
of which 𝑘 are rational and 𝑡 Byzantine, for all values 𝑘, 𝑡 satisfying
𝑛 > max( 32𝑘 + 3𝑡, 2(𝑘 + 𝑡)). Let
#»[ be the strategy in which𝑚(𝑘, 𝑡)
rational players reveal PoFs of the coalition if there is a disagreement
on predecisions. Then, #»[ is a strong (𝑘, 𝑡,𝑚(𝑘, 𝑡))-baiting strategy if:
(1) Each player is required to deposit L = 𝑑 · G, where 𝑑 >
max(𝑘,𝑡 )
( 𝑚 (𝑘,𝑡 )
𝑘 (𝑡0−𝑚 (𝑘,𝑡 )+1)
)
, and
(2) the baiting reward is R = 𝑡0L.
Proof. Theorem 4.2 uses the proof of baiting-agreement from
Lemma 4.1 to show that if𝑚(𝑘, 𝑡) play the baiting strategy in the
event of a disagreement on predecisions, then the Trap protocol
solves the rational agreement problem. Theorem 4.4 shows that
𝑚(𝑘, 𝑡) will play the baiting strategy (baiting-dominance) of which
one will be rewarded, and the reward will be paid with the deposits
of the fraudsters (lossfree-reward).
Finally, we consider all possible values of 𝑘 and 𝑡 analogously to
Theorem 4.4, deriving a value of 𝑑 that holds for all possible values
of 𝑘 and 𝑡 : 𝑑 > max(𝑘,𝑡 )
( 𝑚 (𝑘,𝑡 )
𝑘 (𝑡0−𝑚 (𝑘,𝑡 )+1)
)
. □
Notice that the greater the size of the coalition, the greater 𝑑
must be in order for the protocol to be 𝜖-(𝑘, 𝑡)-robust. However, for
𝑛 > 3
2𝑘 + 3𝑡 and 𝑛 > 2(𝑘 + 𝑡), since for every two rational players
that join the coalition one Byzantine must leave, the coalition that
maximizes the total deposit D = L𝑛 = 𝑑G𝑛 is a coalition of 𝑘 = 1
rational player and 𝑡 = 𝑡0 Byzantine players, and that means 𝑑 >
1
⌈𝑛3 ⌉−1
. Corollary 4.1 shows such particular robustness.
Corollary 4.1. Let #»𝜎 be the Trap protocol. Then #»𝜎 is 𝜖-(𝑘, 𝑡)-
robust for the rational agreement problem for 𝑛 > 3
2𝑘 + 3𝑡 and
𝑛 > 2(𝑘 + 𝑡) if the following predicates hold:
(1) Each player is required to deposit L = 𝑑 · G + 𝛿 , where 𝑑 =
1
⌈𝑛3 ⌉−1
and 𝛿 > 0, and
(2) the baiting reward is R = 𝑡0L.
Thus, there are two possible outcomes for the Trap protocol:
• if the coalition is made by so many rational players that devi-
ating does not compensate the risk of losing their deposits, then the
Trap protocol will provide agreement at predecision level without
paying a reward R, or
• if the coalition has enough Byzantine players to make the
deviation into two predecisions profitable, then enough 𝑚(𝑘, 𝑡)
rational players in the coalition will bait so that the disagreement
on predecisions can safely be resolved and decided, and one rational
player among the baiters will receive a reward R, paid entirely by
the deposits of the rest of the provably fraudulent players.
In both scenarios, theTrap protocol implements rational agreement,
being 𝜖-(𝑘, 𝑡)-robust for 𝑛 > max
(
3
2𝑘 + 3𝑡, 2(𝑘 + 𝑡)
)
.
5 CONCLUSION
In this paper, we showed that rational players help reduce the de-
pendability on correct players to solve the Byzantine consensus
problem. To this end, we introduced a necessary and sufficient
baiting strategy to solve the rational agreement problem—a vari-
ant of the Byzantine consensus problem that also tolerate ratio-
nal players—under partial synchrony. Based on this strategy, we
also proposed Trap, a novel Byzantine consensus protocol among
𝑛 > max
( 3
2𝑘 + 3𝑡, 2(𝑘 + 𝑡)
)
players, where 𝑘 players are rational
and 𝑡 are Byzantine. This protocol tolerates the coordinated devia-
tions of up to 𝑘 rational players and 𝑡 Byzantine players, solving
consensus in the presence of less than 2𝑛/3 correct players. As
future work, it would be interesting to explore whether our bound
𝑛 > max
( 3
2𝑘 + 3𝑡, 2(𝑘 + 𝑡)
)
is tight, and to consider the impact of
non-negligible costs of computation and communication. We are
currently working at reducing our bound to 𝑛 > 3
2𝑘 + 3𝑡 with a
novel VSS scheme.
Acknowledgements
This research is supported under Australian Research Council Fu-
ture Fellowship funding scheme (project number 180100496).
REFERENCES
[1] Ittai Abraham, Danny Dolev, Ivan Geffner, and Joseph Y. Halpern. 2019. Imple-
menting Mediators with Asynchronous Cheap Talk. In Proceedings of the 2019
ACM Symposium on Principles of Distributed Computing. 501–510.
[2] Ittai Abraham, Danny Dolev, Rica Gonen, and Joe Halpern. 2006. Distributed
Computing Meets Game Theory: Robust Mechanisms for Rational Secret Sharing
and Multiparty Computation. In Proceedings of the 25th Annual ACM Symposium
on Principles of Distributed Computing. 53–62.
[3] Ittai Abraham, Danny Dolev, and Joseph Y. Halpern. 2019. Distributed Proto-
cols for Leader Election: A Game-Theoretic Perspective. ACM Transactions on
Economics and Computation 7, 1 (2019).
[4] Ittai Abraham, Philipp Jovanovic, Mary Maller, Sarah Meiklejohn, Gilad Stern,
and Alin Tomescu. 2021. Reaching Consensus for Asynchronous Distributed Key
Generation. In Proceedings of the 2021 ACM Symposium on Principles of Distributed
Computing. 363–373.
[5] Yehuda Afek, Yehonatan Ginzberg, Shir Landau Feibish, and Moshe Sulamy. 2014.
Distributed Computing Building Blocks for Rational Agents. In Proceedings of
the 2014 ACM Symposium on Principles of Distributed Computing. 406–415.
[6] Amitanand S. Aiyer, Lorenzo Alvisi, Allen Clement, Mike Dahlin, Jean-Philippe
Martin, and Carl Porth. 2005. BAR Fault Tolerance for Cooperative Services.
SIGOPS Operating Systems Review 39, 5 (2005), 45–58.
[7] Yackolley Amoussou-Guenou, Bruno Biais, Maria Potop-Butucaru, F Paris, and
Sara Tucci-Piergiovanni. 2020. Rational vs Byzantine Players in Consensus-based
Blockchains. Proceedings of the 19th International Conference on Autonomous
Agents and MultiAgent Systems (2020), 43–51.
[8] Robert J Aumarm. 2016. Acceptable points in general cooperative n-person games.
Contributions to the Theory of Games (AM-40), Volume IV 40 (2016), 287.
[9] Xiaohui Bei, Wei Chen, and Jialin Zhang. 2012. Distributed Consensus Resilient
to Both Crash Failures and Strategic Manipulations. Technical Report 1203.4324.
arXiv.
[10] Elchanan Ben-Porath. 2003. Cheap talk in games with incomplete information.
Journal of Economic Theory 108, 1 (2003), 45–71.
[11] Lorenz Breidenbach, Phil Daian, Florian Tramèr, and Ari Juels. 2018. Enter the
Hydra: Towards Principled Bug Bounties and Exploit-Resistant Smart Contracts.
In 27th USENIX Security Symposium (USENIX Security 18). 1335–1352.
[12] Pierre Civit, Seth Gilbert, and Vincent Gramoli. 2020. Brief Announcement: Poly-
graph: Accountable Byzantine Agreement. In Proceedings of the 34th International
Symposium on Distributed Computing (DISC) (LIPIcs, Vol. 179). 45:1–45:3.
[13] Pierre Civit, Seth Gilbert, and Vincent Gramoli. 2021. Polygraph: Accountable
Byzantine Agreement. In Proceedings of the 2021 IEEE 41st International Conference
on Distributed Computing Systems (ICDCS). 403–413.
[14] Pierre Civit, Seth Gilbert, Vincent Gramoli, Rachid Guerraoui, and Jovan Koma-
tovic. 2022. As easy as ABC: Optimal (A)ccountable (B)yzantine (C)onsensus is
easy!. In Proceedings of the 36th International Parallel and Distributed Processing
Symposium (IPDPS).
[15] Tyler Crain, Vincent Gramoli, Mikel Larrea, and Michel Raynal. 2018. DBFT:
Efficient Leaderless Byzantine Consensus and its Application to Blockchains. In
2018 IEEE 17th International Symposium on Network Computing and Applications
(NCA). 1–8.
[16] Varsha Dani, MahnushMovahedi, Yamel Rodriguez, and Jared Saia. 2011. Scalable
rational secret sharing. In Proceedings of the 30th Annual ACM Symposium on
Principles of Distributed Computing. 187–196.
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
179
[17] Sourav Das, Vinith Krishnan, Irene Miriam Isaac, and Ling Ren. 2021. SPURT:
Scalable Distributed Randomness Beacon with Transparent Setup. Technical Report
2021/100. Cryptology ePrint.
[18] Changyu Dong, Yilei Wang, Amjad Aldweesh, Patrick McCorry, and Aad van
Moorsel. 2017. Betrayal, Distrust, and Rationality: Smart Counter-Collusion
Contracts for Verifiable Cloud Computing. In Proceedings of the 2017 ACM SIGSAC
Conference on Computer and Communications Security. 211–227.
[19] Cynthia Dwork, Nancy Lynch, and Larry Stockmeyer. 1988. Consensus in the
presence of partial synchrony. Journal of the ACM (JACM) 35, 2 (1988), 288–323.
[20] Zahra Ebrahimi, Bryan Routledge, andAriel Zetlin-Jones. 2019. Getting blockchain
incentives right. Technical Report. Carnegie Mellon University.
[21] Michael J Fischer, Nancy A Lynch, and Michael S Paterson. 1985. Impossibility
of distributed consensus with one faulty process. Journal of the ACM (JACM) 32,
2 (1985), 374–382.
[22] Georg Fuchsbauer, Jonathan Katz, and David Naccache. 2010. Efficient Rational
Secret Sharing in Standard Communication Networks. In Proceedings of the 7th
International Conference on Theory of Cryptography (TCC). 419–436.
[23] Oded Goldreich, Silvio Micali, and Avi Wigderson. 2019. How to play any mental
game. In Annual ACM Symposium on Theory of Computing. 307–328.
[24] Adam Groce, Jonathan Katz, Aishwarya Thiruvengadam, and Vassilis Zikas. 2012.
Byzantine Agreement with a Rational Adversary. In Automata, Languages, and
Programming. 561–572.
[25] Adam Groce, Jonathan Katz, Aishwarya Thiruvengadam, and Vassilis Zikas. 2012.
Byzantine Agreement with a Rational Adversary. In Automata, Languages, and
Programming. 561–572.
[26] Joseph Y. Halpern and Xavier Vilaça. 2020. Rational Consensus. Technical Report
2005.10141. arXiv.
[27] Itay Harel, Amit Jacob-Fanani, Moshe Sulamy, and Yehuda Afek. 2020. Consen-
sus in Equilibrium: Can One Against All Decide Fairly?. In 23rd International
Conference on Principles of Distributed Systems (LIPIcs, Vol. 153). 20:1–20:17.
[28] Dominik Harz, Lewis Gudgeon, Arthur Gervais, and William J. Knottenbelt. 2019.
Balance: Dynamic Adjustment of Cryptocurrency Deposits. In Proceedings of
the 2019 ACM SIGSAC Conference on Computer and Communications Security.
1485–1502.
[29] Yuval Heller. 2005. Minority-proof cheap-talk protocol (extended version). Ph. D.
Dissertation. Citeseer.
[30] Eleftherios Kokoris Kogias, Dahlia Malkhi, and Alexander Spiegelman. 2020.
Asynchronous Distributed Key Generation for Computationally-Secure Random-
ness, Consensus, and Threshold Signatures.
[31] A. Kosba, A. Miller, E. Shi, Z. Wen, and C. Papamanthou. 2016. Hawk: The
Blockchain Model of Cryptography and Privacy-Preserving Smart Contracts. In
2016 IEEE Symposium on Security and Privacy (SP). 839–858.
[32] Leslie Lamport, Robert Shostak, and Marshall Pease. 1982. The Byzantine Gen-
erals Problem. ACM Transaction on Programming Languages and Systems 4, 3
(1982), 382–401.
[33] Anna Lysyanskaya and Nikos Triandopoulos. 2006. Rationality and Adversarial
Behavior in Multi-party Computation. In Advances in Cryptology - CRYPTO 2006.
180–197.
[34] Alejandro Ranchal-Pedrosa and Vincent Gramoli. 2021. ZLB: A Blockchain to
Tolerate Colluding Majorities. Technical Report 2007.10541. arXiv.
[35] Peiyao Sheng, Gerui Wang, Kartik Nayak, Sreeram Kannan, and Pramod
Viswanath. 2021. BFT Protocol Forensics. In Proceedings of the 2021 ACM SIGSAC
Conference on Computer and Communications Security. 1722–1743.
[36] Atul Singh, Pedro Fonseca, Petr Kuznetsov, Rodrigo Rodrigues, and Petros Mani-
atis. 2009. Zeno: Eventually Consistent Byzantine-Fault Tolerance. In Proceedings
of the 6th USENIX Symposium on Networked Systems Design and Implementation.
169–184.
[37] Ewa Syta, Philipp Jovanovic, Eleftherios Kokoris Kogias, Nicolas Gailly, Linus
Gasser, Ismail Khoffi, Michael J. Fischer, and Bryan Ford. 2017. Scalable Bias-
Resistant Distributed Randomness. In 2017 IEEE Symposium on Security and
Privacy (SP). 444–460.
[38] Xavier Vilaça, Oksana Denysyuk, and Luís Rodrigues. 2012. Asynchrony and
Collusion in the N-party BAR Transfer Problem. In Structural Information and
Communication Complexity. 183–194.
[39] Xavier Vilaça, João Leitão, and Luís Rodrigues. 2011. N-Party BAR Transfer:
Motivation, Definition, and Challenges. In Proceedings of the 3rd International
Workshop on Theoretical Aspects of Dynamic Distributed Systems.
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
180
𝑡 𝑘 −𝑚 𝑚 𝐴 𝐵
𝐴 ∩ 𝐵 = ∅, partition of correctByzantines
𝑘 rationals,
of which𝑚 bait
➀ predec(𝑣𝐴) ➀ predec(𝑣𝐵 )
➀ 𝑡 + 𝑘 players
lead𝐴 and 𝐵
to disagree
on predecisions
➁ ➁
➁ 𝐴 and 𝐵 cannot
terminate without
hearing from at least
1 of the𝑚 baiters ce
rti
fic
at
e (
𝑣 𝐴
)
cer
tifi
cat
e (𝑣 𝐵
)
➂
➂𝑚 baiters wait to
receive certificates
to construct
proofs-of-fraud
𝑅𝐵 1(enc_pofs(𝑣
𝐴 ,𝑣
𝐵 ) )
𝑅𝐵 1(enc_pofs(𝑣
𝐴 ,𝑣
𝐵 ) )
➃ ➃
➃𝑚 baiters commit
to the encrypted
proofs-of-fraud
𝑅𝐵
2
𝐴
𝑅𝐵
2
𝐵➄
➄𝑚 baiters wait to
confirm they are
valid candidates reveal key
reveal key
➅ ➅
➃ partitions of correct players 𝐴 and 𝐵 (𝑖) discover disagreement,
(𝑖𝑖) select a winner of the reward at random out of the𝑚 baiters,
(𝑖𝑖𝑖) punish the rest of 𝑡 + 𝑘 − 1 deviants, and
(𝑖𝑣) resolve the disagreement on predecisions to agree on decision
Figure 3: Extended example execution of the Trap proto-
col. First, ➀ all 𝑡 Byzantine and 𝑘 rational players collude
to cause a disagreement on the output of the accountable
consensus protocol, resulting in 𝐴 and 𝐵 predeciding differ-
ent outputs. Then, ➁ 𝑚 of the 𝑘 rational players commit
to bait while executing the BFTCR protocol, preventing 𝐴
and 𝐵 from deciding their disagreeing predecisions. As such,
➂ the𝑚 baiters wait until they receive proof of the disagree-
ment on predecisions, to then ➃ commit to the encrypted
PoFs. Finally, ➄ once they deliver as many second reliable
broadcast from 𝐴 and 𝐵 as possible confirming that correct
players delivered their PoFs encrypted commitment, then ➅
the 𝑚 baiters prove the disagreement revealing the proofs-
of-fraud in the BFTCR protocol. Hence, neither 𝐴 nor 𝐵 de-
cide their conflicting predecisions, but instead reward one
of the𝑚 baiters, punish the rest of 𝑡 + 𝑘 − 1 players respon-
sible for the disagreement on predecisions, and resolve the
disagreement, deciding one of 𝑣𝐴 or 𝑣𝐵 , or, depending on the
application, merging both.
A EXTENDED EXAMPLE FIGURE
Figure 3 depicts a slightly extended version of the execution ex-
ample of Figure 1. Similarly to Figure 1, the execution starts with
𝑘 + 𝑡 Byzantine and rational players causing a disagreement on
predecisions. However, now we detail further how the𝑚 baiters
prevent termination of the BFTCR protocol. In particular, by not
committing to a value in the first reliable broadcast of BFTCR, the𝑚
baiters can prevent players in𝐴 and in 𝐵 from terminating in any of
the two partitions. Thus, the𝑚 baiting players wait till they receive
certificates from players in 𝐴 and in 𝐵 in order to construct PoFs.
Then, they wait till they deliver enough values from the second
group reliable broadcasts from players in partitions 𝐴 and 𝐵 that
guarantee that no other Byzantine or rational player can become a
valid candidate once they reveal that they are baiting (as we showed
in the proof of Lemma 4.3). At this point, the𝑚 players reveal their
PoFs by sending the decryption key to their commitment. Then,
players in 𝐴 and 𝐵 can resolve their disagreement on predecisions,
choose a winner of the reward from among the𝑚 valid candidates
at random, and punish the rest of deviating players.
B DISCUSSION: PAYING A REWARD AT NO
COST TO NON-DEVIANTS.
Onemight think that implementing a baiting strategy with a reward
and deposits might not be enough: we need to discourage coalitions
from actually playing the baiting strategy, since the system would
have to pay the reward R, and thus the coalition can effectively
steal some funds from the system. However, if the system can use
the deposited amount L from at least 𝑡0 certified fraudsters in the
coalition to pay for the baiting reward R, then the system does
not lose any funds (lossfree-reward), while obtaining agreement
(baiting-agreement).
Furthermore, notice that if the coalition consists entirely of ra-
tional players then they do not actually play this strong baiting
strategy since, by the definition of strong baiting strategy, they all
individually lose more than they can gain from deviating. Even
if the presence of Byzantine players leads to a baiter being paid,
agreement will still be guaranteed at no cost to non-deviating play-
ers. This leaves the open question of how likely it is that Byzantine
players with unexpected utilities but possibly with the goal to break
the system would be interested in giving their funds for free to ra-
tional players, if it does not cause some damage on non-deviating
players or on the system itself. In other words, with a more refined,
realistic modelling of Byzantine players, it is very likely that the
very correctness of the Trap protocol will be enough of a deter-
rent from deviating, which would lead to agreement directly at the
predecision level.
Session 2A: Blockchain #1 ASIA CCS ’22, May 30–June 3, 2022, Nagasaki, Japan
181
	Abstract
	1 Introduction and Background
	1.1 Our result
	1.2 Related work
	1.3 Roadmap
	2 Preliminaries
	3 Rational Agreement Impossibility without a Baiting Strategy
	4 Trap: Reaching Rational Agreement
	4.1 Overview: consensus with a baiting strategy
	4.2 Baiting component: the BFTCR protocol
	4.3 Financial component: deposits & reward
	5 Conclusion
	References
	A Extended Example Figure
	B Discussion: paying a reward at no cost to non-deviants.