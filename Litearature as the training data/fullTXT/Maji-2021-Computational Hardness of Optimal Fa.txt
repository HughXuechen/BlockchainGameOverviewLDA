Computational Hardness of Optimal Fair Computation: Beyond Minicrypt
Computational Hardness of Optimal Fair
Computation: Beyond Minicrypt
Hemanta K. Maji(B) and Mingyuan Wang
Department of Computer Science, Purdue University, West Lafayette, USA
{hmaji,wang1929}@purdue.edu
Abstract. Secure multi-party computation allows mutually distrusting
parties to compute securely over their private data. However, guarantee-
ing output delivery to honest parties when the adversarial parties may
abort the protocol has been a challenging objective. As a representative
task, this work considers two-party coin-tossing protocols with guaran-
teed output delivery, a.k.a., fair coin-tossing.
In the information-theoretic plain model, as in two-party zero-sum
games, one of the parties can force an output with certainty. In the
commitment-hybrid, any r-message coin-tossing protocol is 1/
√
r-unfair,
i.e., the adversary can change the honest party’s output distribution by
1/
√
r in the statistical distance. Moran, Naor, and Segev (TCC–2009)
constructed the first 1/r-unfair protocol in the oblivious transfer-hybrid.
No further security improvement is possible because Cleve (STOC–1986)
proved that 1/r-unfairness is unavoidable. Therefore, Moran, Naor, and
Segev’s coin-tossing protocol is optimal. However, is oblivious transfer
necessary for optimal fair coin-tossing?
Maji and Wang (CRYPTO–2020) proved that any coin-tossing proto-
col using one-way functions in a black-box manner is at least 1/
√
r-unfair.
That is, optimal fair coin-tossing is impossible in Minicrypt. Our work
focuses on tightly characterizing the hardness of computation assump-
tion necessary and sufficient for optimal fair coin-tossing within Crypto-
mania, outside Minicrypt. Haitner, Makriyannia, Nissim, Omri, Shaltiel,
and Silbak (FOCS–2018 and TCC–2018) proved that better than 1/
√
r-
unfairness, for any constant r, implies the existence of a key-agreement
protocol.
We prove that any coin-tossing protocol using public-key encryption
(or, multi-round key agreement protocols) in a black-box manner must be
1/
√
r-unfair. Next, our work entirely characterizes the additional power
of secure function evaluation functionalities for optimal fair coin-tossing.
We augment the model with an idealized secure function evaluation of
f , a.k.a., the f -hybrid. If f is complete, that is, oblivious transfer is
The research effort is supported in part by an NSF CRII Award CNS–1566499, NSF
SMALL Awards CNS–1618822 and CNS–2055605, the IARPA HECTOR project,
MITRE Innovation Program Academic Cybersecurity Research Awards (2019–2020,
2020–2021), a Ross-Lynn Research Scholars Grant (2021–2022), a Purdue Research
Foundation (PRF) Award (2017–2018), and The Center for Science of Information, an
NSF Science and Technology Center, Cooperative Agreement CCF–0939370.
c© International Association for Cryptologic Research 2021
T. Malkin and C. Peikert (Eds.): CRYPTO 2021, LNCS 12826, pp. 33–63, 2021.
https://doi.org/10.1007/978-3-030-84245-1_2
http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-030-84245-1_2&domain=pdf
https://doi.org/10.1007/978-3-030-84245-1_2
34 H. K. Maji and M. Wang
possible in the f -hybrid, then optimal fair coin-tossing is also possible
in the f -hybrid. On the other hand, if f is not complete, then a coin-
tossing protocol using public-key encryption in a black-box manner in
the f -hybrid is at least 1/
√
r-unfair.
Keywords: Fair computation · Optimal fair coin-tossing ·
Cryptomania · Black-box separation · Hardness of computation
results · Secure function evaluation functionalities
1 Introduction
Secure multi-party computation [31,75] allows mutually distrusting parties to
compute securely over their private data. However, guaranteeing output deliv-
ery to honest parties when the adversarial parties may abort during the pro-
tocol execution has been a challenging objective. A long line of highly influen-
tial works has undertaken the task of defining security with guaranteed out-
put delivery (i.e., fair computation) and fairly computing functionalities [1–
5,10,11,14,33,34,39,60]. This work considers the case when honest parties are
not in the majority. In particular, as is standard in this line of research, the
sequel relies on the representative task of two-party secure coin-tossing, an ele-
gant functionality providing uncluttered access to the primary bottlenecks of
achieving security in any specific adversarial model.
In the information-theoretic plain model, one of the parties can fix the coin-
tossing protocol’s output (using attacks in two-player zero-sum games, or games
against nature [65]). If the parties additionally have access to the commitment
functionality (a.k.a., the information-theoretic commitment-hybrid), an adver-
sary is forced to follow the protocol honestly (otherwise, the adversary risks
being identified), or abort the protocol execution prematurely. Against such
adversaries, referred to as fail-stop adversaries [20], there are coin-tossing proto-
cols [6,12,13,19] where a fail-stop adversary can change the honest party’s output
distribution by at most O(1/
√
r) , where r is the round-complexity of the proto-
col. That is, these protocols are O(1/
√
r)-insecure. In a ground-breaking result,
Moran, Naor, and Segev [61] constructed the first secure coin-tossing protocol in
the oblivious transfer-hybrid [24,67,68] that is O(1/r)-insecure. No further secu-
rity improvements are possible because Cleve [19] proved that O(1/r)-insecurity
is unavoidable; hence, the protocol by Moran, Naor, and Segev is optimal.
Incidentally, all fair computation protocols (not just coin-tossing, see, for
example, [1–5,10,11,14,33,34,39,60]) rely on the oblivious transfer functional-
ity to achieve O (1/r)-insecurity. A fundamental principle in theoretical cryp-
tography is to securely realize cryptographic primitives based on the minimal
computational hardness assumptions. Consequently, the following question is
natural.
Is oblivious transfer necessary for optimal fair computation?
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 35
Towards answering this fundamental research inquiry, recently, Maji and
Wang [59] proved that any coin-tossing protocol that uses one-way functions
in a black-box manner [7,44,69] must incur Ω (1/
√
r)-insecurity. This result
proves the qualitative optimality of the coin tossing protocols of [6,12,13,19]
in Minicrypt [42] because the commitment functionality is securely realizable by
the black-box use of one-way functions [38,62,63]. Consequently, the minimal
hardness of computation assumption enabling optimal fair coin-tossing must be
outside Minicrypt.
Summary of our results. This work studies the insecurity of fair coin-tossing
protocols outside Minicrypt, within (various levels of) Cryptomania [42]. Our
contributions are two-fold.
1. First, we generalize the (fully) black-box separation of Maji and Wang [59]
to prove that any coin-tossing protocol using public-key encryption in a fully
black-box manner must be Ω (1/
√
r)-insecure.
2. Finally, we prove a dichotomy for two-party secure (possibly, randomized out-
put) function evaluation functionalities. For any secure function evaluation
functionality f , either (A) optimal fair coin-tossing exists in the information-
theoretic f -hybrid, or (B) any coin-tossing protocol in the f -hybrid, even
using public-key encryption algorithms in a black-box manner, is Ω (1/
√
r)-
insecure.
Remark 1. In the information-theoretic f -hybrid model, parties have access to a
trusted party faithfully realizing the functionality f . However, this functionality
is realized unfairly. That is, the trusted party delivers the output to the adver-
sary first. If the adversary wants, it can abort the protocol and block the output
delivery to the honest parties. Otherwise, it can also permit the delivery of the
output to the honest parties and continue with the protocol execution. We high-
light that the fair f -hybrid (where the adversary cannot block output delivery to
the honest parties), for any f where both parties influence the output, straight-
forwardly yields perfectly or statistically secure fair coin-tossing protocol.1
Our hardness of computation results hold even for a game-theoretic definition
of fairness as well (which extends to the stronger simulation-based security defi-
nition). Section 1.1 summarizes our contributions. As shown in Fig. 1, our results
1 Suppose f = XOR. In a fair f -hybrid, the adversary cannot block the output delivery
to the honest parties. So, parties input random bits to the f -functionality and agree
on the output. This protocol has 0-insecurity. A similar protocol (using a deter-
ministic extractor for independent small-bias sources) can extract the fair output
from any f where both parties have influence on the output distribution. Consider
the following “collaborative randomness generation” followed by “extraction” pro-
tocol. (a) Invoke (in parallel) a bidirectional influence functionality multiple times
with random inputs. The output of each invocation in not entirely determined by
one of the parties. Consequently, these samples have average min-entropy. (b) Non-
interactively, parties use these fair output samples to extract this entropy to obtain
the (common) fair coin toss (using convolution/XOR, or traversal of an appropriate
expander graph).
36 H. K. Maji and M. Wang
Secure Construction Adversarial Attack
Pessiland
In General:
constant-unfair [37]
Fail-stop Adversary: Fail-stop Adversary:
1/
√
r-unfair [20]
Minicrypt
One-way Functions:
1/
√
r-unfair [6,12,13,19] 1/
√
r-unfair [59]
Cryptomania
Public-key Encryption:
1/
√
r-unfair [This work]
PKE + f -hybrid, f �→ OT:
1/
√
r-unfair [This work]
Oblivious Transfer:
1/r-unfair [61] 1/r-unfair [19]
Fig. 1. The first column summarizes of the most secure fair coin-tossing protocols in
Impagliazzo’s worlds [42]. Corresponding to each of these worlds, the second column
has the best attacks on these fair coin-tossing protocols. All the adversarial attacks are
fail-stop attackers except for the general attack in pessiland.
further reinforce the widely-held perception that oblivious transfer is necessary
for optimal fair coin-tossing. Our work nearly squeezes out the entire remain-
ing space left open in the state-of-the-art after the recent breakthrough of [59],
which was the first advancement on the quality of the attacks on fair coin-tossing
protocols since [20] after almost three decades. However, there are fascinating
problems left open by our work; Sect. 6 discusses one.
Positioning the technical contributions. Information-theoretic lower-
bounding techniques that work in the plain model and also extend to the f -
hybrid are rare. Maji and Wang [59] proved that optimal coin-tossing is impossi-
ble in the information-theoretic model even if parties can access a random oracle.
This work extends the potential-based approach of [59] to f -hybrid information-
theoretic models, such that oblivious transfer is impossible in the f -hybrid and
parties additionally have access to a public-key encryption oracle.
Fig. 2. The Kushilevitz Function [51], where Alice holds input x ∈ {0, 1, 2} and Bob
holds input y ∈ {0, 1, 2}. For example, the output is z0 if x = 0 and y ∈ {0, 1}.
For the discussion below, consider f to be the Kushilevitz function [51] (see
Fig. 2). One cannot realize this function securely in the information-theoretic
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 37
plain model even against honest-but-curious adversaries [9,49,50,57]. Further-
more, oblivious transfer is impossible in the f -hybrid [46,47]. The characterization
of the exact power of making ideal f -invocations is not entirely well-understood.
Invocations of the ideal f -functionality are non-trivially useful. For example,
one can realize the commitment functionality in the f -hybrid model [58] (even
with Universally Composable (UC) security [15,16] against malicious adver-
saries). The f -functionality is also known to securely implement other secure
function evaluation functionalities as well [71]. All these functionalities would
otherwise be impossible to securely realize in the plain model [17,52,66]. Con-
sequently, it is plausible that one can even implement optimal fair coin-tossing
without implementing oblivious transfer in the f -hybrid model.
Our technical contribution is an information-theoretic lower-bounding tech-
nique that precisely characterizes the power of any f -hybrid vis-à-vis its ability
to implement optimal fair coin-tossing. The authors believe that these techniques
shall be of independent interest to characterize the power of performing ideal
f -invocations in general.
1.1 Our Contribution
This section provides an informal summary of our results and positions our
contributions relative to the state-of-the-art. To facilitate this discussion, we need
to introduce a minimalistic definition of coin-tossing protocols. An (r,X)-coin-
tossing protocol is a two-party r-message interactive protocol where parties agree
on the final output ∈ {0, 1}, and the expected output of an honest execution of
the protocol is X. A coin-tossing protocol is ε-unfair if one of the parties can
change the honest party’s output distribution by ε (in the statistical distance).
Maji and Wang [59] proved that the existence of optimal coin-tossing pro-
tocols is outside Minicrypt [42], where one-way functions and other private-
key cryptographic primitives exist (for example, pseudorandom generator [40,
41,43], pseudorandom function [29,30], pseudorandom permutation [55], sta-
tistically binding commitment [62], statistically hiding commitment [38,63],
zero-knowledge proof [32], and digital signature [64,70]). Public-key crypto-
graphic primitives like public-key encryption, (multi-message) key-agreement
protocols, and secure oblivious transfer protocol are in Cryptomania [44] (out-
side Minicrypt). Although the existence of a secure oblivious transfer protocol
suffices for optimal fair coin-tossing, it was unknown whether weaker hardness of
computation assumptions (like public-key encryption and (multi-message) key-
agreement protocols [27]) suffice for optimal fair coin-tossing or not. Previously,
Haitner, Makriyannis, Nissim, Omri, Shaltiel, and Silbak [35,36], for any con-
stant r, prove that r-message coin-tossing protocols imply key-agreement proto-
cols, if they are less than 1/
√
r-insecure.
Result I. Towards this objective, we prove the following result.
Corollary 1 (Separation from Public-key Encryption). Any (r,X)-coin-
tossing protocol that uses a public-key encryption scheme in a fully black-box
manner is Ω (X(1 − X)/
√
r)-unfair.
38 H. K. Maji and M. Wang
We emphasize that X may depend on the message complexity r of the protocol,
which, in turn, depends on the security parameter. For example, consider an
ensemble of fair coin-tossing protocols with round complexity r and expected
output X = 1/r. This result shows a fail-stop adversary that changes the honest
party’s output distribution by 1/r3/2 in the statistical distance.
This hardness of computation result extends to the fair computation of any
multi-party functionality (possibly with inputs) such that the output has some
entropy, and honest parties are not in the majority (using a standard partition
argument). At a high level, this result implies that relying on stronger hardness of
computation assumptions like the existence of public-key cryptography provides
no “fairness-gains” for coin-tossing protocols than only using one-way functions.
This result’s heart is the following relativized separation in the information-
theoretic setting (refer to Theorem 5). There exists an oracle PKEn [56] that
enables the secure public-key encryption of n-bit messages. However, we prove
that any (r,X)-coin-tossing protocol where parties have oracle access to the
PKEn oracle (with polynomial query complexity) is Ω (X(1 − X)/
√
r)-unfair.
This relativized separation translates into a fully black-box separation using
by-now-standard techniques in this field [69]. Conceptually, this black-box sepa-
ration indicates that optimal fair coin-tossing requires a hardness of computation
assumption that is stronger than the existence of a secure public-key encryption
scheme.
Gertner, Kannan, Malkin, Reingold, and Vishwanathan [27] showed that the
existence of a public-key encryption scheme with additional (seemingly innocu-
ous) properties (like the ability to efficiently sample a public-key without know-
ing the private-key) enables oblivious transfer. Consequently, our oracles realiz-
ing public-key encryption must avoid any property enabling oblivious transfer
(even unforeseen ones). This observation highlights the subtlety underlying our
technical contributions. For example, our set of oracles permit testing whether
a public-key or cipher-text is valid or not. Without this test, oblivious transfer
and, in turn, optimal fair coin-tossing is possible. Surprisingly, these test oracles
are also sufficient to rule out the possibility of oblivious transfer.
Since public-key encryption schemes imply key agreement protocols, our
results prove that optimal fair coin-tossing is black-box separated from key agree-
ment protocols as well.
Result II. Let f : X × Y → R
Z be a two-party secure symmetric function
evaluation functionality, possibly with randomized output. The function takes
private inputs x and y from the parties and samples an output z ∈ Z according to
the probability distribution pf (z|x, y). The information-theoretic f-hybrid is an
information-theoretic model where parties have additional access to the (unfair)
f -functionality.
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 39
Observe that if f is the (symmetrized) oblivious transfer functionality,2 then
the Moran, Naor, and Segev protocol [61] is an optimal fair coin-tossing pro-
tocol in the (unfair) f -hybrid. More generally, if f is a functionality such that
there is an oblivious transfer protocol in the f -hybrid, one can emulate the
Moran, Naor, and Segev optimal coin-tossing protocol; consequently, optimal
coin-tossing exists in the f -hybrid. Kilian [47] characterized all functions f such
that there exists a secure oblivious transfer protocol in the f -hybrid, referred to
as complete functions.
Our work explores whether a function f that is not complete may enhance
the security of fair coin-tossing protocols.
Corollary 2 (Dichotomy of Functions). Let f be an arbitrary 2-party sym-
metric function evaluation functionality, possibly with randomized output. Then,
exactly one of the following two statements holds.
1. For all r ∈ N and X ∈ [0, 1], there exists an optimal (r,X)-coin-tossing
protocol in the f-hybrid (a.k.a., O(1/r)-unfair protocol).
2. Any (r,X)-coin-tossing protocol that uses public-key encryption protocols in
a black-box manner in the f-hybrid is Ω (X(1 − X)/
√
r)-unfair.
For example, Corollary 1 is implied by the stronger version of our result by
using a constant-valued f , a trivial function evaluation. For more details, refer
to Theorem 6. In our model, we emphasize that parties can perform an arbitrary
number of f -invocations in parallel in every round.
Let us further elaborate on our results. Consider a function f that has a
secure protocol in the information-theoretic plain model, referred to as triv-
ial functions. For deterministic output, trivial functions’ full characterization
is known [9,49,50,57]. For randomized output, the characterization of trivial
functions is not known currently. Observe that trivial functions are definitely
not complete; otherwise, a secure oblivious transfer protocol shall exist in the
information-theoretic plain model, which is impossible. For every t ∈ N, there
are functions ft such that any secure protocol for ft requires t rounds of interac-
tive communication in the information-theoretic plain model. For the random-
ized output case, the authors know of functions such that |X| = |Y | = 2 and
|Z| = (t+1) that need t-round protocols for secure computation, which is part of
ongoing independent research. Compiling out the ft-hybrid using such a t-round
secure computation protocol allows only for an Θ
(
X(1 − X)/
√
rt
)
-insecurity,
which yields a useless bound for t = Ω (r). Consequently, compiling out the
trivial functions is inadequate.
It is also well-known that functions of intermediate complexity exist [9,49,
50,57], which are neither complete nor trivial (for example, the Kushilevitz func-
tion, refer to Fig. 2). In fact, there are randomized functions (refer to Fig. 3) of
intermediate complexity such that |X| = |Y | = 2 and |Z| = 3 [23].
2 In the symmetrized oblivious transfer functionality, the sender has input (x0, x1) ∈
{0, 1}2, and the receiver has input (b, r) ∈ {0, 1}2. The symmetric oblivious transfer
functionality returns xb ⊕r to both the parties. If the receiver picks r
$←− {0, 1}, then
this functionality hides the receiver’s choice bit b from the sender.
40 H. K. Maji and M. Wang
Fig. 3. A randomized functionality of intermediate complexity with X = Y = {0, 1}
and Z = {0, 1, 2}. For instance, when x = 0 and y = 0, the distribution of the output
over Z is (18/54, 18/54, 18/54), i.e., a uniform distribution over Z.
Our result claims that even an intermediate function f is useless for optimal
fair coin-tossing; it is as useless as one-way functions or public-key encryption.
Therefore, our results’ technical approach must treat each f -hybrid invocation as
one step in the protocol. We highlight that the intermediate functions are useful
in securely realizing other non-trivial functionalities as well [58,71]. However, for
fair coin-tossing, they are useless.
1.2 Prior Works
Deterministic secure function evaluation. In this paper, we focus on two-party
secure function evaluation functionalities that provide the same output to the
parties. Consider a deterministic function f : X × Y → Z. The unfair ideal
functionality implementing f takes as input x and y from two parties and delivers
the output f(x, y) to the adversary. The adversary may choose to block the
output delivery to the honest party, or permit the delivery of the output to the
honest party.
In this document, we consider security against a semi-honest information-
theoretic adversary, i.e., the adversary follows the protocol description honestly
but is curious to find additional information about the other party’s private
input. There are several natural characterization problems in this scenario. The
functions that have perfectly secure protocols in the information-theoretic plain
model, a.k.a., the trivial functions, are identical to the set of decomposable func-
tions [9,50]. For every t ∈ N, there are infinitely many functions that require
t-rounds for their secure evaluation. Interestingly, relaxing the security from
perfect to statistical security, does not change this characterization [49,57].
Next, Kilian [46] characterized all deterministic functions f that enable obliv-
ious transfer in the f -hybrid, the complete functions. Any functions that has an
“embedded OR-minor” (refer to Definition 4) is complete. Such functions, intu-
itively, are the most powerful functions that enable general secure computation
of arbitrary functionalities.
The sets of trivial and complete functions are not exhaustive (for |Z| >
3 [18,48]). There are functions of intermediate complexity, which are neither
trivial nor complete (see, for example, Fig. 2). The power of the f -hybrid, for an
intermediate f , was explored by [71] using restricted forms of protocols.
Randomized secure function evaluation. A two-party randomized function
f(x, y) : X ×Y → R
Z is a function that, upon receipt of the inputs x and y, sam-
ples an output according to the distribution pf (z|x, y) over the samples space Z.
Kilian [47] characterized all complete randomized functions. Any function that
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 41
has an “embedded generalized OR-minor” (refer to Definition 4) is complete.
Recently, [23] characterized functions with 2-round protocols. Furthermore, even
for |X| = |Y | = 2 and |Z| = 3, there are random function evaluations that are
of intermediate complexity [23].
In the field of black-box separation, the seminal work of Impagliazzo and
Rudich [44] first proposed the notion of black-box separation between cryp-
tographic primitives. Since then, there has been many influential works [25–
28,69,72,74] in this line of research. Below, we elaborate on a few works that
are most relevant to us.
Firstly, for the fair coin-tossing in the random oracle model, the work of
Dachman-Soled, Lindell, Mahmoody, and Malkin [21] showed that when the
message complexity is small, random oracle can be compiled away and hence is
useless for fair coin-tossing. In another work, Dachman-Soled, Mahmoody, and
Malkin [22] studied a restricted type of protocols that they called “function-
oblivious” and showed that for this particular type of protocols, random oracles
cannot yield optimal fair coin-tossing. Recently, Maji and Wang [59] resolved
this problem in the full generality. They showed that any r-message coin-tossing
protocol in the random oracle model must be Ω (1/
√
r)-unfair.
In a recent work of Haitner, Nissim, Omri, Shaltiel, and Silbak [36] and
Haitner, Makriyannis, and Omri [35], they proved that, for any constant r, the
existence of an r-message fair coin-tossing protocol that is more secure than
1/
√
r implies the existence of (infinitely often) key agreement protocols.
1.3 Technical Overview
In this section, we present a high-level overview of our proofs. We start by
recalling the proofs of Maji and Wang [59].
Before we begin, we need to introduce the notion of Alice and Bob’s defense
coins. At any instance of the protocol evolution, Alice has a private defense coin
∈ {0, 1}, referred to as the Alice defense coin, which she outputs if Bob aborts
the protocol. Similarly, Bob has a Bob defense coin. When Alice prepares a
next message of the protocol, she updates her defense coin. However, when Bob
prepares a next message of the protocol, Alice’s defense coin remains unchanged.
Analogously, Bob updates his defense coin when preparing his next messages in
the protocol.
Abstraction of Maji and Wang [59] Technique. Consider an arbitrary fair coin-
tossing protocol πO where Alice and Bob have black-box access to some oracle
O. In their setting, O is a random oracle. Let r and X be the message complexity
and the expected output of this protocol. They used an inductive approach to
prove this protocol is (c · X(1 − X)/
√
r)-insecure as follows (c is a universal
constant).
For every possible first message of this protocol, they consider two attacks
(refer to Fig. 4). Firstly, parties can attack by immediately abort upon this first
message. Secondly, parties can defer their attack to the remaining sub-protocol,
42 H. K. Maji and M. Wang
Fig. 4. An intuitive illustration of the approach of Maji and Wang [59].
which has only r−1 messages. Suppose when the first message is mi, the remain-
ing sub-protocol has expected output xi. Additionally, the expectation of Alice
and Bob defense is ai and bi. The effectiveness of the first attack is precisely
|xi − ai| + |xi − bi| ,
where |xi − ai| is the change of Alice’s output if Bob aborts, and analogously,
|xi − bi| is the change of Bob’s output if Alice aborts. On the other hand, by the
inductive hypothesis, we know the effectiveness of the second attack is at least
c · xi(1 − xi)/
√
r − 1.
Now, they employed a key inequality by [45] (refer to Imported Lemma 1) and
show that the maximum of these two quantities is lower bounded by
c√
r
· (
xi(1 − xi) + (xi − ai)2 + (xi − bi)2
)
.
Define potential function Φ(x, a, b) := x(1 − x) + (x − a)2 + (x − b)2. Maji
and Wang noted that if Jensen’s inequality holds, i.e.,
E
i
[Φ(xi, ai, bi)] ≥ Φ
(
E
i
[xi] ,E
i
[ai] ,E
i
[bi]
)
, (1)
then the proof is complete. This is because the overall effectiveness of the attack
is lower bounded by
E
i
[
max
(
|xi − ai| + |xi − bi| , c · xi(1 − xi)/
√
r − 1
)]
(Expectation of the most effective attack)
≥ E
i
[
c√
r
· Φ(xi, ai, bi)
]
(The key inequality of [45])
≥ c√
r
· Φ
(
E
i
[xi] ,E
i
[ai] ,E
i
[bi]
)
(Jensen’s inequality)
≥ c√
r
· X(1 − X). (∵ E
i
[xi] = X)
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 43
To prove Eq. 1, they noted that Φ(x, a, b) could be rewritten as
Φ(x, a, b) = x + (x − a − b)2 − 2ab.
Observe that x and (x−a−b)2 are convex functions, and hence Jensen’s inequal-
ity holds. The only problematic term is ab. To resolve this, they noted that
suppose we have the following guarantee.
Conditioned on the partial transcript,
Alice private view and Bob private view are (close to) independent.3
Then we shall have E
i
[aibi] ≈ E
i
[ai] E
i
[bi] (refer to Claim 1).4 Consequently,
Eq. 1 shall hold and the proof is done.
Note that the argument thus far is oblivious to the fact that the oracle in
use is a random oracle. For any oracle O, if we have the guarantee above, this
proof will follow.
In particular, when the oracle in use is the random oracle, Maji and Wang
observed that, standard techniques (namely, the heavy querier [8]) do ensure
that Alice private view and Bob private view are (close to) independent. This
completes their proof.
Extending to f-hybrid. When f is a complete function, one can build oblivious
transfer protocol in the f -hybrid model and, consequently, by the MNS proto-
col [61], optimal fair coin-tossing does exist in the f -hybrid model.
On the other hand, if f is not complete, Kilian [47] showed that f must satisfy
the cross product rule (refer to Definition 4). This implies that conditioned on
the partial transcript, which includes ideal calls to f , Alice and Bob private view
are (perfectly) independent (refer to Lemma 3). Therefore, the proof strategy of
Maji and Wang [59] is applicable.
Extending to Public-key Encryption. Our proof for the public-key encryption
follows from the ideas of Mahmoody, Maji, and Prabhakaran [56]. First, we
define a collection of oracles PKEn (refer to Sect. 5.1), with respect to which
public-key encryption exists. To prove that optimal fair coin-tossing protocol
does not exist, it suffices to ensure that Alice and Bob private view are (close
to) independent. However, since with the help of PKEn oracle, Alice and Bob can
agree on a secret key such that a third party, Eve, who sees the transcript and
may ask polynomially many queries to the oracle, cannot learn any information
about the key. It is impossible to ensure the independence of the private views
by only invoking a public algorithm.
To resolve this, [56] showed that one could compile any protocol π in the
PKEn oracle to be a new protocol π′ in the PKEn oracle where parties never
3 For a joint distribution (X,Y ), one may measure the closeness of X and Y being
independent by the statistical distance between (X,Y ) and X × Y .
4 In particular, if Alice private view and Bob private view are perfectly independent,
we shall have E
i
[aibi] = E
i
[ai] E
i
[bi].
44 H. K. Maji and M. Wang
query the decryption oracle (refer to Imported Theorem 1). This compiler sat-
isfies that given a local view of Alice (resp., Bob) in protocol π, one could simu-
late the local view of Alice (resp., Bob) in protocol π′ and vice versa. Therefore,
instead of considering a fair coin-tossing protocol in the PKEn oracle model, one
could consider a fair coin-tossing protocol in the PKEn oracle model where par-
ties never query the decryption oracle. And [56] showed that, when the parties
do not call the decryption oracle, there does exist a public algorithm, namely the
common information learner, who can find all the correlation between Alice and
Bob (refer to Imported Theorem 2). And conditioned on the partial transcript
with the additional information from the common information learner, Alice and
Bob private view are (close to) independent. Therefore, we can continue with
the proof-strategy of Maji and Wang [59].
2 Preliminaries
For a randomized function f : X → Y, we shall use f(x; s) for f evaluated with
input x and randomness s.
We use uppercase letters for random variables, (corresponding) lowercase
letters for their values, and calligraphic letters for sets. For a joint distribution
(A,B), A and B represent the marginal distributions, and A × B represents
the product distribution where one samples from the marginal distributions A
and B independently. For two random variables A and B distributed over a
(discrete) sample space Ω, their statistical distance is defined as SD (A,B) := 1
2 ·∑
ω∈Ω |Pr[A = w ] − Pr[B = w ]| .
For a sequence (X1,X2, . . .), we use X≤i to denote the joint distribution
(X1,X2, . . . , Xi). Similarly, for any (x1, x2, . . . ) ∈ Ω1 × Ω2 × · · ·, we define
x≤i := (x1, x2, . . . , xi) ∈ Ω1 ×Ω2 ×· · ·×Ωi. Let (M1,M2, . . . ,Mr) be a joint dis-
tribution over sample space Ω1×Ω2×· · ·×Ωr, such that for any i ∈ {1, 2, . . . , n},
Mi is a random variable over Ωi. A (real-valued) random variable Xi is said to be
M≤i measurable if there exists a deterministic function f : Ω1×· · ·×Ωi → R such
that Xi = f(M1, . . . ,Mi). A random variable τ : Ω1 × · · · × Ωr → {1, 2, . . . , r}
is called a stopping time, if the random variable 1τ≤i is M≤i measurable, where
1 is the indicator function. For a more formal treatment of probability spaces,
σ-algebras, filtrations, and martingales, refer to, for example, [73].
The following inequality shall be helpful for our proof.
Theorem 1 (Jensen’s inequality). If f is a multivariate convex function,
then E [f (X)] ≥ f (E[X ]), for all probability distributions X over the domain
of f .
In particular, f(x, y, z) = (x − y − z)2 is a tri-variate convex function where
Jensen’s inequality applys.
3 Fair Coin-Tossing Protocol in the f-hybrid Model
Let f : X ×Y → Z be an arbitrary (possibly randomized) function. As standard
in the literature, we shall restrict to f such that the input domain X and Y and
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 45
the range Z are of constant size. A two-party protocol in the f -hybrid model is
defined as follows.
Definition 1 (f-hybrid Model [15,53]). A protocol between Alice and Bob
in the f-hybrid model is identical to a protocol in the plain model except that
both parties have access to a trusted party realizing f . At any point during the
execution, the protocol specifies which party is supposed to speak.
– Alice/Bob message. If Alice is supposed to speak, she shall prepare her next
message as a deterministic function of her private randomness and the partial
transcript.If Bob is supposed to speak, his message is prepared in a similar
manner.
– Trusted party message. At some point during the execution, the protocol
might specify that the trusted party shall speak next. In this case, the protocol
shall also specify a natural number 	, which indicates how many instances of
f should the trusted party compute. Alice (resp., Bob) will prepare her inputs
x = (x1, . . . , x�) (resp., y = (y1, . . . , y�)) and send it privately to the trusted
party. The trusted party shall compute (f(x1, y1), . . . , f(x�, y�)) and send it
as the next message.
In this paper, we shall restrict to fail-stop adversarial behavior.
Definition 2 (Fail-stop Attacker in the f-hybrid Model). A fail-stop
attacker follows the protocol honestly and might prematurely abort. She might
decide to abort when it is her turn to speak. Furthermore, during the trusted
party message, she shall always receive the trusted party message first and, based
on this message, decide whether to abort or not. If she decides to abort, this
action prevents the other party from receiving the trusted party message.
In particular, we shall focus on fair coin-tossing protocols in the f -hybrid model.
Definition 3 (Fair Coin-tossing in the f-hybrid Model). An (X0, r)-fair
coin-tossing in the f-hybrid model is a two-party protocol between Alice and Bob
in the f-hybrid model such that it satisfies the following.
– X0-Expected Output. At the end of the protocol, parties always agree on
the output ∈ {0, 1} of the protocol. The expectation of the output of an honest
execution is X0 ∈ (0, 1).
– r-Message Complexity. The total number of messages of the protocol is
(at most) r. This includes both the Alice/Bob message and the trusted party
message.
– Defense Preparation. Anytime a party speaks, she shall also prepare a
defense coin based on her private randomness and the partial transcript. Her
latest defense coin shall be her output when the other party decides to abort.
To ensure that parties always have a defense to output, they shall prepare a
defense before the protocol begins.
– Insecurity. The insecurity is defined as the maximum change a fail-stop
adversary can cause to the expectation of the other party’s output.
46 H. K. Maji and M. Wang
For any (randomized) functionality f , Kilian [47] proved that if f does not
satisfy the following cross product rule, f is complete for information-theoretic
semi-honest adversaries. That is, for any functionality g, there is a protocol in
the f -hybrid model that realizes g, which is secure against information-theoretic
semi-honest adversaries. In particular, this implies that there is a protocol in the
f -hybrid model that realizes oblivious transfer.
Definition 4 (Cross Product Rule). A (randomized) functionality f : X ×
Y → Z is said to satisfy the cross product rule if for all x0, x1 ∈ X , y0, y1 ∈ Y,
and z ∈ Z such that
Pr[f(x0, y0) = z ] > 0 and Pr[f(x1, y0) = z ] > 0,
we have
Pr[f(x0, y0) = z ] · Pr[f(x1, y1) = z ] = Pr[f(x1, y0) = z ] · Pr[f(x0, y1) = z ] .
We recall the MNS protocol by Moran, Naor, and Segev [61]. The MNS
protocol makes black-box uses of the oblivious transfer as a subroutine to con-
struct optimal-fair coin-tossing protocols. In particular, their protocol enjoys
the property that any fail-stop attack during the oblivious transfer subroutine is
an entirely ineffective attack. Therefore, the MNS protocol, combined with the
results of Kilian [47], gives us the following theorem.
Theorem 2 ([47,61]). Let f be a (randomized) functionality that is complete.
For any X0 ∈ (0, 1) and r ∈ N
∗, there is an (X0, r)-fair coin-tossing protocol in
the f-hybrid model that is (at most) O(1/r)-insecure against fail-stop attackers.
Remark 2 (On the necessity of the unfairness of f). We emphasize that it is
necessary that in the f -hybrid model, f is realized unfairly. That is, the adver-
sary receives the output of f before the honest party does. If f is realized fairly,
i.e., both parties receive the output simultaneously, it is possible to construct
perfectly-secure fair coin-tossing. For instance, let f be the XOR function. Con-
sider the protocol where Alice samples x
$←− {0, 1}, Bob samples y
$←− {0, 1}, and
the trusted party broadcast f(x, y), which is the final output of the protocol.
Trivially, one can verify that this protocol is perfectly-secure.
Intuitively, the results of Kilian [47] and Moran, Naor, and Segev [61] showed
that when f is a functionality that does not satisfy the cross product rule, a
secure protocol realizing f can be used to construct optimal-fair coin-tossing.
In this work, we complement the above results by showing that when f is a
functionality that does satisfy the cross product rule, a fair coin-tossing protocol
in the f -hybrid model is (qualitatively) as insecure as a fair coin-tossing protocol
in the information-theoretic model. In other words, f is completely useless for
fair coin-tossing. Our results are summarized as the following theorem.
Theorem 3 (Main Theorem for f-hybrid). Let f be a randomized function-
ality that is not complete. Any (X0, r)-fair coin-tossing protocol in the f-hybrid
model is (at least) Ω
(
X0(1−X0)√
r
)
-insecure.
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 47
4 Proof of Theorem 3
4.1 Properties of Functionalities
Let f be a functionality that satisfies the cross product rule. We start by observ-
ing some properties of f . Firstly, let us recall the following definition.
Definition 5 (Function Isomorphism [57]). Let f : X × Y → Z and g : X ×
Y → Z ′ be any two (randomized) functionalities. We say f ≤ g if there exist
deterministic mappings MA : X × Z ′ → Z and MB : Y × Z ′ → Z such that, for
all x ∈ X , y ∈ Y, and randomness s,
MA (x, g(x, y; s)) = MB (y, g(x, y; s))
and
SD (f(x, y) , MA (x, g(x, y))) = 0.
We say f and g are isomorphic (i.e., f ∼= g) if f ≤ g and g ≤ f .
Intuitively, f and g are isomorphic if securely computing f can be realized
by one ideal call to g without any further communication and vise versa. As an
example, the (deterministic) XOR functionality
[
0 1
1 0
]
is isomorphic to
[
0 1
2 3
]
.
Given two isomorphic functionalities f and g, it is easy to see that there is a
natural bijection between protocols in the f -hybrid model and g-hybrid model.
Lemma 1. Let f and g be two functionalities such that f ∼= g. For every fair
coin-tossing protocol π in the f-hybrid model, there is a fair coin-tossing protocol
π′ in the g-hybrid model such that
– π and π′ have the same message complexity r and expected output X0.
– For every fail-stop attack strategy for π, there exists a fail-stop attack strategy
for π′ such that the insecurities they cause are identical and vice versa.
Proof (Sketch). Given any protocol π in the f -hybrid model between A and B,
consider the protocol π′ in the g-hybrid model between A′ and B′. In π′, A′
simply simulates A and does what A does. Except when the trusted party sends
the output of g, A′ uses the mapping MA to recover the output of f and feeds it
to A. B′ behaves similarly. Easily, one can verify that these two protocols have
the same message complexity and expected output. Additionally, for every fail-
stop adversary A∗ for π, there is a fail-stop adversary (A∗)′ for π′ that simulates
A∗ in the same manner, which deviates the output of Bob by the same amount.
We are now ready to state our next lemma.
Lemma 2 (Maximally Renaming the Outputs of f). Let f : X × Y → Z
be a (randomized) functionality that is not complete. There exists a functionality
f ′ : X × Y → Z ′ such that f ∼= f ′ and f ′ satisfies the following strict cross
product rule. That is, for all x0, x1 ∈ X , y0, y1 ∈ Y, and z′ ∈ Z ′, we have
Pr[f ′(x0, y0) = z′ ] ·Pr[f ′(x1, y1) = z′ ] = Pr[f ′(x1, y0) = z′ ] ·Pr[f ′(x0, y1) = z′ ] .
48 H. K. Maji and M. Wang
The proof of this lemma follows from standard argument. We refer the reader
to the full version for a complete proof.
Following the example above, the XOR functionality
[
0 1
1 0
]
satisfies the cross
product rule, i.e., XOR is not complete, but it does not satisfy the strict cross
product rule since
Pr[XOR(0, 0) = 1] · Pr[XOR(1, 1) = 1] 
= Pr[XOR(1, 0) = 1] · Pr[XOR(0, 1) = 1] .
On the other hand, functionality
[
0 1
2 3
]
is isomorphic to XOR and does satisfy
the strict cross product rule.
By Lemma 1, the insecurity of a fair coin-tossing protocol in the f -hybrid
model is identical to a fair coin-tossing protocol in the f ′-hybrid model when
f ∼= f ′. Therefore, in the rest of this section, without loss of generality, we
shall always assume f is maximally renamed according to Lemma 2 such that it
satisfies the strict cross product rule.
4.2 Notations and the Technical Theorem
Let π be an (X0, r)-fair coin-tossing protocol in the f -hybrid model. We shall use
RA and RB to denote the private randomness of Alice and Bob. We use random
variable Mi to denote the ith message of the protocol, which could be either an
Alice/Bob message or a trusted party message. Let Xi be the expected output
of the protocol conditioned on the first i messages of the protocol. In particular,
this definition is consistent with the definition of X0.
For an arbitrary i, we consider both Alice aborts and Bob aborts the ith
message. Suppose the ith message is Alice’s message. Alice abort means that she
aborts without sending this message to Bob. Conversely, Bob abort means he
aborts in his next message immediately after receiving this message. On the other
hand, if this is a trusted party message, then both a fail-stop Alice and a fail-
stop Bob can abort this message. This prevents the other party from receiving
the message. We refer to the defense output of Alice when Bob aborts the ith
message as Alice’s ith defense. Similarly, we define the ith defense of Bob. Let DA
i
(resp., DB
i ) be the expectation of Alice’s (resp., Bob’s) ith defense conditioned
on the first i messages.
Now, we are ready to define our score function.
Definition 6. Let π be a fair coin-tossing protocol in the f-hybrid model with
message complexity r. Let τ be a stopping time. Let P ∈ {A,B,T} be the party
who sends the last message.5 We define the score function as follows.
Score (π, τ) := E
[
1(τ �=r)∨(P�=A) · ∣
∣Xτ − DA
τ
∣
∣ + 1(τ �=r)∨(P�=B) · ∣
∣Xτ − DB
τ
∣
∣] .
The following remarks, similar to [45,59], provide additional perspectives.
5 We use A, B, and T to stand for Alice, Bob, and the trusted party, respectively.
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 49
Remark 3. 1. In the information-theoretic plain model, for every message of the
protocol, one usually only consider the attack by the sender of this message.
The attack by the receiver, who may abort immediately after receiving this
message, usually is ineffective. This is because the sender is not lagging behind
in terms of the progress of the protocol. However, in the f -hybrid model, we
have trusted party messages, which reveal information regarding both parties’
private randomness. Therefore, both parties’ defenses may lag behind, and
both parties’ attacks could be effective. Hence, in our definition of the score
function, for every message we pick in the stopping time, we consider the
effectiveness of both parties’ attacks.
2. The last message of the protocol is a boundary case of the above argument.
Suppose Alice sends the last message of the protocol, Bob does not have
the opportunity to abort after receiving this message. Similarly, if this is a
Bob message, Alice cannot attack this message. On the other hand, if the
last message is a trusted party message, then both parties could potentially
attack this message. This explains the indicator function in our definition.
3. Finally, given a stopping time τ∗ that witnesses a high score. We can always
find a fail-stop attack strategy that deviates the expected output of the other
party by 1
4 · Score (π, τ∗) in the following way. For Alice, we shall partition
the stopping time τ∗ by considering whether Xτ ≥ DB
τ or not. Similarly,
we partition τ∗ for Bob. These four attacks correspond to either Alice or
Bob favoring either 0 or 1. The quality of these four attacks sums up to
be Score (π, τ∗). Hence, one of these four fail-stop attacks might be at least
1
4 · Score (π, τ∗) effective.
The score function measures the effectiveness of a fail-stop attack corresponds
to a stopping time τ . We are interested in the effectiveness of the most devas-
tating fail-stop attacks. This motivates the following definition.
Definition 7. Let π be a fair coin-tossing protocol in the f-hybrid model. Define
Opt (π) := max
τ
Score (π, τ) .
Now, we are ready to state our main theorem, which shows that the most
devastating fail-stop attack is guaranteed to achieve a high score. In light of the
remarks above, Theorem 4 directly implies Theorem 3.
Theorem 4. For any (X0, r)-fair coin-tossing protocol π in the f-hybrid model,
we have
Opt (π) ≥ Γr · X0 (1 − X0) ,
where Γr :=
√√
2−1
r .
50 H. K. Maji and M. Wang
4.3 Inductive Proof of Theorem 4
In this section, we shall prove Theorem 4 by using mathematical induction on
the message complexity r. Let us first state some useful lemmas.
Firstly, we note that in the f -hybrid model, where f is a (randomized) func-
tionality that satisfies the strict cross product rule, Alice view and Bob view are
always independent conditioned on the partial transcript.
Lemma 3 (Independence of Alice and Bob view). For any i and partial
transcript m≤i, conditioned on this partial transcript, the joint distribution of
Alice and Bob private randomness is identical to the product of the marginal
distribution. That is,
SD
(
(
RA, RB
)∣∣M≤i = m≤i ,
(
RA
∣
∣M≤i = m≤i
) × (
RB
∣
∣M≤i = m≤i
)
)
= 0.
In particular, this lemma implies the following claim.
Claim 1. Let π be an arbitrary fair coin-tossing protocol in the f-hybrid model.
Suppose there are 	 possible first messages, namely, m
(1)
1 ,m
(2)
1 , . . . ,m
(�)
1 , each
happens with probability p(1), p(2), . . . , p(�). Suppose conditioned on the first mes-
sage being M1 = m
(i)
1 , the expected defense of Alice and Bob are d
A,(i)
1 and d
B,(i)
1
respectively. Then we have
�∑
i=1
p(i) · d
A,(i)
1 d
B,(i)
1 = DA
0 · DB
0 .
Lemma 3 and Claim 1 can be proven in a straightforward manner. We omit it
due to space constraint. A proof can be found in the full version. Finally, the
following lemma from [45] shall be helpful as well.
Imported Lemma 1 ([45]). For all P ∈ [0, 1] and Q ∈ [0, 1/2], if P and Q
satisfy that
Q ≤ P
1 + P 2
,
then for all x, α, β ∈ [0, 1], we have
max (P · x(1 − x) , |x − α| + |x − β|) ≥ Q · (
x(1 − x) + (x − α)2 + (x − β)2
)
.
In particular, for any integer r ≥ 1, the constraints are satisfied, if we set P = Γr
and Q = Γr+1, where Γr :=
√√
2−1
r .
Base case: r = 1. We are now ready to prove Theorem 4. Let us start with
the base case. In the base case, the protocol consists of only one message. Recall
that the last message of the protocol is a boundary case of our score function.
It might not be the case that both parties can attack this message. Hence, we
prove it in different cases.
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 51
Case 1: Alice message. Suppose this message is an Alice message. In this case,
we shall only consider the attack by Alice. By definition, with probability X0,
Alice will send a message, conditioned on which the output shall be 1. And with
probability 1 − X0, Alice will send a message, conditioned on which the output
shall be 0. On the other hand, the expectation of Bob’s defense will remain the
same as DB
0 . Therefore, the maximum of the score shall be
X0 · ∣
∣1 − DB
0
∣
∣ + (1 − X0) · ∣
∣0 − DB
0
∣
∣ ,
which is
≥ X0 (1 − X0) .
In particular, this is
≥ Γ1 · X0 (1 − X0) .
Case 2: Bob message. This case is entirely analogous to case 1.
Case 3: Trusted party message. In this case, we shall consider the effectiveness
of the attacks by both parties. Suppose there are 	 possible first message by
the trusted party, namely, m
(1)
1 ,m
(2)
1 , . . . ,m
(�)
1 , each happens with probability
p(1), p(2), . . . , p(�). Conditioned on first message being M1 = m
(i)
1 , the output of
the protocol is x
(i)
1 . We must have x
(i)
1 ∈ {0, 1} since the protocol has ended and
parties shall agree on the output. Furthermore, let the expected defense of Alice
and Bob be d
A,(i)
1 and d
B,(i)
1 . Therefore, the maximum of the score will be
�∑
i=1
p(i) ·
(∣
∣
∣x(i)
1 − d
A,(i)
1
∣
∣
∣ +
∣
∣
∣x(i)
1 − d
B,(i)
1
∣
∣
∣
)
.
We have
�∑
i=1
p(i) ·
(∣
∣
∣x(i)
1 − d
A,(i)
1
∣
∣
∣ +
∣
∣
∣x(i)
1 − d
B,(i)
1
∣
∣
∣
)
≥
�∑
i=1
p(i) ·
(
x
(i)
1
(
1 − x
(i)
1
)
+
(
x
(i)
1 − d
A,(i)
1
)2
+
(
x
(i)
1 − d
B,(i)
1
)2
)
(Since x
(i)
1 ∈ {0, 1})
=
�∑
i=1
p(i) ·
(
x
(i)
1 +
(
x
(i)
1 − d
A,(i)
1 − d
B,(i)
1
)2
− 2d
A,(i)
1 d
B,(i)
1
)
(Identity Transformation)
≥ X0 +
(
X0 − DA − DB
)2 −
�∑
i=1
p(i) · 2d
A,(i)
1 d
B,(i)
1
(Jensen’s inequality on convex function F (x, y, z) := (x − y − z)2)
= X0 +
(
X0 − DA − DB
)2 − 2DA
0 · DB
0 (Claim 1)
52 H. K. Maji and M. Wang
= X0 (1 − X0) +
(
X0 − DA
0
)2
+
(
X0 − DB
0
)2
(Identity Transformation)
≥ X0 (1 − X0)
≥ Γ1 · X0 (1 − X0)
This completes the proof of the base case.
Inductive Step. Suppose the statement is true for message complexity r. Let π
be an arbitrary protocol with message complexity r+1. Suppose there are 	 pos-
sible first messages, namely, m
(1)
1 ,m
(2)
1 , . . . ,m
(�)
1 , each happens with probability
p(1), p(2), . . . , p(�). Conditioned on first message being M1 = m
(i)
1 , the output of
the protocol is x
(i)
1 and the expected defense of Alice and Bob are d
A,(i)
1 and
d
B,(i)
1 respectively. Note that conditioned on the first message being M1 = m
(i)
1 ,
the remaining protocol π(i) becomes a protocol with expected output x
(i)
1 and
message complexity r. By our inductive hypothesis, we have
Opt
(
π(i)
)
≥ Γr · x
(i)
1
(
1 − x
(i)
1
)
.
On the other hand, we could also pick the first message m
(i)
1 as our stopping
time, which yields a score of
∣
∣
∣x(i)
1 − d
A,(i)
1
∣
∣
∣ +
∣
∣
∣x(i)
1 − d
B,(i)
1
∣
∣
∣ .
Therefore, the stopping time that witnesses the largest score yields (at least) a
score of
max
(
Γr · x
(i)
1
(
1 − x
(i)
1
)
,
∣
∣
∣x(i)
1 − d
A,(i)
1
∣
∣
∣ +
∣
∣
∣x(i)
1 − d
B,(i)
1
∣
∣
∣
)
≥Γr+1 ·
(
x
(i)
1
(
1 − x
(i)
1
)
+
(
x
(i)
1 − d
A,(i)
1
)2
+
(
x
(i)
1 − d
B,(i)
1
)2
)
(Imported Lemma 1)
Therefore, Opt (π) is lower bounded by
�∑
i=1
p(i) · Γr+1 ·
(
x
(i)
1
(
1 − x
(i)
1
)
+
(
x
(i)
1 − d
A,(i)
1
)2
+
(
x
(i)
1 − d
B,(i)
1
)2
)
= Γr+1 ·
�∑
i=1
p(i) ·
(
x
(i)
1 +
(
x
(i)
1 − d
A,(i)
1 − d
B,(i)
1
)2
− 2d
A,(i)
1 d
B,(i)
1
)
(Identity Transformation)
≥ Γr+1 ·
(
X0 +
(
X0 − DA − DB
)2 −
�∑
i=1
p(i) · 2d
A,(i)
1 d
B,(i)
1
)
(Jensen’s inequality on convex function F (x, y, z) := (x − y − z)2)
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 53
= Γr+1 ·
(
X0 +
(
X0 − DA − DB
)2 − 2DA
0 · DB
0
)
(Claim 1)
= Γr+1 ·
(
X0 (1 − X0) +
(
X0 − DA
0
)2
+
(
X0 − DB
0
)2)
(Identity Transformation)
≥ Γr+1 · X0 (1 − X0)
This completes the proof of the inductive step.
5 Black-Box Uses of Public-Key Encryption is Useless
for Optimal Fair Coin-Tossing
In this section, we prove that public-key encryption used in a black-boxed manner
shall not enable optimal fair coin-tossing. Our objective is to prove the existence
of an oracle, with respect to which public-key encryption exists, but optimal fair
coin-tossing does not.
5.1 Public-Key Encrytion Oracles
Let n be the security parameter. We follow the work of [56] and define the
following set of functions.
– Gen : {0, 1}n → {0, 1}3n. This function is a random injective function.
– Enc : {0, 1}3n ×{0, 1}n → {0, 1}3n. This function is uniformly randomly sam-
pled among all functions that are injective with respect to the second input.
That is, when the first input is fixed, this function is injective.
– Dec : {0, 1}n × {0, 1}3n → {0, 1}n ∪ {⊥}. This function is the uniquely deter-
mined by functions Gen and Enc as follows. Dec takes as inputs a secret-
key sk ∈ {0, 1}n and a ciphertext c ∈ {0, 1}3n. If there exists a message
m ∈ {0, 1}n such that Enc(Gen(sk),m) = c, define Dec(sk, c) := m. Other-
wise, define Dec(sk, c) := ⊥. Note that such message m, if exists, must be
unique, because Enc is injective with respect to the second input.
– Test1 : {0, 1}3n → {0, 1}. This function is uniquely determined by function
Gen. It takes as an input a public-key pk ∈ {0, 1}3n. If there exists a secret-
key sk ∈ {0, 1}n such that Gen(sk) = pk, define Test1(pk) := 1. Otherwise,
define Test1(pk) := 0.
– Test2 : {0, 1}3n × {0, 1}3n → {0, 1}. This function is uniquely determined by
function Enc. It takes as inputs a public-key pk ∈ {0, 1}3n and a ciphertext
c ∈ {0, 1}3n. If there exists a message m such that Enc(pk,m) = c, define
Test2(pk, c) := 1. Otherwise, define Test2(pk, c) := 0.
We shall refer to this collection of oracles the PKE oracle. Trivially, the PKE
oracle enables public-key encryption. We shall prove that it does not enable
optimally-fair coin-tossing.
54 H. K. Maji and M. Wang
Remark 4. We stress that it is necessary to include the test functions Test1
and Test2. As shown by [27,54], public-key encryption with additional features
could be used to construct oblivious transfer protocols, which, in turn, could be
used to construct optimally-fair coin-tossing protocols [61].[56] proved that with
the test functions Test1 and Test2, Alice’s and Bob’s private views can only be
correlated as a disjoint union of independent views, which is not sufficient to
realize oblivious transfer.We refer the readers to [56] for more details.
5.2 Our Results
We shall prove the following theorem.
Theorem 5 (Main theorem for PKE Oracle). There exists a universal
polynomial p(·, ·, ·, ·) such that the following holds. Let π be any fair coin-tossing
protocol in the PKE oracle model, where Alice and Bob make at most m queries.
Let X0 be the expected output, and r be the message complexity of π. There exists
an (information-theoretic) fail-stop attacker that deviates the expected output of
the other party by (at least)
Ω
(
X0 (1 − X0)√
r
)
.
This attacker shall ask at most p
(
n,m, r, 1
X0(1−X0)
)
additional queries.
It is instructive to understand why Theorem 3 does not imply Theorem 5. One
may be tempted to model the public-key encryption primitive as an idealized
secure function evaluation functionality to prove this implication. The idealized
functionality for public-key encryption delivers sender’s message to the receiver,
while hiding it from the eavesdropper. So, the “idealized public-key encryption”
functionality is a three-party functionality where the sender’s input is delivered
to the receiver; the eavesdropper has no input or output. This idealized effect is
easily achieved given secure point-to-point communication channels, which we
assume in our work. The non-triviality here is that our result is with respect
to an oracle that implements the public-key encryption functionality. An oracle
for public-key encryption is not necessarily used just for secure message passing.
Section 6 has a discussion elaborating the difference between an “ideal function-
ality” and an “oracle implementing the ideal functionality.”
Remark 5. As usual in the literature [21,22,59], we shall only consider instant
protocols. That is, once a party aborts, the other party shall not make any
additional queries to defend, but directly output her current defense coin. We
refer the reader to [21] for justification and more details on this assumption.
In fact, our proof technique is sufficient to prove the following stronger the-
orem.
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 55
Theorem 6. There exists a universal polynomial p(·, ·, ·, ·) such that the follow-
ing holds. Let f be any (randomized) functionality that is not complete. Let π
be any fair coin-tossing protocol in the f-hybrid model where parties have access
to the PKE oracle model. Assume Alice and Bob make at most m queries. Let
X0 be the expected output, and r be the message complexity of π. There exists
an (information-theoretic) fail-stop attacker that deviates the expected output of
the other party by (at least)
Ω
(
X0 (1 − X0)√
r
)
.
This attacker shall ask at most p
(
n,m, r, 1
X0(1−X0)
)
additional queries.
Our proof strategy consists of two steps, similar to that of [56].
1. Given a protocol in the PKE oracle model, we shall first convert it into a
protocol where parties do not invoke the decryption queries. By Imported
Theorem 1 proven in [56], we can convert it in a way such that the insecurity
of these two protocols in the presence of a semi-honest adversary is (almost)
identical. In particular, this ensures that the insecurity of fair coin-tossing
protocol in the presence of a fail-stop adversary is (almost) identical.
2. Next, we shall extend the results of [59], where they proved a fair coin-tossing
protocol in the random oracle model is highly insecure, to the setting of PKE
oracles without decryption oracle. Intuitively, The proof of [59] only relied on
the fact that in the random oracle model, there exists a public algorithm [8]
that asks polynomially many queries and decorrelate the private view of Alice
and Bob. Mahmoody, Maji, and Prabhakaran [56] proved that (summarized as
Imported Theorem 2) the PKE oracles without the decryption oracle satisfies
the similar property. Hence, the proof of [59] extends naturally to this setting.
Together, these two steps prove Theorem 5. The first step is summarized in
Sect. 5.3. The second step is summarized in Sect. 5.4.
5.3 Reduction from PKE Oracle to Image Testable Random Oracle
A (keyed version of) image-testable random oracles is a collection of pairs of
oracles (Rkey, T key) parameterized by a key such that the following holds.
– Rkey : {0, 1}n → {0, 1}3n is a randomly sampled injective function.
– T key : {0, 1}3n → {0, 1} is uniquely determined by function Rkey as follows.
Define T key(β) := 1 if there exists an α ∈ {0, 1}n such that Rkey(α) = β.
Otherwise, define T key(β) = 0.
Observe that the PKE oracle without the decryption oracle Dec is exactly
a (keyed version of) image-testable random oracles with the keys drawn from
{⊥} ∪ {0, 1}3n. If the key is ⊥, it refers to the pair of oracles (Gen,Test1). If the
key ∈ {0, 1}3n, it refers to the pair of oracles (Enc(key, ·),Test2(key, ·)). We shall
refer to the PKE oracle without the decryption oracle Dec as ITRO. We shall
use the following imported theorem, which is implicitly proven in [56].
56 H. K. Maji and M. Wang
Imported Theorem 1 ([56]). There exists a universal polynomial p(·, ·) such
that the following holds. Let π be a fair coin-tossing protocol in the PKE oracle
model. Let X0 and r be the expected output and message complexity. Suppose
Alice and Bob ask (at most) m queries. For any ε > 0, there exists a fair coin-
tossing protocol π′ in the ITRO model such that the following holds.
– Let X ′
0 and r′ be the expected output and message complexity of π′. Then,
r′ = r and |X ′
0 − X0| < ε.
– Parties asks at most p(m, 1/ε) queries in protocol π′.
– For any semi-honest adversary A′ for protocol π′, there exists a semi-honest
adversary A for protocol π, such that the view of A is ε-close to the view of
A′. And vice versa. In particular, this implies that if π′ is α-insecure. π is
(at least) (α − ε)-insecure.
The intuition behind this theorem is the following. To avoid the uses of
decryption oracle, parties are going to help each other decrypt. In more detail,
suppose Alice generates a ciphertext using Bob’s public key. Whenever the prob-
ability that Bob invokes the decryption oracle on this ciphertext is non-negligibly
high, Alice will directly reveal the message to Bob. Hence, Bob does not need
to use the decryption oracle. This shall not harm the security as a semi-honest
Bob can recover the message by asking polynomially many additional queries.
We refer the readers to [56] for more details.
Looking forward, we shall prove that any fair coin-tossing protocol in the
ITRO model is Ω
(
X′
0(1−X′
0)√
r
)
-insecure. By setting ε to be 1/poly for some
sufficiently large polynomial, we shall guarantee that
ε = o
(
X0 (1 − X0)√
r
)
.
This guarantees that the insecurity of the protocol in the PKE oracle model is
(qualitatively) identical to the insecure of the protocol in the ITRO model.
5.4 Extending the Proof of [59] to Image Testable Random Oracle
We first recall the following theorem from [56].
Imported Theorem 2 (Common Information Learner [56]). There exists
a universal polynomial p(·, ·) such that the following holds. Let π be any two-party
protocol in the ITRO model, in which both parties make at most m queries. For
all threshold ε ∈ (0, 1), there exists a public algorithm, called the common infor-
mation learner, who has access to the transcript between Alice and Bob. After
receiving each message, the common information learner performs a sequence of
queries and obtain its corresponding answers from the ITRO. Let Mi denote the
ith message of the protocol. Let Hi denote the sequence of query-answer pairs
asked by the common information learner after receiving the message Mi. Let
Ti be the union of the ith message Mi and the ith common information learner
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 57
message Hi. Let V A
i (resp., V B
i ) denote Alice’s (resp., Bob’s) private view imme-
diately after message Ti, which includes her private randomness, private queries,
and the public partial transcript. The common information learner guarantees
that the following conditions are simultaneously satisfied.
– Cross-product Property. Fix any round i,
E
t≤i←T≤i
[
SD
((
V A
i , V B
i
∣
∣T≤i = t≤i
)
,
(
V A
i
∣
∣T≤i = t≤i
) × (
V B
i
∣
∣T≤i = t≤i
))] ≤ ε.
Intuitively, it states that on average, the statistical distance between (1) the
joint distribution of Alice and Bob’s private view, and (2) the product of
the marginal distributions of Alice’s private views and Bob’s private views is
small.
– Efficient Property. The expected number of queries asked by the common
information learner is bounded by p(m, 1/ε).
This theorem, combined with proof of [59] gives the following theorem.
Theorem 7. There exists a universal polynomial p(·, ·, ·, ·) such that the follow-
ing holds. Let π be a protocol in the ITRO model, where Alice and Bob make at
most m queries. Let X0 and r be the expected output and message complexity.
Then, there exists an (information-theoretic) fail-stop adversary that deviates
the expected output of the other party by
Ω
(
X0 (1 − X0)√
r
)
.
This attacker asks at most p
(
n,m, r, 1
X0(1−X0)
)
additional queries.
Below, we briefly discuss why Imported Theorem 2 is sufficient to prove this
theorem. The full proof is analogous to [59] and the proof of the results in the
f -hybrid model. Hence we omit it here.
On a high level, the proof goes as follows. We prove Theorem 7 by induction.
Conditioned on the first message, the remaining protocol becomes an (r − 1)-
message protocol, and one can apply the inductive hypothesis. For every possible
first message i, we consider whether to abort immediately or defer the attack
to the remaining sub-protocol. By invoking Imported Lemma 1, we obtain a
potential function, which characterizes the insecurity of the protocol with first
message being i. This potential function will be of the form
Φ(xi, ai, bi) = xi(1 − xi) + (xi − ai)2 + (xi − bi)2,
where xi, ai, and bi stands for the expected output, expected Alice defense, and
expected Bob defense, respectively. To complete the proof, [59] showed that it
suffices to prove the following Jensen’s inequality.
E
i
[Φ(xi, ai, bi)] ≥ Φ
(
E
i
[xi] ,E
i
[ai] ,E
i
[bi]
)
.
58 H. K. Maji and M. Wang
To prove this, one can rewrite Φ(x, a, b) as
Φ(x, a, b) = x + (x − a − b)2 − 2ab.
We note that x and (x−a−b)2 are convex functions, and hence Jensen’s inequal-
ity holds. As for the term ab, we shall have
E
i
[aibi] ≈ E
i
[ai] · E
i
[bi]
as long as, conditioned on every possible first message i, Alice’s private view
is (almost) independent to Bob’s private view. This is exactly what Imported
Theorem 2 guarantees except for a small error depending on ε, which we shall
set to be sufficiently small. Therefore, the proof shall follow.
6 Open Problems
In this work, we proved that access to ideal invocations to the secure func-
tion evaluation functionalities like the Kushilevitz function [51] (Fig. 2) does
not enable optimal fair coin-tossing. However, we do not resolve the following
stronger statement. Suppose there exists an oracle relative to which there exists
a secure protocol for the Kushilevitz function. Is optimal fair coin-tossing impos-
sible relative to this oracle?
To appreciate the distinction between these two statements, observe that
there may be additional ways to use the “oracle implementing Kushilevitz func-
tion” than merely facilitating the secure computing of the Kushilevitz function.
More generally, there may be implicit consequences implied by the existence of
such an oracle. For example, “the existence of an efficient algorithm for 3SAT”
not only allows solving 3SAT problems, but it also allows efficiently solving any
problem in PH because the entire PH collapses to P.
This problem is incredibly challenging and one of the major open problems
in this field. The technical tools developed in this paper also bring us closer to
resolving this problem.
References
1. Agrawal, S., Prabhakaran, M.: On fair exchange, fair coins and fair sampling. In:
Canetti, R., Garay, J.A. (eds.) CRYPTO 2013, Part I. LNCS, vol. 8042, pp. 259–
276. Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-40041-4 15
2. Alon, B., Omri, E.: Almost-optimally fair multiparty coin-tossing with nearly three-
quarters malicious. In: Hirt, M., Smith, A. (eds.) TCC 2016, Part I. LNCS, vol.
9985, pp. 307–335. Springer, Heidelberg (2016). https://doi.org/10.1007/978-3-
662-53641-4 13
3. Asharov, G.: Towards characterizing complete fairness in secure two-party compu-
tation. In: Lindell, Y. (ed.) TCC 2014. LNCS, vol. 8349, pp. 291–316. Springer,
Heidelberg (2014). https://doi.org/10.1007/978-3-642-54242-8 13
https://doi.org/10.1007/978-3-642-40041-4_15
https://doi.org/10.1007/978-3-662-53641-4_13
https://doi.org/10.1007/978-3-662-53641-4_13
https://doi.org/10.1007/978-3-642-54242-8_13
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 59
4. Asharov, G., Beimel, A., Makriyannis, N., Omri, E.: Complete characterization
of fairness in secure two-party computation of boolean functions. In: Dodis, Y.,
Nielsen, J.B. (eds.) TCC 2015, Part I. LNCS, vol. 9014, pp. 199–228. Springer,
Heidelberg (2015). https://doi.org/10.1007/978-3-662-46494-6 10
5. Asharov, G., Lindell, Y., Rabin, T.: A full characterization of functions that imply
fair coin tossing and ramifications to fairness. In: Sahai, A. (ed.) TCC 2013. LNCS,
vol. 7785, pp. 243–262. Springer, Heidelberg (2013). https://doi.org/10.1007/978-
3-642-36594-2 14
6. Awerbuch, B., Blum, M., Chor, B., Goldwasser, S., Micali, S.: How to implement
Bracha’s O (log n) byzantine agreement algorithm (1985)
7. Baecher, P., Brzuska, C., Fischlin, M.: Notions of black-box reductions, revisited.
In: Sako, K., Sarkar, P. (eds.) ASIACRYPT 2013, Part I. LNCS, vol. 8269, pp.
296–315. Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-42033-
7 16
8. Barak, B., Mahmoody-Ghidary, M.: Merkle puzzles are optimal - an O(n2)-query
attack on any key exchange from a random oracle. In: Halevi, S. (ed.) CRYPTO
2009. LNCS, vol. 5677, pp. 374–390. Springer, Heidelberg (2009). https://doi.org/
10.1007/978-3-642-03356-8 22
9. Beaver, D.: Perfect privacy for two-party protocols. In: DIMACS (1989)
10. Beimel, A., Lindell, Y., Omri, E., Orlov, I.: 1/p-secure multiparty computa-
tion without honest majority and the best of both worlds. In: Rogaway, P.
(ed.) CRYPTO 2011. LNCS, vol. 6841, pp. 277–296. Springer, Heidelberg (2011).
https://doi.org/10.1007/978-3-642-22792-9 16
11. Beimel, A., Omri, E., Orlov, I.: Protocols for multiparty coin toss with dishon-
est majority. In: Rabin, T. (ed.) CRYPTO 2010. LNCS, vol. 6223, pp. 538–557.
Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-14623-7 29
12. Blum, M.: Coin flipping by telephone - a protocol for solving impossible problems
(1982)
13. Broder, A.Z., Dolev, D.: Flipping coins in many pockets (byzantine agreement on
uniformly random values). In: 25th FOCS, pp. 157–170. IEEE Computer Society
Press, October 1984
14. Buchbinder, N., Haitner, I., Levi, N., Tsfadia, E.: Fair coin flipping: tighter analysis
and the many-party case. In: Klein, P.N. (ed.) 28th SODA, pp. 2580–2600. ACM-
SIAM, January 2017
15. Canetti, R.: Security and composition of multiparty cryptographic protocols. J.
Cryptol. 13(1), 143–202 (2000)
16. Canetti, R.: Universally composable security: a new paradigm for cryptographic
protocols. In: 42nd FOCS, pp. 136–145. IEEE Computer Society Press, October
2001
17. Canetti, R., Kushilevitz, E., Lindell, Y.: On the limitations of universally com-
posable two-party computation without set-up assumptions. In: Biham, E. (ed.)
EUROCRYPT 2003. LNCS, vol. 2656, pp. 68–86. Springer, Heidelberg (2003).
https://doi.org/10.1007/3-540-39200-9 5
18. Chor, B., Kushilevitz, E.: A zero-one law for Boolean privacy (extended abstract).
In: 21st ACM STOC, pp. 62–72. ACM Press, May 1989
19. Cleve, R.: Limits on the security of coin flips when half the processors are faulty
(extended abstract). In: 18th ACM STOC, pp. 364–369. ACM Press, May 1986
20. Cleve, R., Impagliazzo, R.: Martingales, collective coin flipping and discrete control
processes (extended abstract) (1993)
https://doi.org/10.1007/978-3-662-46494-6_10
https://doi.org/10.1007/978-3-642-36594-2_14
https://doi.org/10.1007/978-3-642-36594-2_14
https://doi.org/10.1007/978-3-642-42033-7_16
https://doi.org/10.1007/978-3-642-42033-7_16
https://doi.org/10.1007/978-3-642-03356-8_22
https://doi.org/10.1007/978-3-642-03356-8_22
https://doi.org/10.1007/978-3-642-22792-9_16
https://doi.org/10.1007/978-3-642-14623-7_29
https://doi.org/10.1007/3-540-39200-9_5
60 H. K. Maji and M. Wang
21. Dachman-Soled, D., Lindell, Y., Mahmoody, M., Malkin, T.: On the black-box
complexity of optimally-fair coin tossing. In: Ishai, Y. (ed.) TCC 2011. LNCS,
vol. 6597, pp. 450–467. Springer, Heidelberg (2011). https://doi.org/10.1007/978-
3-642-19571-6 27
22. Dachman-Soled, D., Mahmoody, M., Malkin, T.: Can optimally-fair coin tossing be
based on one-way functions? In: Lindell, Y. (ed.) TCC 2014. LNCS, vol. 8349, pp.
217–239. Springer, Heidelberg (2014). https://doi.org/10.1007/978-3-642-54242-
8 10
23. Data, D., Prabhakaran, M.: Towards characterizing securely computable two-party
randomized functions. In: Abdalla, M., Dahab, R. (eds.) PKC 2018, Part I. LNCS,
vol. 10769, pp. 675–697. Springer, Cham (2018). https://doi.org/10.1007/978-3-
319-76578-5 23
24. Even, S., Goldreich, O., Lempel, A.: A randomized protocol for signing contracts.
In: Chaum, D., Rivest, R.L., Sherman, A.T. (eds.) CRYPTO 1982, pp. 205–210.
Plenum Press, New York (1982)
25. Gennaro, R., Gertner, Y., Katz, J.: Lower bounds on the efficiency of encryption
and digital signature schemes. In: 35th ACM STOC, pp. 417–425. ACM Press,
June 2003
26. Gennaro, R., Trevisan, L.: Lower bounds on the efficiency of generic cryptographic
constructions. In: 41st FOCS, pp. 305–313. IEEE Computer Society Press, Novem-
ber 2000
27. Gertner, Y., Kannan, S., Malkin, T., Reingold, O., Viswanathan, M.: The rela-
tionship between public key encryption and oblivious transfer. In: 41st FOCS, pp.
325–335. IEEE Computer Society Press, November 2000
28. Gertner, Y., Malkin, T., Reingold, O.: On the impossibility of basing trapdoor
functions on trapdoor predicates. In: 42nd FOCS, pp. 126–135. IEEE Computer
Society Press, October 2001
29. Goldreich, O., Goldwasser, S., Micali, S.: How to construct random functions
(extended abstract). In: 25th FOCS, pp. 464–479. IEEE Computer Society Press,
October 1984
30. Goldreich, O., Goldwasser, S., Micali, S.: How to construct random functions. J.
ACM 33(4), 792–807 (1986)
31. Goldreich, O., Micali, S., Wigderson, A.: How to play any mental game or a com-
pleteness theorem for protocols with honest majority. In: Aho, A. (ed.) 19th ACM
STOC, pp. 218–229. ACM Press, May 1987
32. Goldreich, O., Micali, S., Wigderson, A.: Proofs that yield nothing but their validity
or all languages in NP have zero-knowledge proof systems. J. ACM 38(3), 691–729
(1991)
33. Gordon, S.D., Hazay, C., Katz, J., Lindell, Y.: Complete fairness in secure two-
party computation. In: Ladner, R.E., Dwork, C. (eds.) 40th ACM STOC, pp.
413–422. ACM Press, May 2008
34. Gordon, S.D., Katz, J.: Partial fairness in secure two-party computation. In:
Gilbert, H. (ed.) EUROCRYPT 2010. LNCS, vol. 6110, pp. 157–176. Springer,
Heidelberg (2010). https://doi.org/10.1007/978-3-642-13190-5 8
35. Haitner, I., Makriyannis, N., Omri, E.: On the complexity of fair coin flipping.
In: Beimel, A., Dziembowski, S. (eds.) TCC 2018, Part I. LNCS, vol. 11239, pp.
539–562. Springer, Cham (2018). https://doi.org/10.1007/978-3-030-03807-6 20
36. Haitner, I., Nissim, K., Omri, E., Shaltiel, R., Silbak, J.: Computational two-party
correlation: a dichotomy for key-agreement protocols. In: Thorup, M. (ed.) 59th
FOCS, pp. 136–147. IEEE Computer Society Press, October 2018
https://doi.org/10.1007/978-3-642-19571-6_27
https://doi.org/10.1007/978-3-642-19571-6_27
https://doi.org/10.1007/978-3-642-54242-8_10
https://doi.org/10.1007/978-3-642-54242-8_10
https://doi.org/10.1007/978-3-319-76578-5_23
https://doi.org/10.1007/978-3-319-76578-5_23
https://doi.org/10.1007/978-3-642-13190-5_8
https://doi.org/10.1007/978-3-030-03807-6_20
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 61
37. Haitner, I., Omri, E.: Coin flipping with constant bias implies one-way functions.
In: Ostrovsky, R. (ed.) 52nd FOCS, pp. 110–119. IEEE Computer Society Press,
October 2011
38. Haitner, I., Reingold, O.: Statistically-hiding commitment from any one-way func-
tion. In: Johnson, D.S., Feige, U. (eds.) 39th ACM STOC, pp. 1–10. ACM Press,
June 2007
39. Haitner, I., Tsfadia, E.: An almost-optimally fair three-party coin-flipping protocol.
In: Shmoys, D.B. (ed.) 46th ACM STOC, pp. 408–416. ACM Press, May/June
(2014)
40. H̊astad, J.: Pseudo-random generators under uniform assumptions. In: 22nd ACM
STOC, pp. 395–404. ACM Press, May 1990
41. H̊astad, J., Impagliazzo, R., Levin, L.A., Luby, M.: A pseudorandom generator
from any one-way function. SIAM J. Comput. 28(4), 1364–1396 (1999)
42. Impagliazzo, R.: A personal view of average-case complexity. In: Proceedings of
the Tenth Annual Structure in Complexity Theory Conference (1995)
43. Impagliazzo, R., Levin, L.A., Luby, M.: Pseudo-random generation from one-way
functions (extended abstracts). In: 21st ACM STOC, pp. 12–24. ACM Press, May
1989
44. Impagliazzo, R., Rudich, S.: Limits on the provable consequences of one-way per-
mutations. In: 21st ACM STOC, pp. 44–61. ACM Press, May 1989
45. Khorasgani, H.A., Maji, H.K., Wang, M.: Coin tossing with lazy defense: hard-
ness of computation results. Cryptology ePrint Archive, Report 2020/131 (2020).
https://eprint.iacr.org/2020/131
46. Kilian, J.: A general completeness theorem for two-party games. In: 23rd ACM
STOC, pp. 553–560. ACM Press, May 1991
47. Kilian, J.: More general completeness theorems for secure two-party computation.
In: 32nd ACM STOC, pp. 316–324. ACM Press, May 2000
48. Kreitz, G.: A zero-one law for secure multi-party computation with ternary out-
puts. In: Ishai, Y. (ed.) TCC 2011. LNCS, vol. 6597, pp. 382–399. Springer, Hei-
delberg (2011). https://doi.org/10.1007/978-3-642-19571-6 23
49. Künzler, R., Müller-Quade, J., Raub, D.: Secure computability of functions in
the IT setting with dishonest majority and applications to long-term security. In:
Reingold, O. (ed.) TCC 2009. LNCS, vol. 5444, pp. 238–255. Springer, Heidelberg
(2009). https://doi.org/10.1007/978-3-642-00457-5 15
50. Kushilevitz, E.: Privacy and communication complexity. In: 30th FOCS, pp. 416–
421. IEEE Computer Society Press, October/November 1989
51. Kushilevitz, E., Nisan, N.: Communication complexity. Google Scholar Digital
Library Digital Library (1997)
52. Lindell, Y.: Lower bounds for concurrent self composition. In: Naor, M. (ed.) TCC
2004. LNCS, vol. 2951, pp. 203–222. Springer, Heidelberg (2004). https://doi.org/
10.1007/978-3-540-24638-1 12
53. Lindell, Y.: How to simulate it - a tutorial on the simulation proof technique. Tutor.
Found. Cryptogr. 277–346, (2017)
54. Lindell, Y., Omri, E., Zarosim, H.: Completeness for symmetric two-party func-
tionalities - revisited. In: Wang, X., Sako, K. (eds.) ASIACRYPT 2012. LNCS,
vol. 7658, pp. 116–133. Springer, Heidelberg (2012). https://doi.org/10.1007/978-
3-642-34961-4 9
55. Luby, M., Rackoff, C.: How to construct pseudorandom permutations from pseu-
dorandom functions. SIAM J. Comput. 17(2), 373–386 (1988)
https://eprint.iacr.org/2020/131
https://doi.org/10.1007/978-3-642-19571-6_23
https://doi.org/10.1007/978-3-642-00457-5_15
https://doi.org/10.1007/978-3-540-24638-1_12
https://doi.org/10.1007/978-3-540-24638-1_12
https://doi.org/10.1007/978-3-642-34961-4_9
https://doi.org/10.1007/978-3-642-34961-4_9
62 H. K. Maji and M. Wang
56. Mahmoody, M., Maji, H.K., Prabhakaran, M.: On the power of public-key encryp-
tion in secure computation. In: Lindell, Y. (ed.) TCC 2014. LNCS, vol. 8349, pp.
240–264. Springer, Heidelberg (2014)
57. Maji, H.K., Prabhakaran, M., Rosulek, M.: Complexity of multi-party computation
problems: the case of 2-party symmetric secure function evaluation. In: Reingold,
O. (ed.) TCC 2009. LNCS, vol. 5444, pp. 256–273. Springer, Heidelberg (2009).
https://doi.org/10.1007/978-3-642-00457-5 16
58. Maji, H.K., Prabhakaran, M., Rosulek, M.: A zero-one law for cryptographic com-
plexity with respect to computational UC security. In: Rabin, T. (ed.) CRYPTO
2010. LNCS, vol. 6223, pp. 595–612. Springer, Heidelberg (2010). https://doi.org/
10.1007/978-3-642-14623-7 32
59. Maji, H.K., Wang, M.: Black-box use of one-way functions is useless for optimal
fair coin-tossing. In: Micciancio, D., Ristenpart, T. (eds.) CRYPTO 2020, Part II.
LNCS, vol. 12171, pp. 593–617. Springer, Cham (2020). https://doi.org/10.1007/
978-3-030-56880-1 21
60. Makriyannis, N.: On the classification of finite boolean functions up to fairness.
In: Abdalla, M., De Prisco, R. (eds.) SCN 2014. LNCS, vol. 8642, pp. 135–154.
Springer, Cham (2014). https://doi.org/10.1007/978-3-319-10879-7 9
61. Moran, T., Naor, M., Segev, G.: An optimally fair coin toss. In: Reingold, O. (ed.)
TCC 2009. LNCS, vol. 5444, pp. 1–18. Springer, Heidelberg (2009). https://doi.
org/10.1007/978-3-642-00457-5 1
62. Naor, M.: Bit commitment using pseudorandomness. J. Cryptol. 4(2), 151–158
(1991)
63. Naor, M., Ostrovsky, R., Venkatesan, R., Yung, M.: Perfect zero-knowledge argu-
ments for NP using any one-way permutation. J. Cryptol. 11(2), 87–108 (1998)
64. Naor, M., Yung, M.: Universal one-way hash functions and their cryptographic
applications. In: 21st ACM STOC, pp. 33–43. ACM Press, May 1989
65. Papadimitriou, C.H.: Games against nature (extended abstract). In: 24th FOCS,
pp. 446–450. IEEE Computer Society Press, November 1983
66. Prabhakaran, M., Rosulek, M.: Cryptographic complexity of multi-party compu-
tation problems: classifications and separations. In: Wagner, D. (ed.) CRYPTO
2008. LNCS, vol. 5157, pp. 262–279. Springer, Heidelberg (2008). https://doi.org/
10.1007/978-3-540-85174-5 15
67. Rabin, M.O.: How to exchange secrets by oblivious transfer. Technical Memo TR-
81 (1981)
68. Rabin, M.O.: How to exchange secrets with oblivious transfer. Cryptology ePrint
Archive, Report 2005/187 (2005). http://eprint.iacr.org/2005/187
69. Reingold, O., Trevisan, L., Vadhan, S.: Notions of reducibility between crypto-
graphic primitives. In: Naor, M. (ed.) TCC 2004. LNCS, vol. 2951, pp. 1–20.
Springer, Heidelberg (2004).https://doi.org/10.1007/978-3-540-24638-1 1
70. Rompel, J.: One-way functions are necessary and sufficient for secure signatures.
In: 22nd ACM STOC, pp. 387–394. ACM Press, May 1990
71. Rosulek, M., Shirley, M.: On the structure of unconditional UC hybrid protocols.
In: Beimel, A., Dziembowski, S. (eds.) TCC 2018, Part II. LNCS, vol. 11240, pp.
98–126. Springer, Cham (2018). https://doi.org/10.1007/978-3-030-03810-6 4
72. Rudich, S.: The use of interaction in public cryptosystems (extended abstract).
In: Feigenbaum, J. (ed.) CRYPTO 1991. LNCS, vol. 576, pp. 242–251. Springer,
Heidelberg (1992). https://doi.org/10.1007/3-540-46766-1 19
73. Schilling, R.L.: Measures, integrals and martingales (2017)
https://doi.org/10.1007/978-3-642-00457-5_16
https://doi.org/10.1007/978-3-642-14623-7_32
https://doi.org/10.1007/978-3-642-14623-7_32
https://doi.org/10.1007/978-3-030-56880-1_21
https://doi.org/10.1007/978-3-030-56880-1_21
https://doi.org/10.1007/978-3-319-10879-7_9
https://doi.org/10.1007/978-3-642-00457-5_1
https://doi.org/10.1007/978-3-642-00457-5_1
https://doi.org/10.1007/978-3-540-85174-5_15
https://doi.org/10.1007/978-3-540-85174-5_15
http://eprint.iacr.org/2005/187
https://doi.org/10.1007/978-3-540-24638-1_1
https://doi.org/10.1007/978-3-030-03810-6_4
https://doi.org/10.1007/3-540-46766-1_19
Computational Hardness of Optimal Fair Computation: Beyond Minicrypt 63
74. Simon, D.R.: Finding collisions on a one-way street: can secure hash functions
be based on general assumptions? In: Nyberg, K. (ed.) EUROCRYPT 1998.
LNCS, vol. 1403, pp. 334–345. Springer, Heidelberg (1998). https://doi.org/10.
1007/BFb0054137
75. Yao, A.C.-C.: Protocols for secure computations (extended abstract). In: 23rd
FOCS, pp. 160–164. IEEE Computer Society Press, November 1982
https://doi.org/10.1007/BFb0054137
https://doi.org/10.1007/BFb0054137
	Computational Hardness of Optimal Fair Computation: Beyond Minicrypt
	1 Introduction
	1.1 Our Contribution
	1.2 Prior Works
	1.3 Technical Overview
	2 Preliminaries
	3 Fair Coin-Tossing Protocol in the f-hybrid Model
	4 Proof of Theorem 3
	4.1 Properties of Functionalities
	4.2 Notations and the Technical Theorem
	4.3 Inductive Proof of Theorem 4
	5 Black-Box Uses of Public-Key Encryption is Useless for Optimal Fair Coin-Tossing
	5.1 Public-Key Encrytion Oracles
	5.2 Our Results
	5.3 Reduction from PKE Oracle to Image Testable Random Oracle
	5.4 Extending the Proof of ch2C:MajWan20 to Image Testable Random Oracle
	6 Open Problems
	References