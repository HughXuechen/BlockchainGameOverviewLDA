SCIENCE CHINA
Information Sciences
October 2021, Vol. 64 202301:1–202301:21
https://doi.org/10.1007/s11432-019-2858-8
c© Science China Press and Springer-Verlag GmbH Germany, part of Springer Nature 2021 info.scichina.com link.springer.com
. RESEARCH PAPER .
An incentive-compatible rational secret sharing
scheme using blockchain and smart contract
Zerui CHEN1, Youliang TIAN1,2* & Changgen PENG1,2
1State Key Laboratory of Public Big Date, College of Computer Science and Technology, Guizhou University,
Guiyang 550025, China;
2Institute of Cryptography and Data Security, Guizhou University, Guiyang 550025, China
Received 2 December 2019/Revised 14 March 2020/Accepted 18 March 2020/Published online 3 February 2021
Abstract In the rational cryptographic protocol, the two rational players often fall into the prisoner’s
dilemma, which is also the case for the rational secret sharing we consider in this paper. First, it is proved
that rational secret sharing has a sequential equilibrium in the natural state, so that rational participants will
fall into the prisoner’s dilemma, resulting in no participants being able to reconstruct the secret correctly.
Next, to solve this problem, we propose an incentive-compatible rational secret scheme. Specifically, the game
tree with imperfect information is constructed to facilitate our analysis and proof, and the strictly dominated
strategies are directly eliminated to simplify the game tree. Further more, we describe the motivation of the
verifier. Then, we prove that rational players have no motivation to deviate from honest behavior using
sequential equilibrium so that rational players can reconstruct the secret correctly. Finally, we complete the
simulation using the smart contract and analyze our entire scheme. In addition, the game of our scheme
does not need to be repeated multiple times to reach sequential equilibrium, i.e., the game always follows
the rational path.
Keywords rational secret sharing, game theory, sequential equilibrium, incentive-compatible, smart con-
tract
Citation Chen Z R, Tian Y L, Peng C G. An incentive-compatible rational secret sharing scheme using blockchain
and smart contract. Sci China Inf Sci, 2021, 64(10): 202301, https://doi.org/10.1007/s11432-019-2858-8
1 Introduction
In 1979, Blakey [1] and Shamir [2] separately studied the well-known t-out-of-n secret sharing scheme.
Their basic idea is that a dealer who holds a secret divides the secret into n sub-secrets and distributes
the secret shares to n participants, and any t or more participants can reconstruct the secret, while less
than t players cannot. In traditional secret sharing, we think participants are either “good” or “bad”, and
“good” participants are always willing to participate in reconstruction honestly, while “bad” participants
are unwilling to do so. Then Halpern and Teague [3] used the game theory to analyze secret sharing
and put forward rational secret sharing scheme for the first time. Dodis and Rabin [4] pointed out that
the game theory and cryptography can be effectively combined if a reasonable scheme can be designed.
In such circumstances, participants are neither “good” nor “bad”. To be precise, they are rational, i.e.,
their purpose is to maximize their own utility.
1.1 Related work
Halpern and Teague [3] studied the Nash equilibrium that was determined by iterated deletion of weakly-
dominated strategies in rational secret sharing. Then Gordon and Katz [5] extended the scheme [3]
and gave a Nash equilibrium solution with the number of participants n = 2 in rational secret sharing,
however, not all bad strategies can be eliminated. Kol and Naor [6] proposed the strict Nash equilibrium,
but the equilibrium concepts were too difficult to achieve. Fuchsbauer et al. [7] presented computational
*Corresponding author (email: youliangtian@163.com)
http://crossmark.crossref.org/dialog/?doi=10.1007/s11432-019-2858-8&domain=pdf&date_stamp=2021-2-3
https://doi.org/10.1007/s11432-019-2858-8
info.scichina.com
link.springer.com
https://doi.org/10.1007/s11432-019-2858-8
https://doi.org/10.1007/s11432-019-2858-8
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:2
Nash equilibrium stable with respect to trembles, and they allowed the mistakes of the parties. Like the
idea of solving the “repeated prisoner’s dilemma” in [8], some scholars repeated a secret sharing multiple
times, and guaranteed the participants’ honest behavior through an incentive mechanism. For example,
Maleka et al. [9] studied the repeated games model of rational secret sharing scheme. However, repeated
game requires the game to be played multiple times, and if the participants know that they are in the
last sub-game of secret reconstruction, they have no motivation to be honest at this time. Ong et al. [10]
studied the subgame perfect equilibrium, but a small number of honest players should be assumed in
their model.
Besides, Zhang and Liu [11] presented information-theoretic secure rational secret sharing scheme
in a standard communication network. Then, they designed a credible punishment mechanism [12] in
rational secret sharing based on the extensive game. By introducing rational communication players, Tian
et al. [13] proposed a formal framework to solve the problem of interaction among distrusted players.
Then, they studied the utility function of rational players, and presented a new rational secret sharing
scheme [14] based on Bayesian game. Jin et al. [15] proposed a rational secret sharing scheme based
on the reputation mechanism, and their protocol only required one round. By introducing mechanism
design [16] from the field of microeconomics, Liu et al. [17] proposed a reasonable secret reconstruction
protocol in rational secret sharing.
Nakamoto [18] first proposed the data structure of blockchain and a virtual crypto-currency Bitcoin
in 2008, which guaranteed neutralization, undeniableness, uniqueness and traceability. Recently, some
scholars have done work on the combination of blockchain and secret sharing (see [19–22]), and the focus
of their study is on implementing some mechanics of blockchain by using traditional secret sharing. For
example, Bartolucci et al. [20] used secret sharing to enable on-chain and introduced a secret share-based
voting system on the blockchain. However, our study is to achieve an incentive-compatible rational secret
sharing scheme using blockchain and smart contract. In addition, from the study of Dong et al. [23], it
is feasible to realize the incentive mechanism in rational cryptography through smart contracts.
1.2 Our contribution
In fact, we also have the question, once game theory is introduced, how will the traditional secret sharing
protocol analysis be affected? We consider the players in the secret sharing are rational and define a
utility function for each player whose purpose is to maximize his/her own utility. Unfortunately, as
pointed out in [3], no rational player has an incentive to honestly publish his/her secret share during a
secret reconstruction, which results in no player being able to reconstruct the secret, this phenomenon
is called the prisoner’s dilemma in game theory. And as pointed out in [24], certain game-theoretic
equilibria are achievable if a trusted mediator is available, so we introduce an additional trusted verifier.
Until now, a lot of the cryptographic work has been evaluated in terms of game theory. However, many
existing rational secret sharing schemes contain some incredible threats, leading to the Nash equilibrium
is actually unreasonable. Our contributions are mainly as follows.
(1) We propose an incentive-compatible rational secret sharing scheme. Specifically, we redesigned
the process of secret sharing, i.e., the players not only need to send the secret share, but also need to
send the reconstructed secret after reconstructing the secret for verifiability. Note that the players only
need to send the commitment of secret to ensure privacy. Then we design the incentive mechanism and
guarantee the rational players’ honesty in each phase. In addition, we rigorously prove that there is a
unique sequential equilibrium in the game and the game always follows the rational path. More precisely,
we define players’ utility for each step, and then we prove that players have no motivation to deviate
from honest behavior in order to maximize their own utility.
(2) Our research is based on an extensive game rather than a strategic game, which helps us to provide
credible punishment strategies. Moreover, we consider the imperfect information game, which is close to
the reality. Then we eliminate strictly dominated strategies to simplify the game tree that can facilitate
our analysis and proof.
(3) We complete the simulation using the smart contract, which provids the possibility for the appli-
cation of our scheme in realistic secret sharing scenarios. In addition, we analyze our entire scheme and
conclude that the overhead of the smart contract we design and deploy is extremely small.
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:3
n0
n2n1
p1
f g
p1 p1 p1 p1
p2
p2
n3
n7 n8 n9 n10 n11 n12 n13 n14
n4
n5 n6
nyny
l r l r l r l r
u(p1)(        )u(p2)
2(   )1
1(   )1
1(   )0
0(   )0
1(   )1
0(   )0
0(   )1
−1(     )1
Figure 1 GameSample.
2 Preliminaries
In this section, we introduce the extensive game with imperfect information. We review the Nash equi-
librium and introduce a improvement that has strong influence in equilibrium, which we call sequential
equilibrium.
2.1 Game theory
Our paper is based on the extensive game framework. Note that all the games in our paper are finite.
Often in a game, the actions of the players are in order, the players only know the action strategies of
other players, but do not know what actions other players specifically choose. So the extensive game
with imperfect information is closer to reality and has broader practical implications, which is why we
consider it. We construct the game tree to describe the subsequent game. Through the game tree, we
can clearly see the players, nodes, information sets, optional actions, utility functions, etc. of a game.
Definition 1. An extensive game with imperfect information is a G = {P,A,H,E, I,Q, U}, where
• P is a set of players;
• A is a set of players’ actions;
• H is a set of non-terminal selection nodes;
• E is a set of terminal nodes;
• I is information set;
• Q is a set of optional actions of players in the information set;
• U is a set of utility functions.
As shown in Figure 1, we use circles to represent the elements in H , that is, the non-terminal selection
nodes. We use rectangles to represent the elements in E, i.e., the terminal nodes. We use ni to represent
the node number. We also use horizontal lines to represent the nodes reached by the players after the
action is selected, and use dotted lines to connect non-terminal selection nodes at the same information
set. When the terminal node is reached, the player’s utility function is displayed as follows.
• P = {p1, p2} represents the players of the game are p1, p2.
• A = {f, g, y, n, l, r} represents the combination of all the action strategies of all players.
• H = {n0, n1, n2, n3, n4, n5, n6} represents that when the game reaches node n0−n6, the game is still
going on, and the player at the corresponding node must make a choice of action.
• E = {n7, n8, n9, n10, n11, n12, n13, n14} represents that when the game reaches node n7 − n14, the
game ends.
• I = {I11, I12, I13, I21}. The information set of player p1 is I11, I12, I13 where I11 = {n0}, I12 =
{n3, n4}, I13 = {n5, n6}, and the information set of player p2 is I21 where I21 = {n1, n2}. For example,
when the player p2 is at information set I21, he/she cannot know whether he/she is at n1 or n2. In
other words, at this time, he/she only knows that player p1 has made an action at the starting node n0,
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:4
however, he/she cannot know exactly whether p1 has chosen the action f or the action g, which is the
embodiment of imperfect information.
• Q = {Q11, Q12, Q13, Q21}, Q11 = {f, g},Q12 = Q13 = {l, r},Q21 = {y, n} where Q11 is an optional
action when player p1 is at information set I11, Q21 is an optional action when p2 is at I21, Q12 and Q13
are optional actions when p1 is at I12 or I13.
• U = {u7, u8, u9, u10, u11, u12, u13, u14} represents when the game reaches the terminal node n7−n14,
the corresponding utility function is u7 − u14, such as u7 = (2, 1) represents when the game reaches the
terminal node n7, p1 gets utility 2 and p2 gets utility 1. Note that the purpose of rational players is to
maximize their own utility.
Definition 2. In a game G, an optional strategy combination si of player pi means that for ∀Iij ∈ Ii,
we assign probabilities to all optional actions Qij ∈ Qi.
For example, as shown in Figure 1, s1 = ([ 12 (f),
1
2 (g)], [
1
3 (l),
2
3 (r)], [
2
3 (l),
1
3 (r)]) is an optional strategy
combination of players p1, which means that when player p1 arrives at information set I11, he/she selects
action f with probability 1
2 , selects action g with probability 1
2 ; when he/she arrives at information set
I12, he/she selects action l with probability 1
3 , selects action r with probability 2
3 ; when he/she arrives
at information set I12, he/she selects action l with probability 2
3 , selects action r with probability 1
3 .
Definition 3. In a game G, the strategy combination Si of player pi is a set of all optional strategy
combinations of player pi:
Si = (si1, si2, . . . , sin).
Definition 4. In a game G, the strategy profile S of the game means that the Cartesian product is
made on the strategy combinations (S1, S2, . . . , Sn) of all players:
S = S1 × S2 × · · · × Sn,
where n means the number of players.
Definition 5. In a game G, an optional strategy profile s ∈ S of the game means assigning a probability
to all players’ optional actions at all information sets:
s = (si, s−i),
where s−i = (s1, s2, . . . , si−1, si+1, . . . , sn) and n means the number of players.
For example, as shown in Figure 1, s = (s1, s2) is an optional strategy profile of the game. Where
s1 = ([ 12 (f),
1
2 (g)], [
1
3 (l),
2
3 (r)], [
2
3 (l),
1
3 (r)]), s2 = ([0(y), 1(n)]) mean for player p1, when information set
I11 is reached, action f is selected with probability 1
2 and action g is selected with probability 1
2 ; when
information set I12 is reached, action l is selected with probability 1
3 and action r is selected with
probability 2
3 ; when information set I13 is reached, action l is selected with probability 2
3 and action r is
selected with probability 1
3 ; and when player p2 arrives at information set I21, he/she must choose action
n and never choose action y.
2.2 Nash equilibrium and sequential equilibrium
The most important concept in game theory is the Nash equilibrium. However, Nash equilibrium is not
refined in many cases and some Nash equilibrium in the game may actually have incredible threats, and
thus the Nash equilibrium is unreasonable. In order to eliminate these incredible threats and to refine
the Nash equilibrium, some improvements to the Nash equilibrium are needed. Sequential equilibrium is
considered to be a powerful improvement, even with a stricter definition than perfect Bayesian equilibrium.
Definition 6. In a game G, a Nash equilibrium s∗ = (s∗i , s
∗
−i), s
∗ ∈ S refers to the fact that when one
player deviates from the Nash equilibrium, it is impossible for him/her to obtain higher utility.
∀si ∈ Si, ui(si, s
∗
−i) 6 ui(s
∗
i , s
∗
−i).
In other words, when the strategy profile of the game reaches the Nash equilibrium, the strategy
combination of each player is the best response for the given strategy combination of the other players,
and no one can get higher utility by changing his/her own strategy combination.
Sequential equilibrium eliminates bad strategies by requiring that the game is sequential rationality,
that is, it not only achieves optimal results in the final result of the game, but also achieves optimal
results at each information set. In an extensive game with imperfect information, sequential equilibrium
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:5
consists of a strategy profile and belief system. The strategy profile has been described in the previous
article and will not be described again.
The belief system refers to the judgment of player pi on a specific non-terminal selection node at the
information set in which it is located. In the game tree, when pi is at a certain information set, he/she
judges the probability of being at the specific node. The player needs a belief system to determine his/her
strategy combination so that it is optimal at each information set.
Definition 7. In a game G, belief system βi of player pi means that for ∀Iij ∈ Ii, player pi holds belief
βi(x) = pr[x|Iij ], x ∈ Iij .
The belief system indicates that when a player is at an arbitrary information set, he/she is convinced
of the probabilities distribution of the specific nodes at the information set.
Definition 8. In a game G, when the strategy profile is s, the expected utility of the player pi at node
x is, for the reachable terminal at this time, the sum of the utility at each terminal node:
ui(s, x) =
∑
e∈E
ui(e) · pr[e|s, x],
where ui(e) represents the pi’s utility at the terminal node and pr[e|s, x] represents the probability of
arriving at the reachable terminal node ni ∈ E from the node x when the strategy profile is s.
Definition 9. In a game G, when the belief system of player pi is βi, the expected utility of player pi
at Iij is the sum of expected utility at each x ∈ Iij .
ui(s, β, Iij) =
∑
x∈Iij
βi(x) · ui(s, x).
Definition 10. In a game G, when β is a belief system, the strategy profile s = (si, s−i) is called
rational at the information set when
∀s′i ∈ Si, ui((s
′
i, s−i), β, Iij) 6 ui(s, β, Iij).
Definition 11. In a game G, a (s, β) is called sequential rationality if for ∀pi ∈ P, Iij ∈ I, the strategy
profile s = (si, s−i) is rational at the information set.
Definition 12. In a game G, a (s, β) is called sequential consistency if there exists a sequence of fully
mixed behavior strategy profile (sk)k∈N converging to s and the sequence of belief (βk)k∈N induced by
(sk)k∈N converging to the belief system β. In other words, it satisfies both
(1) lim
k→∞
(sk) → s, (2) lim
k→∞
(βk) → β.
Definition 13. In a game G, a (s, β) is called the sequential equilibrium if it satisfies sequential
rationality and consistency.
For a given sequential equilibrium (s, β), the player’s expected utility at any point is the highest, and
any strategy combination of the players that deviates from the sequential equilibrium does not make the
utility higher. Therefore, rational players have no motivation to deviate from sequential equilibrium.
Definition 14. In a game G, RPath(x) is called the rational path if there is only one sequential
equilibrium so that the game will always follow this unique path and end at the terminal node x.
3 Natural state and prisoner’s dilemma
In this section, we introduce the rational secret sharing in the natural state. We prove that rational
players are bound to fall into the prisoner’s dilemma, so that no player has a motivation to honestly
publish his/her secret share, which results in no player being able to reconstruct the secret.
3.1 Natural system model
In the nature state, a rational secret sharing process contains a secret generation center (SGC) and players
who are called secret sharing parties (SSPs).
• SGC: The task of trusted SGC is to distribute and save the shared secret in the system, which is
similar to a key generation center, and once the secret is distributed, it goes offline.
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:6
honest
honest  dishonest honest  dishonest
 dishonest
u(p1)(        )u(p2)
b(   )b
d(   )a
a(   )d
c(   )c
n0
n2n1
n3
n4 n5
n6
Figure 2 Game1.
• SSPs: The SSPs in our paper are rational p1, p2 in secret sharing and they can interact with each
other.
And we describe such a process as the following two phases.
Distribution phase.
(1) The SGC randomly generates the shared key W ∈ {0, 1}k, and then it randomly selects w1,w2 ∈
{0, 1}k and satisfies W = w1 ⊕ w2.
(2) The SGC sends w1 to p1 and w2 to p2, and then it goes offline.
w1 and w2 are secret shares, obviously, if a player does not have two secret shares at the same time
and k is large enough, and then the probability of getting W is an negligible ξ = (12 )
k.
Reconstruction phase.
(1) p1 sends w′
1/⊥ to p2 and p2 sends w′
2/⊥ to p1.
(2) p1 computes W1 = w1 ⊕ w′
2 and p2 computes W2 = w2 ⊕ w′
1.
For example, w′
1 means p1 sends a message to p2, but this message may not be correct. ⊥ means player
does not send any message.
3.2 Value variables
To describe the behavior of rational players in the natural state, we define some value variables as follows.
• a : The utility of the player who reconstructs the secret correctly (if only one player reconstructs the
secret correctly).
• b : The utility of each player (if both players reconstruct the secret correctly).
• c : The utility of each player (if no player reconstructs the secret correctly).
• d : The utility of the player who does not reconstruct the secret correctly (if only one player recon-
structs the secret correctly).
Obviously, a > b > c > d.
3.3 Problem statement
Rational p1, p2 aim to maximize their own utility, during the reconstruction phase, they have three
strategies: {publish}, {silent}, {cheat}.
{publish} means the player publishes his/her secret share honestly.
{silent} means the player does not publish his/her secret share.
{cheat} means the player publishes his/her secret share dishonestly.
Because {silent} and {cheat} have no effect on utility functions, and the both strategies represent
dishonest behaviors, so they are called {dishonest}. Similarly, {publish} is called {honest}.
When pi sends the real w′
i = wi to the other player, if he/she receives the wrong w′
−i 6= w−i or even
does not receive a secret share, then he/she gets the worst utility d; if he/she receives the right w′
−i = w−i,
then he/she gets utility b which is less than utility a. In fact, at this time, the strategy {honest} is strictly
inferior to the strategy {dishonest}, and no player will choose the strictly dominated strategy {honest},
therefore, this also leads both players into the prisoner’s dilemma and no player can reconstruct the secret
correctly.
We describe such a prisoner’s dilemma through the game tree in Figure 2.
In this game tree,
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:7
• the players set is P = {p1, p2} and the action set is A = {honest, dishonest};
• the non-terminal selection node set is H = {n0, n1, n2} and the terminal node set is E = {n3, n4, n5,
n6};
• the information set is I = {I1, I2} where I1 = {n0}, I2 = {n1,n2};
• the optional action set is Q = {Q1,Q2} where Q1 = Q2 = {honest, dishonest}.
Lemma 1. The Game1 in Figure 2 has a sequential equilibrium (s, β) = ((s1, s2), (β1, β2)) where











s1 = ([0(honest), 1(dishonest)]),
s2 = ([0(honest), 1(dishonest)]),
β1 = ([1(n0)]),
β2 = ([0(n1), 1(n2)]).
Proof. We set the strategy profile in the sequential equilibrium is s = (s1, s2) where
{
s1 = ([ρ1(honest), ρ2(dishonest)]),
s2 = ([λ1(honest), λ2(dishonest)]).
Note that ρi, λ are probabilities and they satisfy







ρi, λi ∈ [0, 1],
ρ1 + ρ2 = 1,
λ1 + λ2 = 1.
Then we derive belief system β = (β1, β2) from Bayes’ rule:
{
β1 = ([1(n0)]),
β2 = ([ρ1(n1), ρ2(n2)]).
Now we begin to prove the sequential rationality.
When p2 reaches I2, his/her expected utility is
u2(s, β2, I2) = β2(n1) · u2(s, n1) + β2(n2) · u2(s, n2) = ρ1 · u2(s, n1) + ρ2 · u2(s, n2),
and we have
{
u2(s, n1) = λ1 · u2(n3) + λ2 · u2(n4),
u2(s, n2) = λ1 · u2(n5) + λ2 · u2(n6).
Because











u2(n3) = b,
u2(n4) = a,
u2(n5) = d,
u2(n6) = c,
and a > b > c > d, we can know λ1 = 0, λ2 = 1. To be more precise, p2 must choose {dishonest} in order
to maximize his/her own utility.
Now let us consider p1’s situation. When he/she reaches I1, his/her expected utility is
u1(s, β1, I1) = 1(n0) · u1(s, n0) = ρ1 · λ1 · u1(n3) + ρ1 · λ2 · u1(n4) + ρ2 · λ1 · u1(n5) + ρ2 · λ2 · u1(n6).
Because rational p1 also knows that p2 must choose {dishonest}, i.e., λ1 = 0, λ2 = 1,
u1(s, β1, I1) = ρ1 · λ2 · u1(n4) + ρ2 · λ2 · u1(n6).
Because
{
u1(n4) = d,
u1(n6) = c,
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:8
and c > d, we can get that ρ1 = 0, ρ2 = 1.
Then we will prove the sequential consistency. Let the fully mixed sk = (sk1 , s
k
2) where







sk1 =
([
1
k
(honest),
k − 1
k
(dishonest)
])
,
sk2 =
([
1
k
(honest),
k − 1
k
(dishonest)
])
,
and the derived βk = (βk
1 , β
k
2 ) from Bayes rule is





βk
1 = ([1(n0)]),
βk
2 =
([
1
k
(n1),
k − 1
k
(n2)
])
.
Because







lim
k→∞
(
k − 1
k
)
= 1,
lim
k→∞
(
1
k
)
= 0,
we can get the result



lim
k→∞
(
sk
)
→ s,
lim
k→∞
(
βk
)
→ β.
Theorem 1. The Game1 in Figure 2 will always end at n6.
Proof. From Lemma 1, we can know Game1 has unique sequential equilibrium, and RPath(n6) means
there is no motivation for rational players to be honest when they share secret shares, so Game1 will
always begin with n0, pass through n2 and end at n6.
We mark RPath(n6) with the red line in Figure 2. Obviously, in this case, the secret cannot be
reconstructed correctly and this is why we urgently need a solution to break the prisoner’s dilemma.
4 Incentive contract
In order to solve the problems in Section 3, we redesign the process of secret sharing and propose an
incentive contract (IC).
4.1 New system model
Our new system model contains not only a SGC and SSPs, but also a verifier V . The task of V is to
verify the honesty of SSPs if the verification request is initiated.
Then we divides rational secret sharing into the following phases.
Distribution phase. The SGC
(1) randomly generates the shared key W ∈ {0, 1}k, and then it randomly selects w1,w2 ∈ {0, 1}k and
satisfies W = w1 ⊕ w2;
(2) computes hash function m1 = h(w1),m2 = h(w2);
(3) randomly selects s1, s2 ∈ F ∗
q , and then it generates commitments Coms1(m1),Coms2(m2);
(4) sends (w1, s1, h) to p1 and sends (w2, s2, h) to p2. Besides, it sends (W,w1, w2,Coms1(m1),
Coms2(m2), h) to V , and then it goes offline.
SGC will go offline after generating and distributing secret shares, so it needs to send useful messages
to V in order to ensure verifiability.
Sign contract phase (SCP).
(1) V puts the commitments Coms1(m1),Coms2(m2) as parts of the incentive contract and puts the
contract on the blockchain.
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:9
(2) SSPs verify the source of contract by opening the commitments and choose whether to sign the
contract or not.
For example, in the SCP, if pi successfully opens Coms1(m1) by s1 and he/she gets m1 = h(w1), then
he/she will be able to believe that the contract is from V .
Publish secret share phase (PSSP).
(1) pi computes hash function m′
i = h(w′
i).
(2) pi randomly selects s′i ∈ F ∗
q , and then he/she generates a commitment Coms′
i
(m′
i).
(3) pi puts his/her commitment Coms′
i
(m′
i) on the blockchain, and sends (s′i, w
′
i) to the other player.
It means that in the PSSP, pi needs to generate a commitment to the message he/she is sending to
the other player. For example, if p1 sends w′
1 to p2, he/she needs to generate a commitment Coms′
1
(m′
1).
Therefore, p2 can verify that the commitment Coms′
1
(m′
1) on the blockchain is actually generated by the
h(w′
1) of the received w′
1. It also ensures that players cannot deny.
Promulgate reconstructed secret phase (PRSP).
(1) pi verifies that whether the other player’s commitment on the blockchain is exactly the result of
computing a commitment for the message (s′−i,m
′
−i).
(2) pi computes Wi = wi ⊕ w′
−i.
(3) pi computes hash function M ′
i = h(W ′
i ).
(4) pi randomly selects Si
′ ∈ F ∗
q , and then he/she generates a commitment ComS′
i
(M ′
i).
(5) pi puts his/her commitment ComS′
i
(M ′
i) on the blockchain, and sends (S′
i,W
′
i ) to the other player.
Similarly, for example, in the PRSP, p1 needs to commit to M ′
1 by choosing a secret S′
1 to generate
a commitment ComS′
1
(M ′
1) and put ComS′
1
(M ′
1) on the blockchain. Therefore, p2 can verify that the
commitment ComS′
1
(M ′
1) on the blockchain is actually generated by the h(W ′
1) of the received W ′
1.
Besides, p2 can judge p1’s honesty by comparing h(W ′
1) with h(W2) where W2 = w′
1 ⊕ w2.
Verification phase.
Once a verification request is initiated, pi must send (s′i, w
′
i, S
′
i,W
′
i ) to V , and then V gradually verifies
pi’s honesty by continually opening commitments. The detailed verification process will be described in
the following Contract content.
Note that this phase begins only when a verification request is initiated. We call the player who first
initiates the verification request pldr while the other player pflr. Whether pi sends the wrong message or
refuses to send the message is easy to verify, so rational players must send the real (s′i, S
′
i) to V to avoid
being confiscated deposit r + g.
4.2 Value variables
Since the incentive contract is introduced, we need to define more value variables.
• r + g : The deposit that players need to pay when signing incentive contract.
• r : Deposit to be confiscated if caught dishonest.
• g : Expense to be paid for initiating a verification request.
• v : Verification cost of verifier.
• ε : Some invisible utility for V when he/she signs the contract with players, such as earning a good
reputation.
Obviously, g − v > 0, otherwise, V does not accept a verification request.
4.3 Contract content and analysis
We will introduce the specific content of IC, and then we analyze each step in detail by studying the
utility function of rational players.
We define some deadlines in the contract, which help us to eliminate some strictly dominated strategies
through utility function, thus simplifying the game tree.
• T1 : In the SCP, the deadline for signing the contract.
• T2 : In the PSSP, the deadline for sending secret share.
• T3 : In the PRSP, the deadline for sending reconstructed secret.
Contract content.
• Step1: In the SCP, if p1, p2 both sign IC before T1, IC will take effect and enter Step2; else p1, p2
will enter Game1.
• Step2: In the PSSP, if p1, p2 both send secret shares before T2, IC will enter Step3; else the deposit
r + g of the silent player pi will be confiscated and IC will terminate.
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:10
• Step3: In the PRSP, if p1, p2 both send reconstructed secrets before T3, IC will enter Step4; else the
deposit r + g of the concealed player pi will be confiscated and IC will terminate.
• Step4: If a player pldr initiates a verification request, IC will enter Step5; else the deposit r + g of
the two players will be returned and IC will enter Step6.
• Step5 (Verification phase): V verifies W ′
flr and W ′
ldr. If W ′
ldr = W ′
flr = W , IC will enter Step5.1;
else if W ′
flr = W , IC will enter Step5.2; else if W ′
ldr = W , IC will enter Step5.3; else IC will enter Step5.4.
• Step5.1: Charging pldr’s deposit g for verification, returning deposit r of pldr and deposit r + g of
pflr, then V sends W to pldr and IC terminates.
• Step5.2: V verifies whether w′
flr is wrong or not. If w′
flr is wrong, IC will enter Step5.2.1; else IC
will enter Step5.2.2.
• Step5.2.1: Charging pldr’s deposit g for verification, transferring pflr’s deposit r to pldr, returning
pldr’s deposit r and pflr’s deposit g, then V sends W to pldr and IC terminates.
• Step5.2.2: Charging pldr’s deposit g for verification, transferring pldr’s deposit r to pflr, returning
pflr’s deposit r + g, then IC terminates.
• Step5.3: V verifies whether w′
ldr is wrong or not. If w′
ldr is wrong, IC will enter Step5.3.1; else IC
will enter Step5.3.2.
• Step5.3.1: Charging pldr’s deposit g for verification, transferring pldr’s deposit r to pflr, returning
pflr’s deposit r + g, then IC terminates.
• Step5.3.2: Charging pldr’s deposit g for verification, transferring pflr’s deposit r to pldr, returning
pldr’s deposit r and pflr’s deposit g, then V sends W to pldr and IC terminates.
• Step5.4: V verifies w′
ldr, w
′
flr . If (((w
′
ldr 6= wldr)||(Wldr 6= (wldr ⊕w′
flr)))&&((w′
flr 6= wflr)||(Wflr 6=
(w′
ldr ⊕ wflr))) = 1, IC will enter Step5.4.1; else if ((w′
ldr 6= wldr)||(Wldr 6= (wldr ⊕ w′
flr))) = 1, IC will
enter Step5.4.2; else if ((w′
flr 6= wflr)&&(Wflr 6= (w′
ldr ⊕wflr))) = 0, IC will enter Step5.4.3; else IC will
enter Step5.4.4.
• Step5.4.1: Charging pldr’s deposit g for verification, confiscating pldr’s and pflr’s deposit r, returning
pflr’s deposit g, then IC terminates.
• Step5.4.2: Charging pldr’s deposit g for verification, transferring pldr’s deposit r to pflr, returning
pflr’s deposit r + g, then IC terminates.
• Step5.4.3: Charging pldr’s deposit g for verification, transferring pflr’s deposit r to pldr, returning
pldr’s deposit r and pflr’s deposit g, then V sends W to pldr and IC terminates.
• Step5.4.4: Charging pldr’s deposit g for verification, confiscating pflr’s deposit g, transferring pflr’s
deposit r to pldr, returning pldr’s deposit r, then V sends W to pldr and IC terminates.
• Step6: V does not verify and IC terminates.
When a verification request is initiated, V will charge pldr’s verification expense g. Then we will
punish the dishonest player and transfer the deposit r to the honest player (both players’ deposit r will
be confiscated by V if there is no honest player). In addition, if pldr is honest, V will send the correct W
to him/her after the verification.
Our analysis process is as follows.
Contract analysis.
* Step1 means that in the SCP, p1, p2 must sign IC to start it, otherwise the prisoners’ dilemma will
occur and both p1, p2 will enter Game1.
* Step2 means that in the PSSP, if a player chooses strategy {silent}, then his/her all deposit will be
confiscated, and it is impossible for him/her to get worst utility. Therefore, the strategy {silent} is a
strictly dominated strategy and no player has motivation to choose it.
* Step3 means that in the PRSP, the strategy {concealed} is a strictly dominated strategy and no
player has motivation to choose it through a similar analysis with Step2.
* Step4 represents whether the players choose to verify or not. Note that player pi can compare the
secret Wi reconstructed by himself/herself and the secret W ′
−i sent by the other player to judge each
other’s honesty.
* Step5 represents the verification process of V .
* Step5.1 means that both players are honest at this time, pldr is obviously “making trouble unrea-
sonably”, and initiating verification will only reduce his/her own utility:
u5.1(pldr, pflr) = (b − g, b).
* Step5.2 means that either pflr cheats in the PSSP or pldr deceives in the PRSP.
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:11
* Step5.2.1 means that pflr cheats in the PSSP, and
u5.2.1(pldr, pflr) = (b + r − g, b− r).
* Step5.2.2 means that pldr deceives in the PRSP, and
u5.2.2(pldr, pflr) = (b − r − g, b+ r).
* Step5.3 means that either pldr cheats in the PSSP or pflr deceives in the PRSP.
* Step5.3.1 means that pldr cheats in the PSSP, and
u5.3.1(pldr, pflr) = (a− r − g, d+ r).
* Step5.3.2 means that pflr deceives in the PRSP, and
u5.3.2(pldr, pflr) = (b + r − g, b− r).
* Step5.4 means that at least one player in pldr, pflr is dishonest and needs to verify both w′
ldr and
w′
flr.
* Step5.4.1 means that both pldr, pflr are dishonest, and
(1) if they both reconstruct the secret correctly,
u5.4.1(pldr, pflr) = (b − r − g, b− r);
(2) else if only pldr reconstructs the secret correctly,
u5.4.1(pldr, pflr) = (a− r − g, d− r);
(3) else if only pflr reconstructs the secret correctly,
u5.4.1(pldr, pflr) = (d− r − g, a− r);
(4) else
u5.4.1(pldr, pflr) = (c− r − g, c− r).
* Step5.4.2 means that only pldr is dishonest, and
(1) if they both reconstruct the secret correctly,
u5.4.2(pldr, pflr) = (b − r − g, b+ r);
(2) else
u5.4.2(pldr, pflr) = (a− r − g, d+ r).
* Step5.4.3 means that only pflr is dishonest, and he/she either cheats in the PSSP or deceives in the
PRSP, and we have
u5.4.3(pldr, pflr) = (b + r − g, b− r).
* Step5.4.4 means that only pflr is dishonest, and he/she both cheats in the PSSP and deceives in the
PRSP, and we have
u5.4.3(pldr, pflr) = (b + r − g, b− r − g).
* Step6 means that no player initiates a verification request, so the strategy in the PRSP does not
affect the utility function. Therefore, in the PSSP,
(1) if both p1, p2 choose strategy {publish}, then
u(p1, p2) = (b, b);
(2) else if both p1, p2 choose strategy {cheat}, then
u(p1, p2) = (c, c);
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:12
Table 1 The pldr’s utility of IVR and NIVR
Serial pldr pldr pflr pflr uIVR(pldr) uNIVR(pldr)
1* publish promulgate publish promulgate b − g b
2* publish promulgate publish deceive b + r − g b
3* publish promulgate cheat promulgate b + r − g d
4* publish promulgate cheat deceive b + r − g d
5* publish deceive publish deceive b − r − g b
6* publish deceive cheat promulgate d− r − g d
7* publish deceive cheat deceive d− r − g d
8* cheat promulgate publish deceive a − r − g a
9* cheat promulgate cheat promulgate c − r − g c
10* cheat promulgate cheat deceive c − r − g c
11* cheat deceive publish deceive a − r − g a
12* cheat deceive cheat promulgate c − r − g c
13* cheat deceive cheat deceive c − r − g c
14* publish deceive publish promulgate b − r − g b
15* cheat promulgate publish promulgate a − r − g a
16* cheat deceive publish promulgate a − r − g a
(3) else
u(pcheat, ppublish) = (a, d).
Through the analysis of IC, we can know when r > g, players’ choice of whether to initiate a verification
request directly affects the utility function. And we draw Table 1 to show the pldr’s utility of initiating
a verification request (IVR) and not initiating a verification request (NIVR).
Lemma 2. Honest player has no motivation to initiate a verification request if the other is as well as
honest.
Proof. Serial 1* in Table 1 means both pldr and pflr are honest, in this case, we have
uIVR(pldr) < uNIVR(pldr).
Lemma 3. If r−g > 0, honest player inevitably initiates a verification request if the other is dishonest.
Proof. Serials 2*–4* in Table 1 mean pldr is honest while pflr is dishonest, in this case, because r−g > 0,
so we have
uIVR(pldr) > uNIVR(pldr).
Lemma 4. Dishonest player must not dare to initiate a verification request.
Proof. Serials 5*–16* in Table 1 mean pldr is dishonest, in this case, we have
uIVR(pldr) < uNIVR(pldr).
4.4 Game and analysis
From the previous analysis, we can know that {silent} in the PSSP and {concealed} in the PRSP are
strictly dominated strategies, so {silent}, {concealed} are directly eliminated. Then after the PRSP,
rational players have reason to choose whether to initiate a verification request or not according to
different situations, reasonable explanations and proofs will be given in the following Theorem 2. For
these reasons, our extensive game tree is simplified and constructed.
• The player set is P = {p1, p2}, non-terminal selection node set is H = {n0, n1, . . . , n16}, terminal
node set is E = {n17, n18, . . . , n32}.
• {silent} and {concealed} are strictly dominated strategies, so these strategies can be directly removed
from the game tree, and the action set is A ={sign, no sign, publish, cheat, promulgate, deceive}.
• The information set is I = {I11, I12, I13, I14, I21, I22, I23, I24} where I11 = {n0}, I12 = {n2}, I13 =
{n5, n6}, I14 = {n7, n8} and I21 = {n1}, I22 = {n3, n4}, I23={n9, n10, n13, n14}, I24={n11, n12, n15, n16}.
• The optional action set is Q = {Q11, Q12, Q13, Q14, Q21, Q22, Q23, Q24} where Q11 = Q21 = {sign,
no sign}, Q12 = Q22 = {publish, cheat} and Q13 = Q14 = Q23 = Q24 = {promulgate, deceive}.
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:13
Table 2 Utility function in Game2
Node u(p1) u(p2)
n17 b b
n18 b + r − g b − r
n19 b − r b + r − g
n20 b b
n21 b + r − g b − r
n22 b + r − g b − r − g
n23 d a
n24 d a
n25 b − r b + r − g
n26 a d
n27 b − r − g b + r − g
n28 a d
n29 c c
n30 c c
n31 c c
n32 c c
Game1 c c
no_sign no_sign
 sign
 sign
 publish
 publish publish  cheat
deceive deceive deceive deceive
 cheat
 cheat
promulgate promulgate promulgate promulgate
promulgate  deceive promulgate  deceive promulgate deceive promulgate  deceive promulgate deceive promulgate deceive promulgate deceive promulgate  deceive
Game1 Game1
n0
n2
n1
p1
p1
p1
p1 p1p1
p2
p2p2
p2
n3
n7 n8
n9 n10 n11
n17 n18 n19 n20 n21 n22 n23 n24 n25 n26 n27 n28 n29 n30 n31 n32
n12 n13 n14 n15 n16
n4
n5 n6
u(p1)(        )u(p2)
p2 p2 p2 p2 p2 p2 p2
d(   )a
b(   )b
b(   )b
b+r−g(          )b−r
b+r−g(          )b−r
b+r−g(          )b−r−g
b−r−g(          )b+r−g
b−r(          )b+r−g
b−r(          )b+r−g
d(   )a
a(   )d
a(   )d
c(   )c
c(   )c
c(   )c
c(   )c
c(   )c
c(   )c
Figure 3 Game2.
Theorem 2. In Game2, we can assign reasonable probabilities for players to IVR and NIVR in different
situations after the PRSP, thus removing unnecessary branches of the game tree.
Proof. From Lemma 2, we can see that the path ending at node n17 means because both players
are honest, no one will initiate a verification request. From Lemma 3, the paths ending at node
{n18, n19, n21, n22, n25, n27} mean because one player is honest while the other is dishonest, the hon-
est player will inevitably initiate a verification request. From Lemma 4, the paths ending at node
{n20, n23, n24, n26, n28, n29, n30, n31, n32} mean because both players are dishonest, they will not dare to
initiate a verification request.
Now we draw Table 2 to facilitate our subsequent proof.
Lemma 5. If r > g, Game2 in Figure 3 exists a sequential equilibrium (s, β) = ((s1, s2), (β1, β2))
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:14
where











s1=([1(sign),0(no sign)], [1(publish),0(cheat)], [1(promulgate), 0(deceive)], [1(promulgate), 0(deceive)]),
s2=([1(sign),0(no sign)], [1(publish),0(cheat)], [1(promulgate), 0(deceive)], [1(promulgate), 0(deceive)]),
β1=([1(n0)], [1(n2), 0(Game1)], [1(n5), 0(n6)], [1(n7), 0(n8)]),
β2=([1(n1), 0(Game1)], [1(n3), 0(n4)], [1(n9), 0(n10), 0(n13), 0(n14)], [1(n11), 0(n12), 0(n15), 0(n16)]).
Proof. We set the strategy profile in the sequential equilibrium is s = (s1, s2) where











s1 = ([ρ1(sign), ρ2(no sign)], [ρ3(publish), ρ4(cheat)], [ρ5(promulgate), ρ6(deceive)],
[ρ7(promulgate), ρ8(deceive)]),
s2 = ([λ1(sign), λ2(no sign)], [λ3(publish), λ4(cheat)], [λ5(promulgate), λ6(deceive)],
[λ7(promulgate), λ8(deceive)]),
ρi, λi are probabilities and they satisfy







ρi, λi ∈ [0, 1],
ρ1 + ρ2 = 1, ρ3 + ρ4 = 1, ρ5 + ρ6 = 1, ρ7 + ρ8 = 1,
λ1 + λ2 = 1, λ3 + λ4 = 1, λ5 + λ6 = 1, λ7 + λ8 = 1.
Then we derive belief system β = (β1, β2) from Bayes’ rule,







β1 = ([1(n0)], [λ1(n2), λ2(Game1)], [λ3(n5), λ4(n6)], [λ5(n7), λ6(n8)]),
β2 = ([ρ1(n1), ρ2(Game1)], [ρ3(n3), ρ4(n4)], [ρ3 · ρ5(n9), ρ3 · ρ6(n10), ρ4 · ρ7(n13), ρ4 · ρ8(n14)],
[ρ3 · ρ5(n11), ρ3 · ρ6(n12), ρ4 · ρ7(n15), ρ4 · ρ8(n16)]).
Now we will first prove the sequential rationality (see (a)–(h)).
(a) When p2 reaches information set I23= {n9,n10,n13,n14}, the expected utility of player p2 is
u2(s, β2, I23) = β2(n9) · u2(s, n9) + β2(n10) · u2(s, n10) + β2(n13) · u2(s, n13) + β2(n14) · u2(s, n14)
= ρ3 · ρ5 · u2(s, n9) + ρ3 · ρ6 · u2(s, n10) + ρ4 · ρ7 · u2(s, n13) + ρ4 · ρ8 · u2(s, n14),
and we have











u2(s, n9) = λ5 · u2(n17) + λ6 · u2(n18),
u2(s, n10) = λ5 · u2(n19) + λ6 · u2(n20),
u2(s, n13) = λ5 · u2(n25) + λ6 · u2(n26),
u2(s, n14) = λ5 · u2(n27) + λ6 · u2(n28).
If r − g > 0, we can easily get
u2(n17) > u2(n18), u2(n19) > u2(n20), u2(n25) > u2(n26), u2(n27) > u2(n28).
Therefore, we can infer that λ5 = 1 and λ6 = 0 is reasonable because it can maximize p2’s own utility.
It means that when p2 reaches I23, he/she must choose {promulgate} to maximize his/her own utility.
(b) When p2 reaches information set I24= {n11,n12,n15,n16}, the expected utility of player p2 is
u2(s, β2, I24) = β2(n11) · u2(s, n11) + β2(n12) · u2(s, n12) + β2(n15) · u2(s, n15) + β2(n16) · u2(s, n16)
= ρ3 · ρ5 · u2(s, n11) + ρ3 · ρ6 · u2(s, n12) + ρ4 · ρ7 · u2(s, n15) + ρ4 · ρ8 · u2(s, n16),
and we have











u2(s, n11) = λ7 · u2(n21) + λ8 · u2(n22),
u2(s, n12) = λ7 · u2(n23) + λ8 · u2(n24),
u2(s, n15) = λ7 · u2(n29) + λ8 · u2(n30),
u2(s, n16) = λ7 · u2(n31) + λ8 · u2(n32).
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:15
We can easily get
u2(n21) > u2(n22), u2(n23) = u2(n24), u2(n29) = u2(n30), u2(n31) = u2(n32).
Therefore, we can infer that λ7 = 1 and λ8 = 0. It means that when p2 reaches I24, he/she must
choose {promulgate} to maximize his/her own utility.
So from (a) and (b), we can know that in the PRSP, p2 must choose {promulgate} in order to maximize
his/her own utility.
(c) Let us continue our analysis. When p1 reaches information set I13 = {n5, n6}, the expected utility
of player p1 is
u1(s, β1, I13) = β1(n5) · u1(s, n5) + β1(n6) · u1(s, n6)
= λ3 · u1(s, n5) + λ4 · u1(s, n6),
and we have
{
u1(s, n5) = λ5 · ρ5 · u1(n17) + λ6 · ρ5 · u1(n18) + λ5 · ρ5 · u1(n19) + λ6 · ρ6 · u1(n20),
u1(s, n6) = λ7 · ρ5 · u1(n21) + λ8 · ρ5 · u1(n22) + λ7 · ρ5 · u1(n23) + λ8 · ρ6 · u1(n24).
Because not only does p2 know that {promulgate} must be chosen to maximize p2’s utility in the
PRSP, but p1 also knows that. In other words, p1 also knows that
{
λ5 = 1, λ6 = 0,
λ7 = 1, λ8 = 0,
so we have
{
u1(s, n5) = ρ5 · u1(n17) + ρ6 · u1(n19),
u1(s, n6) = ρ5 · u1(n21) + ρ6 · u1(n23),
and we can easily get
u1(n17) > u1(n19), u1(n21) > u1(n23).
Therefore, ρ5 = 1, ρ6 = 0 and it means p1 must choose {promulgate} to maximize his/her own utility
at information set I13.
(d) When p1 reaches information set I14 = {n7, n8}, the expected utility of player p1 is
u1(s, β1, I14) = β1(n7) · u1(s, n7) + β1(n8) · u1(s, n8)
= λ5 · u1(s, n7) + λ6 · u1(s, n8).
Similarly, we have
{
u1(s, n7) = ρ7 · u1(n25) + ρ8 · u1(n27),
u1(s, n8) = ρ7 · u1(n29) + ρ8 · u1(n31),
and we can easily get
u1(n25) > u1(n27), u1(n29) = u1(n31).
Therefore, ρ7 = 1, ρ8 = 0 and it means p1 must choose {promulgate} to maximize his/her own utility
at information set I14.
From (a)–(d), we can know p1, p2 must choose {promulgate} in the PRSP.
(e) When p2 reaches I22, the expected utility of player p2 is
u2(s, β2, I22) = β2(n3) · u2(s, n3) + β2(n4) · u2(s, n4)
= ρ3 · u2(s, n3) + ρ4 · u2(s, n4).
Similarly, because p2 knows p1, p2 must choose {promulgate} in the PRSP, i.e.,
{
λ5 = 1, λ6 = 0, λ7 = 1, λ8 = 0,
ρ5 = 1, ρ6 = 0, ρ7 = 1, ρ8 = 0,
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:16
we have
{
u2(s, n3) = λ3 · u2(n17) + λ4 · u2(n21),
u2(s, n4) = λ3 · u2(n25) + λ4 · u2(n29),
and we can easily get
u2(n17) > u2(n21), u2(n25) > u2(n29).
Therefore, λ3 = 1, λ4 = 0 and it means p2 must choose {publish} to maximize his/her own utility at
information set I22.
(f) When p1 reaches I12, the expected utility of player p1 is
u1(s, β1, I12) = β1(n2) · u1(s, n2) + β1(Game1) · u1(s,Game1)
= λ1 · u1(s, n2) + λ2 · u1(s,Game1).
In particular, we should not confuse Game1 with the game after signing IC. Our rational players are
fully aware of the validity of IC. If the IC does not come into effect, p1, p2 can only fall into prisoner’s
dilemma and get utility c. If IC comes into effect, p1, p2 will make independent strategic choices. In other
words, the game after signing IC and Game1 are completely independent.
Similarly, p1 knows
{
λ3 = 1, λ4 = 0, λ5 = 1, λ6 = 0, λ7 = 1, λ8 = 0,
ρ5 = 1, ρ6 = 0, ρ7 = 1, ρ8 = 0.
In the above, we have
{
u1(s, n2) = ρ3 · u1(n17) + ρ4 · u1(n25),
u1(s,Game1) = c,
and we can easily get
u1(n17) > u1(n25).
Therefore, ρ3 = 1, ρ4 = 0 and it means p1 must choose {publish} to maximize his/her own utility at
information set I12.
(g) When p2 reaches I21, the expected utility of player p2 is
u2(s, β2, I21) = β2(n1) · u2(s, n1) + β2(Game1) · u2(s,Game1)
= ρ1 · u2(s, n1) + ρ2 · u2(s,Game1).
p2 knows
{
λ3 = 1, λ4 = 0, λ5 = 1, λ6 = 0, λ7 = 1, λ8 = 0,
ρ3 = 1, ρ4 = 0, ρ5 = 1, ρ6 = 0, ρ7 = 1, ρ8 = 0,
and we have
{
u2(s, n1) = λ1 · u2(n17) + λ2 · c,
u2(s,Game1) = c.
We can easily get
u2(n17) > c.
Therefore, λ1 = 1, λ2 = 0.
(h) When p1 reaches I11, the expected utility of player p1 is
u1(s, β1, I11) = 1(n0) · u1(s, n0).
p2 knows
{
λ1 = 1, λ2 = 0, λ3 = 1, λ4 = 0, λ5 = 1, λ6 = 0, λ7 = 1, λ8 = 0,
ρ3 = 1, ρ4 = 0, ρ5 = 1, ρ6 = 0, ρ7 = 1, ρ8 = 0,
so we have
u1(s, n0) = ρ1 · u1(n17) + ρ2 · c,
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:17
and then we easily get
u1(n17) > c.
Therefore, ρ1 = 1, ρ2 = 0.
So from (a)–(h), we can get that
{
λ1 = 1, λ2 = 0, λ3 = 1, λ4 = 0, λ5 = 1, λ6 = 0, λ7 = 1, λ8 = 0,
ρ1 = 1, ρ2 = 0, ρ3 = 1, ρ4 = 0, ρ5 = 1, ρ6 = 0, ρ7 = 1, ρ8 = 0,
and
⇒











ρ3 · ρ5 = 1,
ρ3 · ρ6 = 0,
ρ4 · ρ7 = 0,
ρ4 · ρ8 = 0.
In summary, (s, β) = ((s1, s2), (β1, β2)) satisfies the sequential rationality.
Then we will prove the sequential consistency (see (i)–(j)).
(i) We set the fully mixed sequence sk = (sk1 , s
k
2) where



























sk1 =
([
k − 1
k
(sign),
1
k
(no sign)
]
,
[
k − 1
k
(publish),
1
k
(cheat)
]
,
[
k − 1
k
(promulgate),
1
k
(deceive)
]
,
[
k − 1
k
(promulgate),
1
k
(deceive)
])
,
sk2 =
([
k − 1
k
(sign),
1
k
(no sign)
]
,
[
k − 1
k
(publish),
1
k
(cheat)
]
,
[
k − 1
k
(promulgate),
1
k
(deceive)
]
,
[
k − 1
k
(promulgate),
1
k
(deceive)
])
.
Because







lim
k→∞
(
k − 1
k
)
= 1,
lim
k→∞
(
1
k
)
= 0,
we can get



lim
k→∞
(sk1) → s1
lim
k→∞
(sk2) → s2
⇒ lim
k→∞
(sk) → s.
(j) Now we derive belief system βk = (βk
1 , β
k
2 ) through Bayes’ rule where





























βk
1 =
(
[1(n0)],
[
k − 1
k
(n2),
1
k
(Game1)
]
,
[
k − 1
k
(n5),
1
k
(n6)
]
,
[
k − 1
k
(n7),
1
k
(n8)
])
,
βk
2 =
([
k − 1
k
(n1),
1
k
(Game1)
]
,
[
k − 1
k
(n3),
1
k
(n4)
]
,
[
(k − 1)
2
k2
(n9),
k − 1
k2
(n10),
1
k2
(n13),
k − 1
k2
(n14)
]
,
[
(k − 1)
2
k2
(n11),
k − 1
k2
(n12),
1
k2
(n15),
k − 1
k2
(n16)
])
.
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:18
Because































lim
k→∞
(
k − 1
k
)
= 1,
lim
k→∞
(
1
k
)
= 0,
lim
k→∞
(k − 1)
2
k2
= 1,
lim
k→∞
k − 1
k2
= 0,
lim
k→∞
1
k2
= 0,
we can get



lim
k→∞
(βk
1 ) → β1
lim
k→∞
(βk
2 ) → β2
⇒ lim
k→∞
(βk) → β.
Theorem 3. If r > g, Game2 in Figure 3 will always end at n17.
Proof. From Lemma 5 we can know that Game2 exists only one sequential equilibrium and we use the
red line to mark the unique RPath(n17). It means that rational players are confident that both of them
will sign IC in the SCP, and then they honestly share secrets in the PSSP and PRSP. So Game2 begins
at n0, passes through (n1, n2, n3, n5, n9) and ends at n17.
4.5 Verifier’s motivation
In the previous article, we describe the motivation of p1, p2 to sign IC and be honest in the PSSP, PRSP.
However, we do not involve the motivation of V to sign IC with p1, p2 in our analysis. Here we will
explain it in detail.
V ’s verification cost is v, and once a verification request is initiated, V will charge pldr’s verification
expense g. V gets the utility v − g and because v − g > 0, V has no motivation to refuse a verification
request.
However, from Theorem 3 we can see that p1, p2 are honest and have no motivation to initiate a
verification request. Of course rational V knows that and the verification expense g cannot be obtained.
So why V signs IC?
In fact, we think there will be some invisible utility ε for him/her such as earning a good reputation if
V signs IC. Therefore, in order to obtain ε, V has the motivation to sign IC.
5 Simulation and analysis
The concept of programmable smart contracts can be traced back to [25], which is widely used with the
introduction of the blockchain. In this section, we simulate the smart contract on the Ethereum, and
then we analyze the requirements and overhead of the entire scheme.
5.1 Smart contract
Our smart contract mainly contains the functions in Table 3. For example, the function TimeOut is
defined to avoid player’s misbehavior, i.e., the player has no motivation to choose {silent} in the PSSP
or {concealed} in the PRSP.
We know from Section 4 that there is a unique RPath(n17) in the game and we simulate the execution
of the rational path, i.e., the rational player pi will
• call function Sign before T1 and pay the deposit r + g.
• call function SendSecretShare before T2 and send correct commitment Comsi(mi).
• call function SendReconstructedSecret before T3 and send the correct commitment ComSi
(Mi).
• call function IVROrNot before T4 and set the IVR = false, that is, not to initiate a verification
request.
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:19
Table 3 Functions in the smart contract
Serial Function Description
1 Sign A player calls this function to sign IC before T1. Auto-transferring each player’s
deposit r + g to the contract account if the contract takes effect.
2 SendSecretShare A player calls this function to send the commitment of his/her secret share before T2.
3 SendReconstructedSecret A player calls this function to send the commitment of his/her reconstructed secret
before T3.
4 IVROrNot A player calls this function to choose whether initiate a verification request or not
before T4.
5 Transfer This function can handle disputes in different situations:
If (UIVR)
contract auto-transfers deposit r + g to pldr, deposit r + g to pflr .
Else if (IVR)
Case1 (Both players are honest): contract auto-transfers deposit r to pldr , deposit
r + g to pflr and deposit g to V ;
Case2 (pldr is honest while pflr is dishonest): contract auto-transfers deposit 2r
to pldr, deposit g to pflr and deposit g to V ;
Case3 (pldr is dishonest while pflr is honest): contract auto-transfers deposit 2r+g
to pflr and deposit g to V ;
Case4 (Both players are dishonest, pflr either cheats in the PSSP or deceives in
the PRSP): contract auto-transfers deposit g to pflr and deposit 2r + g to V ;
Case5 (both players are dishonest, pflr both cheats in the PSSP and deceives in
the PRSP): contract auto-transfers deposit 2r + 2g to V .
6 TimeOut V can call this function if it times out:
Case1 (Only pi called the function SendSecretShare before T2): contract auto-
transfers deposit r + g to pi, deposit r + g to V ;
Case2 (No player called the function SendSecretShare before T2): contract auto-
transfers deposit 2r + 2g to V ;
Case3 (Only pi called the function SendReconstructedSecret before T3): contract
auto-transfers deposit r + g to pi, deposit r + g to V ;
Case4 (No player called the function SendReconstructedSecret before T3): contract
auto-transfers deposit 2r + 2g to V ;
Case5 (Only pi called the function IVROrNot before T4): contract auto-transfers
deposit r + g to pi, deposit r + g to V ;
Case6 (No player called the function IVROrNot before T4): contract auto-transfers
deposit 2r + 2g to V .
So we can get
• the function Transfer will return each player’s deposit r + g,
• the function TimeOut will not be called.
5.2 Requirement
Our scheme mainly needs to consider the following requirements.
• Privacy: For players in secret sharing, their secrets need to be hidden. However, the data on the
blockchain is visible to the public, so privacy should be considered when designing the smart contract.
• Verifiability: Only if the scheme satisfies verifiability can we guarantee that players will not devi-
ate from honest behavior. In addition, rational players must be able to autonomously capture other’s
dishonesty to initiate a verification request.
In order to solve the above requirements, we use the famous Pedersen commitment scheme [26] and a
collision-resistant hash function. More specifically, we use the hash function to compute the secrets such
as m′
i = h(w′
i). Then, in the PSSP, pi randomly generates Coms′
i
(m′
i) by choosing random s′i and sends
Coms′
i
(m′
i) to the blockchain, and in addition, pi sends the randomly chosen s′i and his/her secret shares
w′
i to the p−i through a secure channel. For a given Coms′
i
(m′
i), because the commitment is hiding,
so it is infeasible to know m′
i without s′i. Besides, the commitment is binding; i.e., it is infeasible to
find different pairs (s′i,m
′
i) and (s′i
′
,mi
′′) such that Coms′
i
(m′
i) = Coms′′
i
(mi
′′). So when p−i receives
(s′i, wi
′), he/she computes Coms′
i
(h(w′
i)), and then he/she can compare whether the two commitments
(one is placed on the blockchain by pi and the other is calculated by p−i) are equal. Similarly, pi commits
reconstructed Wi in the PRSP. It is worth noting that if both players are honest, then the reconstructed
secrets of both players should be consistent; i.e., if p−i is honest, then he/she can judge the honesty of
pi by opening pi’s commitment ComS′
i
(M ′
i). Similarly, if a player pldr initiates a verification request, the
verifier V also achieves verifiability by constantly opening commitment. Therefore, our scheme satisfies
privacy and verifiability.
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:20
Table 4 Cost of using the smart contract
Serial Function Cost in Gas Cost in Dollar
1 Deploy 1382691 0.26
2 Sign 292963 0.056
3 SendSecretShare 132224 0.025
4 SendReconstructedSecret 132180 0.025
5 IVROrNot 95416 0.018
6 Transfer 41748 0.008
Table 5 Number of calculations
Player Generate commitment Open commitment Compute hash function
p1 2 3 5
p2 2 3 5
V 0 0 0
Total 4 6 10
5.3 Overhead
Cost is measured in terms of gas in the smart contract. The gas price is 1 Gas = 1 Gwei (1 × 10−9
ether) in all transactions, and the current exchange rate is 1 ether = $190.45. Then we show the cost of
deploying the contract and executing the functions in Table 4.
As we can see, the total cost of using the smart contract is low. The Deploy($0.26) is used to deploy
the contract on the blockchain, and we find other functions cost less. Note that the player’s calculation is
done privately and not published on the blockchain; i.e., the player only needs to send the commitment.
In addition, we know from previous analysis that no rational player has dishonest motivation. So we
show the actual number of calculations in Table 5, and we can get that additional overhead incurred by
cryptography is also small.
6 Conclusion and future work
We consider rational secret sharing as a dynamic game with imperfect information. We find that rational
players will never cooperate if the incentive mechanism is not effective enough, which leads to the fact
that the correct secret cannot be reconstructed. The sequential equilibrium, as an refinement of Nash
equilibrium, specifies sequential rationality and sequential consistency, which can even eliminate incredible
threats in dynamic games with imperfect information. In this paper, we have constructed an incentive-
compatible rational secret sharing scheme and found unique sequential equilibrium solution (in this
equilibrium case no rational player has a motivation to deviate from honest behavior). What is more, we
use blockchain and a smart contract to control the utility functions of rational players, which makes our
scheme feasible in practice applications. In other words, each player must pay a deposit to join the game,
and his/her deposit will be confiscated if he/she behaves dishonestly. In short, we solve the prisoner’s
dilemma in rational secret sharing by using blockchain and a smart contract.
One future direction would be to extend our scheme to rational delegation of computation such as [27],
which may lead to more complex utility functions and incentive mechanisms, and we can analyze the
players’s capacity limitation of attack and defense. Another future direction would be to construct a
composable scheme. For example, in a repeated game of rational secret sharing, rational players will
behave honesty in each round (except the last round) in order to obtain longer cooperation and higher
utility. At this time, our scheme in this paper can be combined and used to solve the problems faced
in the last round. Besides, we hope that sequential equilibrium can be introduced into more traditional
cryptographic primitives where the participants are either honest or malicious.
Acknowledgements This work was supported by National Natural Science Foundation of China (Grant Nos. 61662009,
61772008), Guizhou Provincial Department of Education Science and Technology Top Talent Support Project (Grant No. [2016]060),
Science and Technology Major Support Program of Guizhou Province (Grant No. 20183001), Science and Technology Program of
Guizhou Province (Grant No. [2017]5788), Ministry of Education-China Mobile Research Fund Project (Grant No. MCM20170401),
Guizhou University Cultivation Project (Grant No. [2017]5788), Key Program of the National Natural Science Union Foundation
of China (Grant No. U1836205), and Science and Technology Program of Guizhou Province (Grant No. [2019]1098).
Chen Z R, et al. Sci China Inf Sci October 2021 Vol. 64 202301:21
References
1 Blakley G R. Safeguarding cryptographic keys. In: Proceedings of Americian Federation of Information Processing Societies
(AFIPS’79) National Computer Conference, 1979. 313–317
2 Shamir A. How to share a secret. Commun ACM, 1979, 22: 612–613
3 Halpern J, Teague V. Rational secret sharing and multiparty computation: extended abstract. In: Proceedings of the 36th
Annual ACM Symposium on Theory of Computing, Chicago, 2004. 623–632
4 Dodis Y, Rabin T. Cryptography and game theory. In: Algorithmic Game Theory. Cambridge: Cambridge University Press,
2007. 181–207
5 Gordon S D, Katz J. Rational secret sharing, revisited. In: Proceedings of the 5th International Conference on Security and
Cryptography for Networks, Maiori, 2006. 229–241
6 Kol G, Naor M. Games for exchanging information. In: Proceedings of the 40th Annual ACM Symposium on Theory of
Computing, Victoria, 2008. 423–432
7 Fuchsbauer G, Katz J, Naccache D. Efficient rational secret sharing in standard communication networks. In: Proceedings of
the 7th Theory of Cryptography Conference, Zurich, 2010. 419–436
8 Fudenberg D, Tirole J. Game Theory. Cambridge: MIT Press, 1991
9 Maleka S, Shareef A, Rangan C P. Rational secret sharing with repeated games. In: Proceedings of the 4th Information
Security Practice and Experience Conference, Sydney, 2008. 334–346
10 Ong S J, Parkes D C, Rosen A, et al. Fairness with an honest minority and a rational majority. In: Proceedings of the 6th
Theory of Cryptography Conference, San Francisco, 2009. 36–53
11 Zhang Z, Liu M. Unconditionally secure rational secret sharing in standard communication networks. In: Proceeding of the
13th International Conference on Information Security and Cryptology, Seoul, 2010. 355–369
12 Zhang Z F, Liu M L. Rational secret sharing as extensive games. Sci China Inf Sci, 2013, 56: 032107
13 Tian Y, Ma J, Peng C, et al. A rational framework for secure communication. Inf Sci, 2013, 250: 215–226
14 Tian Y L, Peng C G, Lin D D, et al. Bayesian mechanism for rational secret sharing scheme. Sci China Inf Sci, 2015, 58:
052109
15 Jin J, Zhou X, Ma C, et al. A rational secret sharing relying on reputation. In: Proceeding of the 8th International Conference
on Intelligent Networking and Collaborative Systems, Ostrawva, 2016. 384–387
16 Nisan N, Ronen A. Algorithmic mechanism design. Games Economic Behav, 2001, 35: 166–196
17 Liu H, Li X H, Ma J F, et al. Reconstruction methodology for rational secret sharing based on mechanism design. Sci China
Inf Sci, 2017, 60: 088101
18 Nakamoto S. Bitcoin: a peer-to-peer electronic cash system. 2008. https://bitcoin.org/en/bitcoin-paper
19 Zhou L, Wang L, Sun Y. Mistore: a blockchain-based medical insurance storage system. J Med Syst, 2018, 42: 149
20 Bartolucci S, Bernat P, Joseph D. SHARVOT: secret SHARe-based VOTing on the blockchain. In: Proceedings of the 1st
International Workshop on Emerging Trends in Software Engineering for Blockchain, Gothenburg, 2018. 30–34
21 Kim Y, Raman R K, Kim Y S, et al. Efficient local secret sharing for distributed blockchain systems. IEEE Commun Lett,
2019, 23: 282–285
22 Xiong F, Xiao R, Ren W, et al. A key protection scheme based on secret sharing for blockchain-based construction supply
chain system. IEEE Access, 2019, 7: 126773–126786
23 Dong C, Wang Y, Aldweesh A, et al. Betrayal, distrust, and rationality: smart counter-collusion contracts for verifiable cloud
computing. In: Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, Dallas, 2017.
211–227
24 Katz J. Bridging game theory and cryptography: recent results and future directions. In: Proceedings of the 5th Theory of
Cryptography Conference, New York, 2008. 251–272
25 Szabo N. Formalizing and securing relationships on public networks. First Monday, 1997, 2: 1–21
26 Pedersen T P. Non-interactive and information-theoretic secure verifiable secret sharing. In: Proceedings of the 11st Annual
International Cryptology Conference, Santa Barbara, 1991. 129–140
27 Tian Y, Guo J, Wu Y, et al. Towards attack and defense views of rational delegation of computation. IEEE Access, 2019, 7:
44037–44049
https://doi.org/10.1145/359168.359176
https://doi.org/10.1016/j.ins.2013.06.027
https://doi.org/10.1006/game.1999.0790
https://doi.org/10.1007/s10916-018-0996-4
https://doi.org/10.1109/LCOMM.2018.2886016
https://doi.org/10.1109/ACCESS.2019.2937917
https://doi.org/10.1109/ACCESS.2019.2908858
	Introduction
	Related work
	Our contribution
	Preliminaries
	Game theory
	Nash equilibrium and sequential equilibrium
	Natural state and prisoner's dilemma
	Natural system model
	Value variables
	Problem statement
	Incentive contract
	New system model
	Value variables
	Contract content and analysis
	Game and analysis
	Verifier's motivation
	Simulation and analysis
	Smart contract
	Requirement
	Overhead
	Conclusion and future work